---
layout: post
title: 数据库
tags: Database
categories: Database
published: true
---

数据查询语言DQL（表记录查询），数据操纵语言DML(表记录操作，需要提交事务)，数据定义语言DDL（库或表结构操作），数据控制语言DCL（数据库操作及授权）。

## Mysql

### install

```shell
wget http://dev.mysql.com/get/Downloads/MySQL-5.6/MySQL-5.6.16-1.el6.x86_64.rpm-bundle.tar

rpm -ivh MySQL-client-5.6.16-1.el6.x86_64.rpm
rpm -ivh MySQL-devel-5.6.16-1.el6.x86_64.rpm
rpm -ivh MySQL-server-5.6.16-1.el6.x86_64.rpm
# 更新数据库
sudo mysql_upgrade -u root -p

/etc/my.cnf
/etc/mysql/my.cnf

[mysqld]
bind-address=0.0.0.0
lower_case_table_names=
```

### 启动和停止

#### windows

```bat
net start mysql
net stop mysql

myql -uroot -ppass -hlocalhost
```

#### linux

```shell
service mysqld start
service mysqld stop
/etc/init.d/mysql restart
```

### 创建用户和授权

```sql
select * from mysql.user;
-- 使用安装时生成的默认密码登陆并首次初始化
set password=PASSWORD('admin');
GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY 'admin' WITH GRANT OPTION;

-- 指定IP上登陆
CREATE USER username@ip IDENTIFIED BY 'password';
-- 任意IP登陆
CREATE USER username@'%' IDENTIFIED BY 'password';
SET PASSWORD FOR username=PASSWORD('password');
-- 关闭数据库安全修改（批量更新和删除会报错）
SET SQL_SAFE_UPDATES=0;
```

```sql
GRANT create,alter,drop,insert,update,delete,select ON databasename.* TO username@localhost;
GRANT all ON databasename.* TO username@localhost;
GRANT ALL PRIVILEGES ON *.* TO 'xpress'@'%' IDENTIFIED BY 'admin' WITH GRANT OPTION;
REVOKE all ON databasename.* FROM username@localhost;
FLUSH PRIVILEGES;
SHOW GRANTS FOR username@localhost;
```

### 数据库操作

```sql
show global variables like '%datadir%';
-- 创建数据库
CREATE DATABASE databasename CHARSET=utf8;
-- 删除数据库
DROP DATABASE databasename;
-- 修改数据库
ALTER DATABASE databasename CHARACTER SET utf8;
-- 查看数据
show databases;
-- 数据库切换
use databasename;
```

### 数据类型

| 类型       | 名称               | 备注                                                         |
| ---------- | ------------------ | ------------------------------------------------------------ |
| int        | 整型               |                                                              |
| double     | 浮点型             | double(5,2)表示最多五位，其中有两位是小树，最大值为999.99    |
| decimal    | 浮点型             | 不会出现精度缺失问题                                         |
| char       | 固定长度字符串类型 | char(255)，数据长度不足时补足到指定长度                      |
| varchar    | 可变长度字符串类型 | varchar(65535) 会占用字节存储实际长度                        |
| text(clob) | 字符串类型         | tinytext 2^8-1,text 2^16-1,mediumtext 2^24-1,longtext 2^32-1 |
| blob       | 字节类型           | tinyblob 2^8-1,blob 2^16-1,mediumblob 2^24-1,longblob 2^32-1 |
| date       | 日期类型           | yyyy-MM-dd                                                   |
| time       | 时间类型           | hh:mm:ss                                                     |
| tomestamp  | 时间戳类型         |                                                              |

*ps:使用blob类型时，在my.ini中配置调整允许发送的包大小*

```ini
max_allowed_packet=10485760
```

### 表操作

#### 创建和删除表

```sql
CREATE TABLE IF NOT EXISTS tablename(
    columnname int,
    columnname1 char(255)
);
DROP TABLE tablename
```

#### 查看表

```sql
show tables;
-- 查看创建语句
show create table tablename;
-- 查看表结构
desc tablename;
```

#### 修改表

* 修改表名

```sql
ALTER TABLE tablename tablename RENAME TO newtablename;
```

* 增加列

```sql
ALTER TABLE tablename ADD(
    columnname int,
    columnname1 char(20)
)
```

* 修改列类型

如果别修改列已存在数据，那么新的类型可能影响已存在的数据

```sql
ALTER TABLE tablename MODIFY columnname int;
```

* 修改列名

```sql
ALTER TABLE tablename CHANGE columnname newcolumnname int;
```

* 删除列

```sql
ALTER TABLE tablename DROP columnname;
```

### 数据操作

#### 插入

```sql
INSERT INTO tablename(columnname,columnname1) values ('value','value');
-- 与创建表时顺序相同
INSERT INTO tablename values ('value','value');
```

#### 更新

```sql
UPDATE tablename SET columnname='value',columnname1='value' where columnname='value';
```

查询条件

| 运算符                   | 备注                                                 |
| ------------------------ | ---------------------------------------------------- |
| `=`                      |                                                      |
| `!=`或`<>`               |                                                      |
| `>`、`<`和`<=`、`>=`     |                                                      |
| `BETWEEN AND`            | 检查你的数据库是如何处理 BETWEEN....AND 操作符边界的 |
| `IN(...)`                |                                                      |
| `IS NULL`和`IS NOT NULL` | =NULL必返回false                                     |
| `NOT`                    |                                                      |
| `OR`和`AND`              |                                                      |

#### 删除

```sql
DELETE FROM tablename WHERE columnname = 'value';
```

#### 查询

##### 单表查询

###### 检索去重

```sql
SELECT * FROM tablename;
-- 去除重复
SELECT DISTINCT columnname FROM tablename;
-- 查询到文件 需要权限
select count(1) from table into outfile '/tmp/1.xls';
-- 不需要权限
echo "select * from db_web.help_cat where 1 order by sort desc limit 0,20" | mysql -h127.0.0.1 -uroot > /data/sort.xls
```

###### 运算

```sql
SELECT columnname*1.5 FROM tablename;
-- 防止NULL值相加变成NULL
SELECT columnname+ifnull(columnname1,0) FROM tablename;
```

###### 拼接

```sql
SELECT CONCAT(columnname,'--',columnname1) as alias FROM tablename;
```

###### 模糊查询

```sql
SELECT * FROM tablename WHERE columnname LIKE 'value_';
```

| 符号 | 匹配规则      |
| :--: | :---------:   |
| _    | 匹配一个字符  |
| %    | 匹配0~n个字符 |

###### 排序

```sql
-- 默认ASC升序
SELECT * FROM tablename ORDER BY columnname ASC;
-- 多列排序
SELECT * FROM tablename ORDER BY columnname ASC,columnname1 DESC;
```

###### 聚合函数

```sql
-- 总数，列信息不为NULL则计数，*所有列不为NULL计数
SELECT COUNT(*) FROM tablename;
SELECT MIN(*) FROM tablename;
SELECT MAX(*) FROM tablename;
SELECT SUM(*) FROM tablename;
SELECT AVG(*) FROM tablename;
-- 组合使用
SELECT COUNT(*),MAX(columnname),AVG(columnname) FROM tablename;
```

###### 分组

```sql
-- 分组前条件用WHERE
-- 分组后条件用HAVING
SELECT 
    columnname,
    columnname1,
    COUNT(*),
    MAX(columnname),
    AVG(columnname2)
FROM
    tablename
WHERE
    columnname IS NOT NULL
GROUP BY columnname , columnname1
HAVING COUNT(*) > 1;
```

###### LIMIT方言

```sql
-- LIMIT begin,count 6-15
SELECT * FROM tablename LIMT 5,10;
```

##### 多表查询

###### 合并结果集

    - 两个结果集的列相同，结果在同列显示

```sql
-- 不去重
SELECT * FROM tablename
UNION ALL
SELECT * FROM tablename1
-- 去除重复
SELECT columnname FROM tablename
UNION
SELECT columnname FROM tablename1
```

###### 连接查询

    - 内连接
    - 外连接
        + 左外连接
        + 右外连接
        + 全外连接（mysql不支持）
    - 自然连接

*内连接*

必须满足两张表都有数据

```sql
-- 方言版本
SELECT * FROM tablename,tablename1 WHERE tablename.columnname = tablename1.columnname;
-- 标准版本
SELECT * FROM tablename INNER JOIN tablename1 ON tablename.columnname = tablename1.columnname;
-- 自然内连接：自动匹配两个table列名相同的列
SELECT * FROM tablename NATURAL JOIN tablename1;
```

*外连接*

外连接一主一次，左外左表为主，主表所有数据都会显示，不满足条件的右表数据为NULL

```sql
-- 左外连接
SELECT * FROM tablename LEFT OUTER JOIN tablename1 ON tablename.columnname = tablename1.columnname;
-- 右外连接
SELECT * FROM tablename RIGHT OUTER JOIN tablename1 ON tablename.columnname = tablename1.columnname;
-- 全外链接，左右表结构都在，不符合条件补NULL（mysql不支持）
SELECT * FROM tablename FULL OUTER JOIN tablename1 ON tablename.columnname = tablename1.columnname;
-- 使用合并结果集模拟全外连接
SELECT * FROM tablename LEFT OUTER JOIN tablename1 ON tablename.columnname = tablename1.columnname;
UNION
SELECT * FROM tablename RIGHT OUTER JOIN tablename1 ON tablename.columnname = tablename1.columnname;
-- 自然外连接：同自然内连接
```

###### 子查询

子查询条件组合

| 子查询结果集 | 可嵌套条件          |
| ------------ | ------------------- |
| 单行单列     | =、>、<、>=、<=、!= |
| 多行单列     | IN、ALL、ANY        |
| 单行多列     | 多列IN多列          |
| 多行多列     | 当作表连接查询      |

```sql
-- 单行单列
SELECT * FROM tablename WHERE columnname = (SELECT MAX(columnname) FROM tablename);
-- 多行单列
SELECT * FROM tablename WHERE columnname > ANY (SELECT columnname FROM tablename WHERE columnname1 = 'value');
SELECT * FROM tablename WHERE columnname > ALL (SELECT columnname FROM tablename WHERE columnname1 = 'value');
SELECT * FROM tablename WHERE columnname IN (SELECT columnname FROM tablename WHERE columnname1 = 'value');
-- 单行多列
SELECT * FROM tablename WHERE columnname,columnname1 IN (SELECT columnname,columnname1 FROM tablename WHERE columnname1 = 'value');
-- 多行多列 结果集为表要有别名
SELECT MAX(columnname) FROM (SELECT * FROM tablename  WHERE columnname < 'value') alias;
```

### 约束

* 非空约束
* 唯一约束
* 检查约束
* 主键约束
* 外键约束

#### 主键约束

* 非空
* 唯一
* 被引用（外键）

```sql
CREATE TABLE tablename (
    columnname INT PRIMARY KEY AUTO_INCREMENT,-- 自增长，必须整型
    columnname1 VARCHAR(20)
)

CREATE TABLE tablename (
    columnname INT,
    columnname1 VARCHAR(20),
    PRIMARY KEY (columnname)
)

ALTER TABLE tablename ADD PRIMARY KEY(columnname);
ALTER TABLE tablename DROP PRIMARY KEY;
```

#### 非空约束

```sql
CREATE TABLE tablename (
    columnname INT,
    columnname1 VARCHAR(20) NOT NULL -- 非空
)
```

#### 唯一约束

```sql
CREATE TABLE tablename (
    columnname INT,
    columnname1 VARCHAR(20) UNIQUE -- 唯一
)
```

#### 外键约束

* 外键必须是另一个表的主键（另一个表也可以是本表）
* 外键可以重复
* 外键可以为空
* 一张表可以有多个外键

```sql
CREATE TABLE tablename (
    columnname INT,
    columnname1 VARCHAR(20),
    CONSTRAINT fkname FOREIGN KEY (columnname1)
        REFERENCES tablename1 (colunmname) -- 指定外键，外键名和列名可以不同
)

ALTER TABLE tablename ADD
    CONSTRAINT fkname FOREIGN KEY (columnname1)
        REFERENCES tablename1 (colunmname)
```

##### 一对一关系

从表的主键既是外键

##### 一对多关系

普通外键表示一对多关系

##### 多对多关系

中间表两个外键映射多对多关系

### 事务

```sql
-- 开启事务
start transaction;
-- 提交事务
commit;
-- 回滚事务
rollback;
-- 查看隔离级别
select @@global.tx_isolation, @@tx_isolation;
select @@autocommit;
-- 查看支持的引擎
show engines;
-- 查看当前引擎
show variables like '%storage_engine%';
-- 查看引擎状态，查询上一次死锁
show engine innodb status;
-- 查看最近执行语句
select * from information_schema.innodb_trx;
-- 设置隔离级别isolationlevel 4选1
set transaction isolationlevel;
-- 查询正在进行的语句
show processlist;
kill <id>;
```

### 视图

视图是由查询结果形成的一张虚拟表，示表通过某种运算得到的一个投影

#### 作用

* 可以简化查询
* 可以进行权限控制
    - 表权限关闭，视图中放表的部分数据

#### 创建、修改和删除视图

```sql
create view view_name as select.....  
alter view view_name as select.....  
drop view view_name
```

* 视图和表同一级别，隶属于数据库
* 视图可以设定自己的字段名，通常不设置

#### 查询视图

同查询表，可以使用where

**查看所有视图**

```sql
show tables;
```

**查看视图结构**

```sql
desc view_name
```

#### 插入视图

* 视图必须包含表中没有默认值的所有列，才可以进行插入
* 一般来说，属兔只是用来查询的不应该执行增删改操作。

### 存储过程

把一段代码封装起来，当要调用这段代码时，可以通过调用储存过程实现。

* 经过一次编译后再次调用不需要再次编译
* 权限控制
* 可复用，配合数据库事务一起使用

```sql
show procedure status; --查询现有存储过程
```

#### 创建、删除存储过程

```sql
create procedure p_name(num int)
begin
...
end

drop procedure p_name;
```

#### 调用存储过程

```sql
call p_name(1);
```

#### 语句结束符

```xml
delimiter $
select * from users$
```

#### 变量

##### 会话变量

在编程环境和非编程环境都可以使用

```sql
set @var_name = 'value';
select @var_name;
```

##### 普通变量

在编程环境使用（存储过程、函数、触发器）

```sql
declare var_name type_name default default_value;
set varname = 'value';
```

##### 变量赋值

```sql
set @var_name = 表达式;
set varname = 表达式;
select @var_name := 表达式; -- 赋值并查询结果
select 表达式 into @var_name;
```

##### 系统变量

以@@开头的都是系统变量

```sql
SELECT @@version;
```

#### 运算符

略

#### 标识符

![begin_label.png](/static/img/数据库/begin_label.png "begin_label.png")

#### 条件

##### if判断

```sql
CREATE PROCEDURE p_name(num INT)
  BEGIN
    IF num = 1
    THEN
      SELECT...
    ELSEIF num = 2
      THEN
        SELECT...
    ELSE
      SELECT...
    END IF;
  END;
```

##### case判断

```sql
CREATE PROCEDURE p_name(num INT)
  BEGIN
    CASE num
      WHEN 1
      THEN
        SELECT 'spring' AS 'season';
      WHEN 2
      THEN
        SELECT 'summer' AS 'season';
      WHEN 3
      THEN
        SELECT 'autumn' AS 'season';
    ELSE SELECT '' AS 'season';
    END CASE;
  END;
```

##### loop循环

```sql
CREATE PROCEDURE p_name(num INT)
  BEGIN
    DECLARE current INT DEFAULT 1;
    DECLARE result INT DEFAULT 0;
    operate: LOOP
      SET result = current + result;
      SET current = current + 1;
      IF current > num
      THEN
        LEAVE operate;
      END IF;
    END LOOP;
    SELECT result;
  END;
```

##### while循环

```sql
CREATE PROCEDURE p_name(num INT)
  BEGIN
    DECLARE current INT DEFAULT 1;
    DECLARE result INT DEFAULT 0;
    WHILE current <= num DO

      SET result = current + result;
      SET current = current + 1;

    END WHILE;

    SELECT result;
  END;
```

##### repeat循环

```sql
CREATE PROCEDURE p_name(num INT)
  BEGIN
    DECLARE current INT DEFAULT 1;
    DECLARE result INT DEFAULT 0;
    REPEAT

      SET result = current + result;
      SET current = current + 1;

    UNTIL current > num
    END REPEAT;

    SELECT result;
  END;
```

#### 参数

* 输入参数（in，默认）
* 输出参数（out）
* 输入输出参数（inout）

```sql
CREATE PROCEDURE p_name(IN n INT, OUT result INT)
  BEGIN
    SET result = n * n;
  END;

SET @result = 0;
CALL p_name(100, @result);
SELECT @result;
```

```sql
CREATE PROCEDURE p_name(INOUT n INT)
  BEGIN
    SET n = n * n;
  END;

SET @n = 100;
CALL p_name(@n);
SELECT @n;
```

### 函数

创建的函数是隶属于库的，只能在创建函数的库中使用

* 函数内部可以有各种编程语言的元素（变量，流程控制，函数调用）
* 函数内部可以有增删改等语句
* 函数内部不可以有select、show、desc这种返回结果集的语句

#### 创建函数

```sql
CREATE FUNCTION mySum(n INT, m INT)
  RETURNS INT
  BEGIN
    RETURN m + n;
  END;

SELECT mySum(1, 2);
DROP FUNCTION mySum;
```

#### 系统函数

##### 数字

```sql
SELECT rand();

SELECT *
FROM users
ORDER BY rand()
LIMIT 2; -- 随机取出2个人

SELECT floor(3.9); -- 3
SELECT ceil(3.1); -- 4
SELECT round(3.5); -- 4 四舍五入
```

##### 字符串

```sql
-- 大小写转换
SELECT ucase('Hello');
SELECT lcase('Hello');
```

```sql
SELECT left('abcdef', 3); -- abc
SELECT right('abcdef', 3); -- def
SELECT substr('abcdef', 2, 3); -- bcd，从2开始截取3个，位置从1开始
SELECT concat('abcdef', 3); -- abcdef3
SELECT concat(USERNAME, '-', NICKNAME) FROM users;
SELECT coalesce(NULL, 123); -- 123 如果第一个值为null，就显示第二个值

SELECT length('abcdef'); -- 6
SELECT length('你好'); -- 6 字节个数
SELECT char_length('你好'); -- 2 字符个数
SELECT replace('abc','b','d'); -- adc
SELECT trim(' abc ');

-- 转义
SELECT * FROM BONUS WHERE BONUS.ENAME LIKE '%$%%' ESCAPE '$';-- 指定字符
SELECT * FROM BONUS WHERE BONUS.ENAME LIKE '%\'%';-- 默认转义为\
SELECT * FROM BONUS WHERE BONUS.ENAME LIKE '%''%';-- 是哦那个'转义'
```

##### 时间

```sql
SELECT unix_timestamp();-- 1495179836
SELECT FROM_UNIXTIME(unix_timestamp(),'%y-%m-%d');-- 17-05-19
SELECT FROM_UNIXTIME(unix_timestamp(),'%Y-%m-%d');-- 2017-05-19
SELECT curdate();-- 2017-05-19
SELECT now();-- 2017-05-19 15:44:46
SELECT
  year(now()),
  month(now()),
  day(now()),
  hour(now()),
  minute(now()),
  second(now());
SELECT datediff(now(),'1997-1-1');-- 7443天

SELECT date_sub(curdate(),INTERVAL 1 DAY);-- 2017-05-18
SELECT date_add(curdate(),INTERVAL 1 DAY);-- 2017-05-20
SELECT date_sub(curdate(),INTERVAL 1 HOUR);-- 2017-05-18 23:00:00

SELECT date_format(curdate(),'%Y-%m-%d');
SELECT str_to_date('2017-07-05 17:08:00','%Y-%m-%d %H:%i:%s');
select id from creative where update_time between str_to_date('2017-09-13 19:00:00','%Y-%m-%d %H:%i:%s') and now();
```

##### 表达式

```sql
SELECT concat(10, if(10 % 2 = 0, '偶数', '奇数'));
```

### 触发器

* 是一个特殊的存储过程，在insert、update、delete的时候自动执行的代码块
* 触发器必须定义在特定的表上
* 自动执行，不能直接调用

目前mysql不支持多个具有同一动作、同一时间、同一事件、同一地点的触发器

#### 触发器使用

```sql
SHOW TRIGGERS;
DROP TRIGGER t_name;

-- 对于新增而言，新增的行用new来表示
CREATE TRIGGER t_name
AFTER INSERT ON orderdetails
FOR EACH ROW
  BEGIN
    UPDATE items
    SET COUNT = COUNT - NEW.COUNT
    WHERE ID = NEW.ITEM_ID;
  END;
-- 对于删除而言，删除的行用old来表示
CREATE TRIGGER t_name
AFTER DELETE ON orderdetails
FOR EACH ROW
  BEGIN
    UPDATE items
    SET COUNT = COUNT + OLD.COUNT
    WHERE ID = OLD.ITEM_ID;
  END;
-- 更新前NEW和更新后OLD
CREATE TRIGGER t_name
AFTER UPDATE ON orderdetails
FOR EACH ROW
  BEGIN
    UPDATE items
    SET COUNT = COUNT + OLD.COUNT
    WHERE ID = OLD.ITEM_ID;
    UPDATE items
    SET COUNT = COUNT - NEW.COUNT
    WHERE ID = NEW.ITEM_ID;
  END;
```

#### before和after区别

* after是先完成数据的增删改，再触发，触发器中的语句晚于监视的增删改，无法影响前面的增删改动作
* before是完成触发，再做增删改，触发的语句优于监视的增删改发生，我们有机会判断修改即将发生的操作。

```sql
CREATE TRIGGER t_name
BEFORE UPDATE ON orderdetails
FOR EACH ROW
  BEGIN
    IF NEW.COUNT > 5
    THEN
      SET NEW.COUNT = 5;
    END IF;
  END;
```

### 编码

* 查询编码

```sql
SHOW VARIABLES LIKE 'char%';
```

| 变量名                | 作用       | 备注                          |
| --------------------- | ---------- | ----------------------------- |
| character_set_client  | 客户端编码 | mysql解析客户端发送数据的编码 |
| character_set_results | 结果集编码 | mysql返回结果集的编码         |

* 修改编码

```sql
-- 只在当前窗口有效
set character_set_client=gbk;
set character_set_results=gbk;
```

```ini
# 在配置文件中修改永久有效
# 影响三个变量：client、results、connection
[mysql]

default-character-set=utf8
```

### 高可用和可扩展

为了保证站点可响应和可用，需要三样东西：数据备份，系统冗余和响应性。

* 备份可以将节点恢复到崩溃前的状态
* 即使一个或多个节点停止运行，冗余也可以使站点继续运行
* 响应能力使系统在实践生产中可用

#### 复制

复制的两种最常见的用途是：

* 创建主服务器的备份，以避免主服务器崩溃时丢失任何数据
* 让主服务器的副本执行报表和分析工作，而不会影响其他业务

复制可以做的更多：

* 支持多个机房
* 有服务器停机时高可用
* 灾备
* 错误保护
	* slave比master落后一个周期，在master上发生错误时，找到出错的语句，在slave执行前删除它

在横向扩展场景中使用复制时，重要的是要明白，MySQL复制传统上是异步的，因为事务首先在主服务器上提交，
然后复制到从服务器并在此处应用。这意味着master和slave可能不一致，如果复制持续运行，则slave将落后于master。

使用异步复制的优点是它比同步复制更快、更有效，但是在需要有实时数据的情况下，必须处理不同步的问题以确保信息的时效性。

#### MySQL复制原理

* 通过热备份达到高可用性
* 产生报表
	* 创建一个额外的服务器来运行大量的后台作业
* 调试和审计

##### 复制的基本步骤

系统创建一个能访问关键文件的shell用户。

```conf
# master
[mysqld]
user            = mysql
pid-file        = /var/run/mysqld/mysqld.pid
socket          = /var/run/mysqld/mysqld.sock
port            = 3306
basedir         = /usr
datadir         = /var/lib/mysql
tmpdir          = /tmp
# 默认hostname-bin，来自pid-file选项
# 使用默认值有一个问题就是hostname一旦改变会找不到文件，下同
log-bin         = master-bin
# 默认与上面同名
log-bin-index   = master-bin.index
server-id       = 1
```

```conf
# slave
[mysqld]
user            = mysql
pid-file        = /var/run/mysqld/mysqld.pid
socket          = /var/run/mysqld/mysqld.sock
port            = 3306
basedir         = /usr
datadir         = /var/lib/mysql
tmpdir          = /tmp
# 与master不重复
server-id       = 2
relay-log-index = slave-relay-bin.index
relay-log       = slave-relay-bin
```

```sql
-- master server创建一个复制用户
CREATE USER repl_user;
GRANT REPLICATION SLAVE ON *.* TO repl_user IDENTIFIED BY 'password';
```

```sql
-- 配置master和slave的用户，slave上执行
-- 需要FLUSH LOGS、SHOW MASTER\SLAVE STAUS、CHANGE MASTER TO 、等命令的权限
GRANT REPLICATION SLAVE, RELOAD, CREATE USER, SUPER ON *.* TO mats@'192.168.2.%' WITH GRANT OPTION;
```

```sql
-- slave上使用mats执行
CHANGE MASTER TO MASTER_HOST = 'master-1',MASTER_PORT = 3306,MASTER_USER = 'repl_user',MASTER_PASSWORD = 'password';
```

```sql
-- 删除并清空二进制文件，确保没有slave链接到master
RESET MASTER;
-- 删除复制用的所有文件
STOP SLAVE;-- 首先执行确保没有活动的复制
RESET SLAVE;
```

##### 建立新slave（增加）

自举slave，而不是从头开始复制。参考《二进制日志》部分

1. 配置新的slave
2. 备份master（或者slave）
3. 记录备份的binlog位置
4. 从新的slave上恢复
5. 配置slave从binlog位置开始恢复

**方式1：克隆master**

这种方式需要离线master

_手动过程：_

```sql
-- 刷新所有表并锁定
FLUSH TABLES WITH READ LOCK;
SHOW MASTER STATUS\G
```

```conf
# binlog下一个写入位置为456552
*************************** 1. row ***************************
             File: mysql-bin.0000042
         Position: 456552
     Binlog_Do_DB: 
 Binlog_Ignore_DB: 
```

```shell
# 备份master
mysqldump --all-databases --host=master-1 >backup.sql
```

```sql
UNLOCK TABLES;
```

```shell
# 导入slave
mysql --host=slave-1 <backup.sql
```

```sql
CHANGE MASTER TO MASTER_HOST = 'master-1', MASTER_PORT = 3306, MASTER_USER = 'slave-1', MASTER_PASSWORD = 'password', MASTER_LOG_FILE = 'master-bin.000042', MASTER_LOG_POS = 456552;
START SLAVE;
```

_自动过程：_

```shell
# 自动生成CHANGE MASTER TO语句
mysqldump --host=master -all-databases --master-data=1 >backup-source.sql
```

```shell
mysql --host=slave-1 <backup-source.sql
```

**方式2：克隆slave**

```sql
STOP SLAVE;
SHOW SLAVE STATUS \G
```

执行后可以创建备份，参考《克隆master》部分

```conf
...
Relay_Master_Log_File: master-bin.000042
...
Exec_Master_Log_Pos: 546632
```

```sql
START SLAVE;
```

FLUSH TABLES WITH READ LOCK在InnoDB中使用是不安全的，后台仍有一些阻止不了的活动在运行，下面方法可安全的创建InnoDB数据表的备份：

* 关闭服务器并复制文件。 如果数据库很大，这可能是一个优势，因为使用mysqldump恢复数据可能会很慢。
* 在执行FLUSH TABLES WITH READ LOCK之后使用mysqldump（如上面的操作过程）。
	* 读取锁定可防止读取数据时发生更改。
	* 如果要读取大量数据，数据库可能会长时间处于锁定状态。
	* 可以使用--single-transaction选项获取一致的快照，但只有在使用InnoDB表时才可能。
* 在使用FLUSH TABLES WITH READ LOCK锁定数据库的同时，使用LVM（在Linux上）或ZFS（在Solaris上）等快照解决方案。
* 使用MySQL企业备份（或XtraBackup）进行MySQL的联机备份。

##### 执行常见的复制任务

横向扩展、热备份等

```sql
-- 查看二进制文件名称
SHOW BINARY LOGS;
```

```shell
# 停止slave后，指定binlog文件名称并指定binlog同步的日期区间来解析binlog内容
mysqlbinlog --force --read-from-remote-server --host=reporting.bigcorp.com --start-datetime='2009-09-25 23:55:00' --stop-datetime='2009-09-25 23:59:59' capulet-bin.000004
```

```sql
# 解析结果：
	.
	.
# at 2495
#090929 23:58:36 server id 1  end_log_pos 2650  Query   thread_id=27    exe...
SET TIMESTAMP=1254213690/*!*/;
SET /*!*/;
INSERT INTO message_board(user, message)
     VALUES ('mats@sun.com', 'Midnight, and I'm bored')
/*!*/;
```

```sql
-- 开启slave直到指定位置停止
START SLAVE UNTIL MASTER_LOG_POS='capulet-bin.000004', MASTER_LOG_POS=2650;
-- 阻塞检查直到同步完成，就可以进行其他操作了
SELECT MASTER_POS_WAIT('capulet-bin.000004',  2650);
```

任务调度：

```shell
# reporttab file content
# stop reporting slave five minutes before midnight, every day
55 23 * * * $HOME/mysql_control/stop_slave
# Run reporting script five minutes after midnight, every day
5 0 * * * $HOME/mysql_control/daily_report
```

```shell
crontab reporttab
```

#### 二进制日志

参考《复制》部分二进制日志的配置

复制过程中需要binlog，它记录了服务器数据库上的所有变更，对于不改变数据的语句不会写入二进制日志。  
二进制日志按照master上事务提交的顺序记录它们，每个事务在日志中是连续记录的，取决于事务提交的时间。

_Tips：master和slave上下文环境不完全一致的话，可能导致执行结果不同。MySQL还提供了基于行的复制_

##### 文件记录

```sql
-- 刷新binlog
FLUSH LOGS;
-- \G字段换行输出，只显示第一个
SHOW BINLOG EVENTS\G
SHOW BINLOG EVENTS IN 'master-bin.000002'\G
SHOW BINLOG EVENTS FROM 238\G
-- 查看正在写入的文件名称
SHOW MASTER STATUS\G
```

```log
*************************** 1. row ***************************
   Log_name: mysql-bin.000001
        Pos: 4
 Event_type: Format_desc
  Server_id: 1
End_log_pos: 107
       Info: Server ver: 5.5.34-0ubuntu0.12.04.1-log, Binlog ver: 4
*************************** 2. row ***************************
   Log_name: mysql-bin.000001
        Pos: 107
 Event_type: Query
  Server_id: 1
End_log_pos: 198
       Info: use `test`; CREATE TABLE tbl (text TEXT)
*************************** 3. row ***************************
...
*************************** 5. row ***************************
   Log_name: mysql-bin.000001
        Pos: 374
 Event_type: Xid
  Server_id: 1
End_log_pos: 401
       Info: COMMIT /* xid=188 */
*************************** 6. row ***************************
   Log_name: mysql-bin.000001
        Pos: 401
 Event_type: Rotate
  Server_id: 1
End_log_pos: 444
       Info: mysql-bin.000002;pos=4
6 rows in set (0.00 sec)
```

* Event_type：事件类型
* Server_id：事件服务器id
* Log_name：存储事件的文件名
* Pos：事件在文件中的开始位置
* End_log_pos：事件在文件中的结束位置
* Info：关于事件信息的可读文本

##### 结构和内容

二进制日志由一组包含真实内容的binlog文件和一个跟踪binlog文件存储位置的索引文件组成。  
有一个二进制文件是活动二进制文件，即当前被写入的文件。

![二进制日志的构成](/static/img/数据库/Structure-of-the-binary-log.png)

二进制日志文件都以格式描述时间开始，以日志轮换事件结束。

_注意事项：如果服务器突然停止或司机，binlog文件末尾可能不是轮换事件_

binlog文件中的事件组要么是不属于事务的单个语句，要么是由多条语句组成的事务。每个组要么全都执行，要么都不执行。

![包含多个事件组的单个binlog文件](/static/img/数据库/A-single-binlog-file-with-groups-of-events.png)

###### binlog事件的结构

* 通用头
	* 事件的基本信息，事件类型和事件大小
* 提交头
	* 与特定的事件类型有关
* 事件体
	* 存储事件的主要数据
* 校验和
	* 版本5.6开始可以产生，是一个32位整数，用于检查事件写入后是否有损坏
	* 默认开启，使用CRC32校验和

```shell
# 验证校验和
mysqlbinlog --verify-binlog-checksum master-bin.000001
```

##### 将语句写入日志

在事件组写二进制日志之前，二进制日志将获得一个互斥锁LOCK_log，然后在事件组写完成后释放。这个锁常常会阻塞某些会话线程。

###### 写入DML语句

数据操作语言（DML）语句通常是指DELETE，INSERT和UPDATE语句。  
为了以一致的方式支持日志记录更改，MySQL在获取了事务级锁的同时写入二进制日志，并在二进制日志写入后释放它们。

为了确保二进制日志与语句修改的表一致地更新，每个语句在语句提交期间都被记录到二进制日志中，就在表锁释放之前。
如果没有将日志记录作为语句的一部分，则可以在语句向数据库引入的更改和对二进制日志的语句的日志记录之间“注入”另一个语句。
这意味着语句将以不同的顺序记录，而不是在数据库中执行的顺序，这可能会导致manster和slave之间的不一致。

###### 写入DDL语句

数据定义语言(DDL)语句影响数据模式(schema)，例如CREATE TABLE和ALTER TABLE语句。
DDL语句会在文件系统中创建或改变对戏那个，例如表定义存储在.frm文件中，而数据表现为文件系统中的目录。因此服务洗需要将这些信息保存在内部数据结构中。  
为了保护这个内部数据结构的更新，在修改表定义之前需要先获得一个内部锁(称为LOCK_open)。

因为只有一个锁保护这些数据结构，所以数据库对象的创建、更新和销毁都可能带来性能问题。例如创建和销毁临时表。

###### 写入查询

无论那种情况，时间都在不同的上下文（context）中执行，上下文是指服务器执行语句时必须知道的隐式（implicit）信息，以保证语句能够正确执行

* 当前数据库
	* 向QUERY事件添加一个特殊字段，记录当前数据库
* 当前时间
	* SYSDATE()操作系统取时间，用于复制不安全，慎用；
	* NOW()开始执行语句的时间
	* 事件存储一个时间错，表明事件何时开始执行。
* 上下文事件
	* 用户自定义变量的值
		* 事件：User_var
		* 记录变量名及值
	* RAND函数的种子
		* 事件：Rand
		* 记录RAND随机函数的种子，种子取自会话内部状态。
	* AUTO_INCREMENT字段的插入值
		* 事件：Intvar
		* 记录增量计数器的值
	* 调用LAST_INSERT_ID的返回值
		* 事件：Intvar
		* 记录返回值
* 线程ID
	* 如CONNECTION_ID就必须知道线程ID，线程ID对临时表处理尤为重要
	* 临时表名称由服务器的进程ID，创建表的进程ID和一个线程计数器组成，计数器用来区分同一个线程中不同的临时表实例。
	* 线程ID作为一个独立字段存储在每个QUERY事件，因此可以用线程ID字段来计算线程特定的数据，并正确处理临时表

```shell
*************************** 1. row ***************************
   Log_name: mysqld1-bin.000001
        Pos: 238
 Event_type: Query
  Server_id: 1
End_log_pos: 306
       Info: BEGIN
*************************** 2. row ***************************
   Log_name: mysqld1-bin.000001
        Pos: 306
 Event_type: Intvar
  Server_id: 1
End_log_pos: 334
       Info: INSERT_ID=1
*************************** 3. row ***************************
   Log_name: mysqld1-bin.000001
        Pos: 334
 Event_type: RAND
 Server_id: 1
End_log_pos: 369
       Info: rand_seed1=952494611,rand_seed2=949641547
*************************** 4. row ***************************
   Log_name: mysqld1-bin.000001
        Pos: 369
 Event_type: User var
  Server_id: 1
End_log_pos: 413
       Info: @`foo`=12
*************************** 5. row ***************************
...
*************************** 9. row ***************************
   Log_name: mysqld1-bin.000001
        Pos: 681
 Event_type: Intvar
  Server_id: 1
End_log_pos: 709
       Info: LAST_INSERT_ID=1
```

###### LOAD DATA INFILE语句

* Begin_load_query
	* 这个事件标志着文件中数据传输的开始。
* Append_block
	* 一个或多个这些事件的序列遵循Begin_load_query事件，以包含文件的其余数据，如果文件大于连接上允许的最大数据包大小。
* Execute_load_query
	* 该事件是QUERY事件的一种特殊变体，它包含在master服务器上执行的LOAD DATA INFILE语句。
	* 即使该事件中包含的语句包含了master服务器上使用的文件的名称，但这个文件将不会被slave找到。相反，使用前面的Begin_load_query和Append_block事件获取文件的内容。

```sql
SHOW BINLOG EVENTS IN 'master-bin.000042' FROM 269\G
*************************** 1. row ***************************
   Log_name: master-bin.000042
        Pos: 269
 Event_type: Begin_load_query
  Server_id: 1
End_log_pos: 16676
       Info: ;file_id=1;block_len=16384
*************************** 2. row ***************************
   Log_name: master-bin.000042
        Pos: 16676
 Event_type: Append_block
  Server_id: 1
End_log_pos: 33083
       Info: ;file_id=1;block_len=16384
*************************** 3. row ***************************
   Log_name: master-bin.000042
        Pos: 33083
 Event_type: Append_block
  Server_id: 1
End_log_pos: 33633
       Info: ;file_id=1;block_len=527
*************************** 4. row ***************************
   Log_name: master-bin.000042
        Pos: 33633
 Event_type: Execute_load_query
  Server_id: 1
End_log_pos: 33756
       Info: use `test`; LOAD DATA INFILE 'foo.dat' INTO...;file_id=1
4 rows in set (0.00 sec)
Binary Log Filters
```

##### 将事务写进日志

以下情况开启事务：

* 用户发出START TRANSACTION或BEGIN命令时
* 当AUTOCOMMIT=1，且开始执行访问事务型表的语句时（事务型表）
* 当AUTOCOMMIT=0，且上一个事务已经隐式或显示地被提交或终止时

非事务型语句之后执行的事务型语句仍然属于当前活动的事务。

隐式提交的语句：

* 写文件的语句
	* 大多数的DDL语句
* 修改MySQL数据表的语句
	* 所有创建、删除或修改用户账户或用户权限的语句都是隐式提交的，而且不是事务的一部分。
* 出于实践原因要求隐式提交的语句
	* 锁定表、用于管理的语句和LOAD DATA INFILE语句都会导致隐式提交，这是具体实现的需要。

###### 事务缓存

二进制日志包含所有会话的事务信息，按照它们提交的顺序保存，就好像它们都是顺序执行的。

为了确保每个事务都是作为二进制日志的一个单元来编写的，服务器必须在不同的线程中分别执行不同的语句。
在提交事务时，服务器将所有作为事务部分的语句写入到二进制日志中，作为单个单元。
为此，服务器为每个线程保留一个事务缓存（transaction cache）。为事务执行的每个语句都放在事务缓存中，事务缓存的内容随后被复制到二进制日志中，并在事务提交时清空。

![transaction-cache](/static/img/数据库/transaction-cache.png)

非事务型语句如果同事影响事务型表和非事务型表，情况更加复杂，下面是记录时采取的一些方法：

_如何写入非事务型语句：_

当没有事务打开时，非事务型语句被写入到语句执行结束时的二进制日志中，并且在结束二进制日志之前不会在事务缓存中“中转”。但是，如果事务是打开的，规则如下:

* 如果该语句被标记为事务型的，那么它将被写入到事务缓存中。
* 如果语句没有被标记为事务型的，并且在事务缓存中没有语句，那么该语句将直接写入到二进制日志中。
* 如果语句没有被标记为事务型的，但是在事务缓存中有语句，那么语句将写到事务缓存中。
	* 避免了事务型操作和非事务型操作顺序乱序问题
	* 会引起非事务型数据表操作顺序与写入binlog的顺序不同

_如何避免非事务型语句的复制问题：_

* 不使用非事务型表
* 确保事务中影响非事务型表的语句先写入日志。这样就先写入日志。

`binlog_direct_non_transactional_updates`选项强制非事务型语句直接写入二进制日志。
这要保证这些语句之间没有依赖关系，否则就要使用基于行的复制。

###### 使用XA进行分布式事务处理

MySQL版本5.0允许使用X/Open DT[模型即XA来协调涉及不同资源的事务。
在5.0版本中，服务器在内部使用XA来协调二进制日志和存储引擎。

XA包括一个事务管理器，该事务管理器协调一组资源管理器，以便它们以原子单元的形式提交全局事务。
每个事务分配一个唯一的XID，由事务管理器和资源管理器使用。当在MySQL服务器内部使用时，事务管理器通常是二进制日志，资源管理器是存储引擎。

![提交XA事务的过程](/static/img/数据库/XA-commit.png)

* 在阶段1中，每个存储引擎被要求准备提交。在准备过程中，存储引擎会写入任何需要正确提交到安全存储的信息，然后返回一个OK消息。如果任何存储引擎的回答是否定的，即它不能提交事务，那么提交将被中止，所有的引擎都被指示回滚事务。
	* 在所有存储引擎都报告了它们已经准备好了没有错误的情况下，在第2阶段开始之前，事务缓存被写入到二进制日志中。与正常的事务不同，正常的事务以一个提交的普通查询事件结束，XA事务以包含Xid的Xid事件终止。
* 在第2阶段中，在第1阶段准备的所有存储引擎都被要求提交事务。当提交时，每个存储引擎将报告它已经提交了在稳定存储中的事务。
	* 重要的是要理解commit不能失败:一旦阶段1通过，存储引擎保证事务可以提交，因此不允许在第2阶段报告失败。当然，硬件故障可能导致崩溃，但由于存储引擎存储了持久存储中的信息，因此当服务器重启时，它们将能够正确地恢复。
* 在第2阶段之后，事务管理器就可以丢弃共享资源。二进制日志不需要做任何清理操作，因此在这一步中它对XA没有任何特别的作用。

如果提交XA事务的时候发生系统崩溃，服务器重启后进入恢复过程。

启动后，服务器打开上一个二进制文件并检查Format_description事件。如果binlog_in_use标记被设置，说明服务器发生了崩溃，需要进行XA恢复。

![XA恢复过程](/static/img/数据库/XA-recovery-process.png)

服务器首先检查二进制日志,通过读取Xid事件确定所有事务的XID，然后服务器中加载的存储引擎将根据这个清单来提交事务。
对于列表中的每个XID，存储引擎将判断是否准备了与XID的事务，但没有提交，如果是这样，则提交它。如果存储引擎已经准备了一个没有在这个列表中的XID的事务，那么在服务器崩溃之前，XID显然没有写入二进制日志，因此事务应该回滚。

###### 二进制日志的组提交

由于数据库系统必须能够安全应对崩溃情况，所以需要在事务提交的时候，强制将数据写回磁盘。
如果每个事务都要写磁盘会带来性能问题，为了避免这个问题，多个独立事务可以按组的形式，一起写入磁盘，这就是组提交(group commit)。  
不仅要考虑存储引擎提交事务数据的效率，还好考虑写二进制日志的效率。为此MySQL 5.6增加了二进制日志组提交（binary log group commit）。

每个事务完全提交之前增加一些步骤，每个步骤引入了一个互斥对象，确保每个步骤最多只有一个线程。

![二进制日志的组提交架构](/static/img/数据库/Binary-log-group-commit-architecture.png)

各个步骤负责处理一部分提交过程。

* 第一步将线程的事务缓存到文件页
* 第二步执行一个同步操作将文件写到磁盘
* 最后一步提交所有事务

为了以有序的方式在各个阶段之间移动会话，每个阶段都有一个相关的队列，其中会话可以排队等待处理。每个阶段队列都由在操作队列时短暂持有的互斥锁保护。

Binlog组提交阶段和互斥对象：

| Stage  | Stage mutex   | Stage queue mutex  |
| ------ | ------------- | ------------------ |
| Flush  | LOCK_log      | LOCK_flush_queue   |
| Sync   | LOCK_sync     | LOCK_sync_queue    |
| Commit | LOCK_commit   | LOCK_commit_queue  |

通常一个会话对应一个线程，在flush步骤，任何想要提交事务的会话线程会进入队列：

1. 如果会话线程排队到一个非空的队列，则它是一个follower，并将等待它的事务由其他会话线程提交。
2. 如果会话线程排队到一个空的队列，它是一个leader，并注册所有进入该队列的会话。
3. leader在一个步骤中清空队列的所有会话。会话的顺序将被维护，新的会话可以进入到队列。
4. 阶段处理完成如下:
	* 对于flush，每个会话的事务按照他们进入flush队列的顺序被flush到二进制日志。
		* 做了优化，每次“搬”一个会话，flush它。只要还有会话进入队列，就没必要处理整个队列，逐个处理能让更多会话入队。
		* binlog_max_flush_queue_time参数控制leader线程从flush队列“搬”会话的时间。
	* 对于sync，执行一个fsync调用。
	* 对于commit，事务在存储引擎中按照注册的顺序提交。
5. 这些会话将按照与此阶段注册的相同顺序排队等待下一个阶段的队列。
	* 如果队列是非空的，leader就变成了follower，但是follower不能变成leader
	* 新的leader线程会将提交过程进行到一半的旧线程合并到会话队列中，从而系统可以动态适应各种情况。

_注意事项：binlog_order_commits控制事务是否按顺序提交，如果为OFF，则平行提交事务，线程本身以任意顺序提交，而不用等待leader。_

##### 基于行的复制

基于语句的复制仍然无法正确处理：

* 如果UPDATE、DELETE或INSERT语句包含一个LIMIT子句，那么在执行过程中数据库崩溃可能会导致问题。
* 如果在执行非事务性语句时出现错误，则不能保证对主和从器的效果是相同的。
* 如果一个语句包含对UDF的调用，那么就没有办法确保对这个奴隶使用相同的值。
* 如果该语句包含任何不确定的功能——比如USER、CURRENT_USER或connection_id——结果可能会在master和slave之间有所不同。
* 如果一个语句更新了两个带有自动递增列的表，那么它将不能正常工作，因为只有一个最后的插入ID可以被复制，这将被用于两个表上的从属，而在主服务器上，每个表的插入ID将被单独使用。

上述情况下，最好复制插入表中的真实数据，这就是基于行的复制。  
基于行的复制不复制产生变更的语句，而是复制每个被插入、删除、更新的行。发给slave的行与发给存储引擎的行是一样的，包含插入表的真是数据。

基于行与基于语句复制的选择：

* 语句是否会更新大量的行，还是只做少量行的更新或插入
	* 更新大量的行，那么基于语句的复制更快，但并不总是这样，如果语句的优化和执行计划很复杂，可能基于行的复制更快，因为寻找行的逻辑快的多。
	* 如果只更新或插入少量的行，则基于行的复制更快，因为不需要解析直接交给存储引擎处理。
* 是否需要知道执行了哪些语句
	* 基于行的复制中，事件难以解码
	* 基于语句的复制中，语句被写入二进制日志中，因此可以直接读取
		* 5.6后支持产生行的语句和行一起写入日志

###### 启用基于行的复制

可以通过binlog-format选项控制使用那种格式。该参数可以作为全局变量也可以作为会话变量。
此选项可以使用值STATEMENT, MIXED, 或者 ROW。

```conf
[mysqld]
user            = mysql
pid-file        = /var/run/mysqld/mysqld.pid
socket          = /var/run/mysqld/mysqld.sock
port            = 3306
basedir         = /usr
datadir         = /var/lib/mysql
tmpdir          = /tmp
log-bin         = master-bin
log-bin-index   = master-bin.index
server-id       = 1
# 基于行复制的参数
binlog-format   = ROW
```

###### 使用混合模式

混合模式：正常情况下使用基于语句的复制，而对不安全的语句则切换到基于行的复制。

切换到行复制的情况：

* 语句调用了
	* UUID函数
	* 用户自定义函数
	* CURRENT_USER或USER函数
	* LOAD_FILE函数
* 一个语句同时更新了两个或两个以上含有AUTO_INCREMENT列的表
* 语句中使用了服务器变量
* 存储引擎不允许使用基于语句的复制，如MySQL Cluster引擎
* 后续增加的其他影响安全的因素

##### 二进制日志管理

二进制文件有多个文件组成，将它们分割成适当的组，构成一个binlog文件序列。
为了操作安全，向二进制日志添加一些特殊事件（轮换事件）。

###### 二进制日志和系统崩溃安全

如果更新没有写入二进制日志，就不会提交到存储引擎，反之亦然。

非事务引擎情况下，存储引擎在语句写入日志值钱，早就完成了所有变更；  
为了解决此问题，事件写入二进制入职的时机是表上的锁释放之前，所有变更提交给存储引擎之后。
因此如果在存储引擎释放锁之前系统崩溃，服务器必须确保写入二进制日志的变更实际存在于磁盘上的表中，然后才能提交语句或事务。
这些需要与标准文件系统之间的同步与协调。

操作系统将文件的一部分缓存在内存的某个特殊位置，通常称之为页面缓存。  
XA第一阶段后，所有数据被写入磁盘，以正确的应对崩溃。每次提交事务事，页面缓存都会被写入磁盘（实际由组提交控制）。

sync-binlog选项可以控制写入磁盘的频率，数值表示提交固定次数后写入磁盘。默认为0，由操作系统控制。

对于支持XA的存储引擎，例如InnoDB，设置sync-binlog=1,一般的系统崩溃情况下，都不会丢失任何数据。  
而不支持XA的引擎，可能会至少丢失一个事务。

###### binlog文件轮换

4种行为导致轮换：

* 服务器停止
* binlog文件大小达到最大限制
	* binlog-cache-size来控制文件大小
* 二进制日志被显式刷新
	* FLUSH LOGS命令
	* 建议使用binlog文件进行恢复前，强制执行显示刷新而不是使用活动文件
* 服务器上发生事故

Format_desc事件：

* binlog-in-use标记
	* 写入轮换事件后设置该标记
* binlog文件格式版本
* 服务器版本

为了应对崩溃时候也能安全地轮换二进制日志，服务器采用预写策略，把这个意图存到一个名为清除索引文件的临时文件中，这个文件也被用于清除binlog文件。

如`master-bin.index`对应`master-bin.~rec~`

###### 事故

指在服务器上不会产生数据变更但是必须写入二进制日志的时间，因为他们潜在的影响了复制。

二进制日志中有以下两种incident事件：

* Stop
	* 表示服务器正常停止
	* slave上重放二进制文件，将忽略任何Stop事件
* Incident
	* 表示通用的事故事件，from 5.1
	* 该事件包含一个标识符指定发生的事故类型。表明服务器被迫执行了一些操作，可能导致二进制日志变更丢失。
	* 如数据库重新装载或者非事务型事件由于过大无法写入binlog文件。
	* slave上重放二进制日志时，遇到Incident时间，就会因错误而停止。
	* 如果在集群重载时发现Incident事件，表明需要重新同步集群，很可能还要找到丢失的事件。

###### 清除binlog文件

expire-logs-days选项，服务器可以自动清除旧的binlog文件。

手动清除：

* PURGE BINARY LOGS BEFORE datetime
* PURGE BINARY LOGS TO 'filename'

如果发生崩溃，服务器通过对比清除索引文件和索引文件内容来继续清除（参考轮换部分），并删除哪些因系统崩溃而没有被删除的文件。  
清除索引文件也会在轮换时使用，因此在索引文件正确更新之前发生崩溃，新的binlog文件将被删除，然后在每次轮换时重新创建binlog文件。

##### mysqlbinlog实用工具

###### 基本用法

```sql
SHOW BINARY LOGS;
```

```shell
sudo mysqlbinlog --short-form --force-if-open --base64-output=never /var/lib/mysql1/mysqld1-bin.000038
```

文件可以指定多个

* short-form
	* 只输出发出的sql语句信息，忽略注释
* force-if-open
	* 禁止输出警告
* base64-output=never
	* 阻止输出base64编码的事件
* start-position=bytepos
	* 转储的第一个事件的字节位置，多个文件中的第一个
* stop-position=bytepos
	* 最后输出的事件的字节位置，多个文件中的最后一个
* start-datetime=datetime
* stop-datetime=datetime

**读取远程文件**

只需要服务器上有一个用于REPLICATION SLAVE权限的用户即可

使用read-from-remote-server选项读取binlog文件，参数包括歍的主机和用户、可选的端口号和密码，以及binlog文件名称

```shell
$ sudo mysqlbinlog
>    --read-from-remote-server
>    --host=master.example.com
>    --base64-output=never
>    --user=repl_user --password
>    --start-position=294
>    mysqld1-bin.000038
```

**读取日志文件的原始二进制文件**

mysqlbinlog工具不仅可以用于审查二进制日志，还可以获取binlog文件的备份。

```shell
# 文件会存储与当前目录
mysqlbinlog --raw --read-from-remote-server \
   --host=master.example.com --user=repl_user \
   master-bin.000012 master-bin.000013 ...
```

* --result-file=prefix
	* 创建写入文件的前缀，可以是目录名（反斜杠）或任何其他前缀
* --to-last-log
	* 给定开始的文件，会传送剩余的文件
* --stop-never
	* 达到一个日志文件末尾也不停止，等待更多输入。

###### 解释事件

hexdump选项告诉mysqlbinlog去写事件的市集字节。

```shell
$ sudo mysqlbinlog                       \
   >     --force-if-open                    \
   >     --hexdump                          \
   >     --base64-output=never              \
   >     /var/lib/mysql1/mysqld1-bin.000038
```

##### 二进制日志的选项和变量

* expire-log-days=days
	* 文件保留天数，重启或轮换时删除
	* 默认0，永不删除
* log-bin[=basename]
	* 开启二进制日志，及指定binlog文件的文件名
* log-bin-index[=filename]
	* 索引文件名
* log-bin-trust-function-creators
	* 废除创建存储函数时需要SPUER权限的要求
* binlog-cache-size=bytes
	* 事务缓存在内存中的部分的大小，以字节数计
	* 大事务中增加这个值可以提高性能
* max-binlog-cache-size=bytes
	* 日志文件中每个事务的大小，如果事务大小超过这个值，将出错终止，防止长时间阻塞二进制日志
* max-binlog-size=bytes
	* 每个binlog文件的大小，超过则轮换
* sync-binlog=period
	* 事务调用次数需写入磁盘的阈值，0表示由操作系统控制
* read-only
	* 阻止任何客户端进程（除了SUPER权限的slave线程和用户）更改服务器上的任何数据
	* 对于slave服务器的复制工作非常有用，可以保证slave客户端不破坏数据

###### 基于行的复制参数

binlog-format参数可以设置为以下几种模式：

* STATEMENT
	* 基于语句的复制
* ROW
	* 基于行的复制
	* DDL语句还是基于语句的复制
* MIXED
	* 以语句方式写入二进制文件，如果语句不安全，切换为基于行的复制

binlog-max-row-event-size：

指定何时开始下一个包含行的事件。由于事件在处理时被完全读入内存，该参数粗略控制那些包含行的事件的大小，保证处理行的时候不会消耗过多的内存。

binlog-rows-query-log-events (new in MySQL 5.6.2以后的版本支持，否则导致slave停止复制)：

在行事件值钱向二进制日志添加一个信息事件，这个信息事件包含产生这些行的原始查询。

_Tips：5.6.2以后的版本会忽略不支持的事件_

#### 面向高可用性的复制

确保高可用的三件事：

* 冗余
	* 如果一个组件出现故障，必须有一个替代品；替代品可以使闲置的，也可以是系统中的一部分。
* 应急计划
	* 故障后应该做什么。取决于那个组件出现故障，以及为何出现故障
* 程序
	* 必须能检测出故障原因并迅速解决

如果系统中单个组件的故障导致整个系统瘫痪，成为单点故障。如果系统中存在单点故障，就会严重限制我们实现高可用性的能力。
因此，首要目标是找到这些单点故障，确保我们做了冗余处理。

##### 冗余

一旦确定了哪里需要冗余，我们需要从两个基本方案选择：

1. 为每个组件保留副本，一旦原先的组件发生故障，副本马上接管
	* 切换时不会影响性能
	* 速度快与系统故障恢复
2. 确保系统有额外的处理能力，一旦组件出现故障时，依然可以处理负载
	* 需要更多的处理能力，如果在故障时负载满载，也就失去了继续冗余处理故障的能力
3. 这不是二选一，你可以将两者相结合

服务器发生故障的概率：

| 单点故障概率 | 1   | 2   | 3 |
| ------------ | --- | --- |--|
|1.00% | 100.00% | 49.50% | 16.17%|
|0.50% | 50.00% | 12.38% | 2.02%|
|0.10% | 10.00% | 0.50% | 0.02%|

##### 计划

* slave故障怎么处理已经存在的链接
	* 通常由应用层向另一个服务器重新尝试查询
* master故障
	* 如果有冗余的master，需要将所有的slave都移到master上

###### slave故障

负载均衡将新的查询定位到正常工作的slave，由于失去连接报错后，应用重新递交给正常工作的slave。

###### master故障

迅速替换，防止写操作中断时间过长。  
所有slave上存在过时的数据

###### relay故障

对中继服务器（relay）的故障，需要特殊处理。

剩余的slave必须重定向到其他中继服务器或master，由于添加中继服务器就是为了减轻master的负载，有可能出现master无法处理某个中继服务器上的所有slave的负载

###### 灾难恢复

不可抗拒力，多种故障同时发生。

将数据保存在另一个物理位置。

##### 方法

准备工作：

* 添加新的slave
	* 创建现有slave的快照，恢复后从合适的位置启动复制
	* 方法
		* 使用mysqldump
			* 不用关闭服务器，安全，速度慢
			* 参数可以直接获取快照位置
		* 复制数据库文件
			* 先将服务器离线，速度快
			* 需要mysqldump获取正确启动复制的位置
		* 使用在线备份方法
			* MySQL Enterprise Backup和XtraBackup
		* 使用LVM获取快照
			* Linux逻辑卷管理器（LVM）得到快照。
			* 自己管理复制位置
		* 使用文件系统快照的方法
			* 操作系统支持的快照功能
			* 自己管理复制位置
* 从拓扑结构中删除slave
	* 在负载均衡中剔除slave，然后删除它
* 切换master
	* 将连接在master上的所有slave切换到副master，然后通知负载均衡剔除原来的master
	* 另一种方法是使用slave提升
	* 热备份
* slave故障处理
	* 检测到slave不存在了就在负载均衡池中剔除
* master故障处理
	* 把slave转移到奥一个备用master上或者选择一个slave提升为master
* 升级slave
	* 需要在负载均衡中剔除后升级
* 升级master
	* 首先要升级所有的slave，这样才能读取master全部的复制事件
	* 通常升级时使用备用master或者使用slave提升的master

###### 热备份

做服务器副本最简单的拓扑结构就是热备份（hot standby）。

热备份是一个专用服务器，它是主master的副本，以slave方式连接到master，以读取和应用更新。

这种配置通常称为主-备份配置（primary-backup configuraion），可以有多个热备份。

![具有一个热备份的master](/static/img/数据库/Master-with-a-hot-standby.png)

热备份为我们提供了修复master的机会，修复master后，需要让他重新工作，要么将它设置为热备份，要么把所有的slave再重定向回来。

**主master还在运行的时候，切换到热备份**

_处理切换：_

slave从standby上开始复制的位置，同它在master上停止复制的位置，要完全一致。通常位置是不同的。

在完全相同的位置停止运行slave和standby，然后把slave重定向到standby，由于standby停止后位置没有发生变动，只需确定
standby的binlog位置，然后让slave从那个位置启动。这个任务必须手动执行，因为简单的停止无法使它们之间是同步的。

```sql
-- 检查standby和slave的状态
SHOW SLAVE STATUS;
-- 使用该命令使slave同步到相同位置
START SLAVE UNTIL
       MASTER_LOG_FILE = 'master-bin.000096',
       MASTER_LOG_POS =  756648;
-- 等待slave同步完成
SELECT MASTER_POS_WAIT('master-bin.000096',  756648);
-- standby上运行查看停止节点
SHOW MASTER STATUS;
-- 调整slave重定向到standby
CHANGE MASTER TO
       MASTER_HOST = 'standby.example.com',
       MASTER_PORT = 3306,
	   MASTER_USER = 'repl_user',
       MASTER_PASSWORD = 'xyzzy',
       MASTER_LOG_FILE = 'standby-bin.000019',
       MASTER_LOG_POS = 56447;
-- 如果slave在standby前面，则把上面某些步骤的slave和standby对调
```

```python
# 使用python处理切换
from mysql.replicant.commands import (
    fetch_slave_position,
    fetch_master_position,
    change_master,
)
def replicate_to_position(server, pos):
    server.sql("START SLAVE UNTIL MASTER_LOG_FILE=%s, MASTER_LOG_POS=%s",
               (pos.file, pos.pos))
    server.sql("SELECT MASTER_POS_WAIT(%s,%s)", (pos.file, pos.pos))
def switch_to_master(server, standby, master_pos=None):
    server.sql("STOP SLAVE")
    server.sql("STOP SLAVE")
    if master_pos is None:
        server_pos = fetch_slave_position(server)
        standby_pos = fetch_slave_position(standby)
        if server_pos < standby_pos:
            replicate_to_position(server, standby_pos)
        elif server_pos > standby_pos:
            replicate_to_position(standby, server_pos)
        master_pos = fetch_master_position(standby)
    change_master(server, standby, master_pos)
	standby.sql("START SLAVE")
    server.sql("START SLAVE")
```

###### 双主结构

两个master互相复制，保持同步。双主结构是对称的，用起来非常简单。
将故障切换到备份master上不需要重新配置主master，备用master故障时切换回来也非常简单。

服务器可以是主动的（active），也可以是被动的（passive）：  
如果是主动的，是指服务器接受写操作，这些写操作可以通过复制传播到其他地方；  
如果是被动的，只是跟随主动的master，一旦主动master发生故障可以替代它。

根据目的不同，有两种不同的配置：

* 主动-主动
	* 写操作同时到达两个服务器，然后将变更发送给对方
	* 用于不同地区的用户集同构访问地理位置较近的服务器
	* 由于事务在本地被提交，系统响应更快，这也意味着两个master不是一致的。一个master上提交的变更最终会传播到另一个master，在此之前，两个master上的数据是不一致的

* 主动-被动
	* 负责写操作的成为主动master，另外一个为被动master，与主动master保持同步
	* 和热备份差不多，很容易在两个master之间进行切换
	* 然而不需要被动master响应查询，有些方案中被动master实际是一个冷备份。

主主不同步造成两个后果需要注意：

* 如果两个master都更新了同样的信息，这两个变更之间将会产生冲突，可能会导致复制停止。
* 如果两个master不一致的时候发生了系统崩溃，有些事务将丢失。

只允许写一个master可以从一定程度上避免变更冲突的问题，从而使另一个master成为被动maaster，即主动-被动模式。

使用异步复制不可避免的结果是服务器崩溃时会丢失事务，MySQL 5.5新功能半同步复制，可以限制事务丢失的数量。  
原理是：提交线程的事务会被阻塞，直到至少一个slave确认收到这个事务。由于事务提交到存储引擎后事件才会发给slave，所以事务丢失睡昂可以控制到最多每个线程1个。

主动-被动配置的一个重要问题是，解决两台服务器同时成为主master的风险问题，有称为脑裂综合症。
如果网络连接丢失，被动master将自己提升为主动，后来主动master又重新联机，这时就会产生这个问题。  
为了阻止这个问题发生，通过一种称为STONITH的技术实现，实现有很多种，如连接到服务器然后使用`kill -9`（如果服务器可达），
关闭网卡隔离服务器，或者关掉机器电源等。如果服务器真的不可达，下次服务器又能访问的时候要使用“毒丸”让他自杀。  
处理脑裂综合症为题依赖于使用共享磁盘解决方案，如SCSI支持服务器预留磁盘，服务器发现磁盘被另一个服务器预留，意识到自己不再是primary，就把自己离线。

**共享磁盘**

![使用共享磁盘的双主结构](/static/img/数据库/Dual-masters-using-a-shared-disk.png)

忧点：不用切换binlog的位置，master切换速度很快，只需要记住slave停止的位置，执行CHANGE MASTER命令，然后再次启动复制。

问题：要确保两个master不会同时写文件，在被动master上执行任务时必须小心，重写配置文件，哪怕时失误，都可能时灾难性的。只读模式仍然不够，因为InnoDB处于只读模式还是会写文件。

**使用DRBD（分布式复制块设备）复制磁盘**

行为和外观上和正常磁盘一样，不需要mysql做特殊配置。

![Using-DRBD-to-replicate-disks](/static/img/数据库/Using-DRBD-to-replicate-disks.png)

只能在主动-被动配置中使用DRBD技术，被动磁盘完全不能访问，被动master也不能访问。  
切换速度比共享磁盘方案慢。  
和共享磁盘相同，需要在服务器联机之前恢复数据库文件，所以建议使用恢复性能搞的事务性引擎，MyISAM表的恢复成本相当高，InnoDB是一个好选择。

相对于共享磁盘方案的优点：

* 避免了磁盘的单点故障。
* DRBD还内置了脑裂综合症问题的解决反感，可以配置为自动恢复

**双向复制**

双向复制可以邮主动-主动配置，也可以使用在主动-被动结构中。

![Bidirectional-replication](/static/img/数据库/Bidirectional-replication.png)

配置双向复制的步骤：

1. 确保两台服务器拥有不同的服务器Id
2. 确保两台服务器具有不同的数据（并且在复制启动之前量个系统没有变更）
	* 确定复制的数据没有冲突
3. 创建一个复制用户，在两台服务器上准备复制，参考《复制》部分
4. 在两台服务器上准备复制

如果要把一个slave连接到其中一个服务器，要启用log-slave-updates选项。（使用服务器ID跳过自己发出的事件被重复传播回来的问题）

主动-主动配置的唯一推荐的方法，是保证不同的主动服务器写不同的区域

方案之一是为不同的master分配不同的数据库（或者不同的表），如使用视图连接不同的表。以下问题使管理变的复杂：

* 对不同的表进行读写
	* 应用程序将读写分离，从表写入，从表或视图读取
* 准确数据和当前数据
	* 快照数据不准确，要求准确信息要依赖于应用程序
* 优化视图
	* 利用创建视图和结果集有两个方法，MERGE和TEMPTABLE
	* 对视图做仔细设计是获得良好性能的因素

如果更新同一张表，MySQL服务器设了两个变量用于处理这种情况(会话的或者是全局的)。

* auto_increment_offset
* aotu_increment_increment

```shell
value = auto_increment_offset + N * aotu_increment_increment
```

```sql
-- The common table can be created on either server
CREATE TABLE Employee (
   uid INT AUTO_INCREMENT PRIMARY KEY,
   name VARCHAR(20),
   office VARCHAR(20)
);
-- Setting for first master
SET GLOBAL AUTO_INCREMENT_INCREMENT = 2;
SET GLOBAL AUTO_INCREMENT_OFFSET = 1;
-- Setting for second master
SET GLOBAL AUTO_INCREMENT_INCREMENT = 2;
SET GLOBAL AUTO_INCREMENT_OFFSET = 2;
```

_注意事项：使用这种方法应该控制对应序列Id的处理发送给正确的服务器，否则会导致不一致问题，一种可行方案是划分表权限，但并不总是可行_

###### 提升slave

如果备用服务器之后与任何一个slave，就不能使用备用服务器作为master

提升slave处理master故障的方法：不是保持一个专门的备用服务器（当然也就没有最佳候选备用），
而是确保任何一个连接到master的slave都能被提升为master，并且从master故障的位置接管。
选择“知道最多”的slave成为master，将他妈呢连接到新的master，然后从新的master上读取事件。

**提升slave的传统方法**

![提升slave替代故障的master](/static/img/数据库/Promoting-a-slave-to-replace-a-failed-master.png)

要求：

* 每个可提升的slave必须有一个复制用户账户
* 每个可提升的slave运行时必须使用log-bin选项，即启动二进制日志
* 每个可提升的slave运行时必须不适用log-slave-updates选项

步骤：

1. 使用STOP SLAVE停止slave
2. 使用RESET MASTER重置迹象成为新master的slave。slave将以master身份启动，其他连接的slave从提升的那个时刻开始读取事件
3. 使用CHANGE MASTER将其他slave连接到新的master上。由于重置了新的master，直接从二进制的七点开始复制，不需要额外的位置参数。

每个slave都需要获取丢失的事务，如果slave没有启动二进制日志，可以复制整个库或使用类似mysqldbcompare的工具获取变更。

_注意事项：大多数情况下，传统方法并不适用，因为slave往往落后于master_

**提升slave的修正方法**

![Binary-log-positions-of-the-master-and-the-connected-slaves](/static/img/数据库/Binary-log-positions-of-the-master-and-the-connected-slaves.png)

即使知道最多的那个slave，也没有从故障master那里获得全部变更。没有复制到新master的变更将丢失。5.6引入了GTID就不存在这个问题，或者实现一个类似GTID的机制。

**环形复制**

环形复制：所有用户数据被复制到所有站点，所有的数据中心都可以进行数据更新。

由于slave只能连接一个master，所以两个以上master互相复制，只能以环形的方式搭建。

MySQL 5.6引入了全局事务ID后，很多不推荐环形复制的原因都失效了，其中一个主要原因是一旦发生故障系统将无法运行。

![Circular-replication-setup](/static/img/数据库/Circular-replication-setup.png)

某台服务器出现故障，其他服务器重新连接至上游服务器，使得复制继续。有三个问题：

* 下游服务器需要连接上游服务器，并且从最近的位置开始复制，怎么确定位置
* 故障服务器崩溃前发出了一些事件，这些事件怎么处理
* 怎样把故障服务器重新接入拓扑结构，以及写入日志而为发出的事件丢失问题或者在接入时被重新发送

![Changing-topology-in-response-to-a-failing-server](/static/img/数据库/Changing-topology-in-response-to-a-failing-server.png)

所有问题可以通过全局事务标识符解决，使用CHANGE MASTER命令加上MASTER_AUTO_POSITION=1选项，将下游服务器连接到上游服务器。

```sql
CHANGE MASTER TO MASTER_HOST='stockholm.example.com', MASTER_AUTO_POSITION = 1;
```

由于每个服务器都有事务记录，故障服务器发出的任何事务都会在剩余的每个服务器上执行一次，问题2和3丢失问题自动解决了。  
将服务器恢复到环中的方式是，从环中任意一台服务器恢复，然后接入环中，防止重新发送。

#### 面向横向扩展的MySQL复制

当负载开始增加，有两种解决办法：

* 第一种方法时购买更大的服务器来应对增加的负载，成为纵向扩展（或向上扩展，scale up）
* 第二种方法时添加更多的服务器，成为横向扩展（或向外扩展，scale out）
	* 更常用，只需购买低成本的标准服务器，更具有成本效益
	* 添加服务器不仅可以处理增加的负载，还可以支持高可用性及其他商业要求。如果有效使用，可以综合并利用所有的服务器资源

横向扩展和复制的常见用途：

* 读操作的负载均衡
	* master忙于更新数据，所以将响应查询的服务器分离出来
* 写操作的负载均衡
	* 高流量的部署将处理分发到很多计算机上，复制在分发信息的过程中起着关键作用。
		* 基于信息角色的分发。很少更新的表在一个服务器上，频繁更新的表分割到多个服务器上
		* 按地理区域分割，这样流量可以直接定向到最近的服务器
* 通过热备份进行灾难避免
	* 通过slave热备份防止master单点故障
* 通过远程复制进行灾难避免
	* 远程数据中心之间进行数据传输
* 制作备份
	* 备份服务器离线，然后备份
* 生成报表
	* 离线一个slave产生报表
* 过滤或分区数据
	* 如果网络连接很慢，或者有些数据对某些客户端不可用，可以添加一个服务器进行数据过滤
	* 同样适用于将数据区分到独立的服务器

##### 横向扩展读操作

横向扩展只能扩展读操作，而不是写操作。写操作使用分片技术扩展

单个服务器每秒有10000个事务，master每秒的写负载为4000个事务，而每秒的读事务为6000个：

![average-load-before](/static/img/数据库/average-load-before.png)

添加三个slave，每秒的总负载量就增加到40000个，由于写操作也会被复制，每个写操作都会执行4次（1次master，3个slave 3次），读取负载被分发到各个slave，总的读负载没有增加：

![average-load-before](/static/img/数据库/average-load-after.png)

##### 异步复制的价值

异步复制比同步复制快的多，同步需要额外的同步机制来保持一致性，一般通过两段提交协议来实现。
两端提交协议保证了master和slave之间的一致性，但却需要他们之间有额外的通信消息传递。工作流程如下：

1. 当执行commit语句时，事务被发送给slave，而slave被要求准备提交。
2. 每个slave都准备事务，以便提交，然后向master发送一个OK(或ABORT)消息，表示事务已经准备好(或者是不能准备的)。
3. master等待所有的slave发送OK或ABORT消息:
	* 如果master从所有的slave那里收到了一个OK的信息，它会向所有的slave发送一个提交信息，要求他们提交交易。
	* 如果master收到来自任何一个slave的中止消息，它会向所有的slave发送一个中止消息，请求他们中止交易。
4. 然后，每个slave都在等待master的一个OK或ABORT消息。
	* 如果slave收到提交请求，他们就提交事务并向master发送确认该事务是提交的。
	* 如果slave收到中止请求，他们会取消任何更改并释放他们所持有的任何资源，从而中止事务，然后向master发送确认该事务被中止。
5. 当master服务器收到来自所有slave的确认时，它会将事务报告为提交(或中止)并继续处理下一个事务。

这个协议之所以慢，是因为它一共需要4次消息传递，准备及确认和终止或提交及确认。
主要问题不在于处理同步的网络流量，而是由于网络和slave提交产生的延迟，而且master的提交会被阻塞直到所有的slave确认事务。  
而异步复制只需要一条消息即可，master不需要等待slave，就可以立即报告事务的提交，从而极大的提高了性能。

| 网络延迟 (ms) | 事务提交时间 (ms) | 每秒提交的事务数量 | 示例                 |
| ------------- | ----------------- | ------------------ | -------------------- |
| 0.01          | 0.14              | ~7,100             | Same computer        |
| 0.1           | 0.5               | ~2,000             | Small LAN            |
| 1             | 4.1               | ~240               | Bigger LAN           |
| 10            | 40.1              | ~25                | Metropolitan network |
| 100           | 400.1             | ~2                 | Satellite            |

而异步就像没有slave一样。是以一致性为代价换取性能。

* 如果master出现故障，事务就会消失
* slave上执行的查询可能会返回旧数据

##### 管理复制拓扑

简单拓扑、树形拓扑、双主拓扑和环形拓扑：

![Simple-tree-dual-master-and-circular-replication-topologies](/static/img/数据库/Simple-tree-dual-master-and-circular-replication-topologies.png)

* 双主拓扑用来处理故障转义，环形复制和双主结构允许各个站点在本地运行的同时还能将变更复制到其他站点
* 简单拓扑和树形拓扑用于横向扩展

复制的使用导致读取的数量大大超过写入的数量，这种部署有两种特殊要求：

* 需要负载均衡
	* 写操作交给master
	* 读操作交给slave
	* 特定的查询发给特定的slave
* 需要管理拓扑
	* 应对master或者slave崩溃的情况

为了处理负载均衡更加高效，服务器要保留空闲处理能力：

* 峰值负载的处理
	* 要有余力处理峰值负载，需要密切监控应用以确定什么时候响应时间变慢
* 分布成本
	* 要有空闲处理能力来运行复制，包括管理分布式系统所需的额外查询
	* 每个slave上的写操作和master一样，slave需要一些处理能力来完成复制
* 管理性任务
	* 重新建立复制需要有空闲处理能力，如在服务器之间移动数据的时候重建复制

两种情况处理负载均衡：

* 应用程序根据查询类型请求服务器
* 中间层（通常指代理）分析查询，然后发给适当的服务器

使用中间层分析和分发查询是目前最灵活的方式，但有两点不足：

* 代理导致性能下降
	* 分析查询消耗资源
	* 查询多了一次节点转移，查询被分析两次一次是代理，一次是MySQL
* 正确的查询分析很难实现，有时甚至不可能实现

![Using-a-proxy-to-distribute-queries](/static/img/数据库/Using-a-proxy-to-distribute-queries.png)

###### 应用层的负载均衡

应用程序根据要发出的查询类型向负载均衡服务器请求链接。

应用层的负载均衡需要一个中心存储，存储服务器信息以及这些服务器能够进行哪些查询。

![Load-balancing-on-the-application-level](/static/img/数据库/Load-balancing-on-the-application-level.png)

##### 级联复制

从实践上说，一个master可以处理70个slave，但很大程度上取决于应用程序，master无响应永远是个问题。  
这时候需要添加一个或多个额外的slave作为中继slave（或简称中继服务器，relay），其目的事通过管理一群slave来减轻slave上的复制负载。这种使用中继的方式成为级联复制。

包括一个master、一个relay和若干个连接到relay的slave

![Hierarchical-topology-with-master-relay-and-slaves](/static/img/数据库/Hierarchical-topology-with-master-relay-and-slaves.png)

默认情况下，slave从master那里得到的变更不会写入slave的二进制日志中，如果出现问题，总是可以通过克隆master或另一个slave来恢复它  
另一方面，relay需要进行二进制日志记录所有变更，因为relay需要把变更传给其他slave。与slave不同的是，relay不需要应用这些变更，因为它不响应任何查询。

为此，建立一个Blackhole的存储引擎，它接受所有语句，总是报告语句执行成功，单丢弃任何数据变更。

relay引入了额外延迟，slave滞后master的程度比直接连接master的时候还多。

###### 配置relay

1. 将slave配置成发送任何slave线程执行的事件，并将这些事件写入relay的binlog
	* 主配置文件中配置log-slave-updates选项
2. 将relay上所有表的存储引擎都改成BLACKHOLE存储引擎，保留空间并提高性能
	* SET SQL_LOG_BIN=0;
	* ALTER TABLE user_data ENGINE='BLACKHOLE';
	* SET SQL_LOG_BIN=1;
3. 保证relay上的所有新表都使用BALCKHOLLE引擎
	* 主配置文件中配置default-storage-engine更改默认存储引擎
	* 通过命令SET STORAGE_ENGINE='BLACKHOLE'可暂时修改，重启无效

引入relay：

1. 将relay连接到master，并将其角色配置为relay
2. 一次将slave的连接切换到relay

##### 专用slave

将访问很少的数据放到每个slave上是一种资源浪费。为此需要在复制的之后分离表，MySQL通过过滤事件实现，在事件离开master或到达slave的时候过滤它们。

master和专用slave的复制拓扑：

![Replication-topology-with-master-and-specialized-slaves](/static/img/数据库/Replication-topology-with-master-and-specialized-slaves.png)

###### 过滤复制事件

1. 在master上过滤事件，称为master过滤器
	* 控制哪些被写入二进制日志以及哪些被发送给slave
2. 在slave上过滤事件，称为slave过滤器
	* 控制哪些被执行

如果使用master过滤，意味着无法使用PITR正确的恢复数据库，备份可以恢复，而之后的变更无法恢复，因为二进制日志中没有记录这些变更。  
如果使用slave过滤器，所有变更都会通过网络传输，浪费带宽。

**master过滤器**

创建master过滤器需要两个选项，不推荐同时使用。不接受多个参数但是可以重复使用。

* binlog-do-db=db
	* 如果当前库是db，则写入binlog
* binlog-ignore-db=db
	* 如果当前库是db，则忽略

**slave过滤器**

可以基于数据库的过滤，还可以过滤单个表，甚至使用通配符过滤一组表。

* replicate-do-db=db
* replicate-ignore-db=db
* replicate-do-table=db_name.tbl_name
* replicate-wild-do-table=db_pattern.tbl_pattern
* replicate-ignore-table=db_name.tbl_name
* replicate-wild-ignore-table=db_pattern.tbl_pattern

pattern可以使用`_`和`%`匹配

###### 使用过滤将时间分配给slave

master过滤的问题：

* 因为事件是从二进制日志中过滤出来的，而且只有一个二进制日志，所以不可能“切分”更改，并将数据库的不同部分发送到不同的服务器。
* 二进制日志也用于PITR，因此如果服务器存在任何问题，就不可能恢复所有内容。
* 如果由于某种原因，需要以不同的方式分割数据，那么它将不再可能，因为二进制日志已经被过滤，不能“撤销过滤”。

如果担心流量问题，可以在master上配置一个relay，保留master二进制日志的过滤后的版本。

![Filtering-by-putting-master-and-relay-on-the-same-machine](/static/img/数据库/Filtering-by-putting-master-and-relay-on-the-same-machine.png)

##### 数据一致性管理

为了避免数据过于陈旧，要保证slave提供的是有用的最新数据。如果还要添加relay，问题就更加棘手。  
解决的基本思路是在master上提交的事务做个标记，等slave渠道这个事务的时候（或更晚），才在slave上执行查询

MySQL 5.6引入了全局事务标识符（GTID）,slave和客户端的故障转移变得简单多了，因为大多数问题都可以自动处理了。  
5.6之前，是否存在relay服务器，有不同的解决办法。

###### 非级联部署的一致性

使用SHOW MASTER STATUS获取masster的binlog位置，然后在slave上调用MASTER_POS_WAIT函数等待slave到达位置。

###### 级联部署的一致性

由于每个中间的中继服务器都会更改binlog位置，所以无法等待master位置到达最终slave。

* 利用自定义全局事务标识符来提升slave，并反复轮询slave有没有处理过这个事务。
	* 与5.6的全局事务标识符不同，这里没有wait函数，需要轮询
	* 如果master和slave基本同步，时间较短，只需关心最终slave即可
* 用MASTER_POS_WAIT函数将从master到最终slave路径上的所有relay都连接起来，保证所有变化都能传递到slave。
	* 如果slave大多是滞后的，等待复制树向下扩散，然后执行查询。避免轮询间隔过大导致响应性问题。
	* 应用程序代码需要访问relay
	* 应用程序需要知道复制架构

![Synchronizing-with-all-servers-in-a-relay-chain](/static/img/数据库/Synchronizing-with-all-servers-in-a-relay-chain.png)

5.6以后，使用WAIT_UNTIL_SQL_THREAD_AFTER_GTIDS函数代替MASTER_POS_WAIT

```sql
SELECT WAIT_UNTIL_SQL_THREAD_AFTER_GTIDS($gtids)
```

#### 数据分片

将数据库分割有两种方法：

* 将某些表分别放在不同的机器上，又称为功能分割
* 将某些表分割成不同的行分别存储在不同的机器上，成为水平分割

##### 什么是数据分片

双主结构并不能扩展写操作，因为所有的写操作都会被复制并执行两次。  
最直接的办法就是服务器之间不再有复制机制，这样他们就是完全分离的。
这样就可以将数据分成两个完全独立的子集，然后将客户端定向到它试图变更的数据所在的分区，从而实现扩展写操作。  
此次更新处理并不需要其他的分片消耗资源。这种分割数据的方式通常称为分片（sharding，又称水平分割）。每个分区成为一个分片。

###### 为什么分片

分片的原因取决于应用程序的巨大压力。分片的好处（原因）：

* 将数据放在地理位置接近用户的位置。
	* 减少延迟，提升性能
* 减少工作集（working set）的大小。
	* 如果表比较小，大部分数据甚至整张表可以装入内存
	* 检索表的算法在表较小的时候更有效
* 分发工作
	* 将工作并行化

并不是所有数据都需要分片：

* 可以将某些大表附近进行拆分，然后在每个分片上对小表做全量副本（这些通常是全局表）
* 可以同时使用分片和功能分割，对庞大的数据做分片（文章、评论），而将索引数据（如用户和目录）放在不分片的中心存储

带有中心数据库的分片：

![Shards-with-a-centralized-database](/static/img/数据库/Shards-with-a-centralized-database.png)

###### 分片的局限性

分片可以提高性能，也有一些局限性

挑战是确保所有查询在向未分片的数据库和分片数据库执行时给出相同的结果。
如果您的查询访问多个表(通常是这样的情况)，必须确保对未分片的数据库和分片数据库得到相同的结果。
这意必须选择一个分片索引，以确保查询在共享或不共享的数据库中得到相同的结果。

**跨分片连接**

* 以map-reduce的方式执行查询，即将查询发送到所有分片，然后将查询结果收集到单个结果集中
	* 需要占用一定的服务资源，需要监控资源占用
* 将所有分片复制到某个单独的报表服务器，然后在报表服务器上运行查询
	* 简单的复制，一般采用这种方法完成报表

**使用AUTO_INCREMENT**

分片不同步AUTO_INCREMENT标识符。

如果需要一个唯一标识符，有两种方法：

* 生成一个唯一的UUID
	* 缺点是占用128个比特位，也存在极小的可能重复
* 使用符合标识符（composite identifier），前半部分是分片标识符，后半部分是本地生成的标识符（比如AUTO_INCREMENT生成的）
	* 除了AUTO_INCREMENT列以外，还要增加一列用于维护分片标识符

复合关键字：

![A-composite-key](/static/img/数据库/A-composite-key.png)

##### 分片方案的要素

如何分布数据以及如何有效地对数据进行重新分片：

* 确定如何为应用数据分区
	* 哪些表应该分割
	* 哪些表在所有分片上都应该有
	* 应该在什么列上进行分片
* 确定需要什么分片元数据以及如何管理元数据
	* 如何将分片分配到MySQL服务器
	* 如果将分片关键字映射到分片
	* 分片数据库需要存储哪些数据
* 确定如何分发查询
	* 如何获取分片关键字将查询和事务定向到正确的分片
* 创建分片管理的模式
	* 如何监控分片负载
	* 如何迁移分片
	* 如何通过数据分割和合并分片使系统重新负载均衡

###### 高级分片架构

查询来自应用程序，并由broker接收。broker决定发送查询到哪里，可能需要根据一个记录分片信息的分片数据库来决定。
然后将查询发送到应用程序数据库的一个或多个分片并执行。执行的结果集由broker收集，有可能对结果集进行处理，然后再发送回应用程序。

![High-level-sharding-architecture](/static/img/数据库/High-level-sharding-architecture.png)

##### 数据分区

高效的数据检索同样重要，为此，需要将相关数据放在一起。因此，高效分片的最大挑战是创建一个高效的分片索引（sharding index），使经常一起访问的数据落在一个分片上。

分片索引是定义在多个表的多个列之上的，通常每个表只用一个列（一般为主键，也便于做再次分割），也可以每个表多个列（不便于维护）。分片索引决定哪些表需要分片，以及怎样分片。

数据库表：

| Table        | Rows    |
| ------------ | ------- |
| departments  | 9       |
| dept_emp     | 331603  |
| dept_manager | 24      |
| employees    | 300024  |
| salaries     | 2844047 |
| titles       | 443308  |

![Employee schema](/static/img/数据库/Employee-schema.png)

带有分片表和全局表的模式：

![Schema-with-sharded-and-global-tables](/static/img/数据库/Schema-with-sharded-and-global-tables.png)

分片索引取决于你要做怎样的查询，以及表之间的依赖关系和记录行数。

使用MySQL的information_schema模式，能够计算出相关列上所有可能的分片索引。

```sql
USE information_schema;
SELECT
   GROUP_CONCAT(
     CONCAT_WS('.', table_schema, table_name, column_name)
   ) AS indexes
FROM
   key_column_usage JOIN table_constraints
      USING (table_schema, table_name, constraint_name)
WHERE
   constraint_type = 'FOREIGN KEY'
GROUP BY
   referenced_table_schema,
   referenced_table_name,
   referenced_column_name
ORDER BY
   table_schema, table_name, column_name;
```

在上述结构中使用查询得到两个分片索引：

| Candidate #1        | Candidate #2         |
| ------------------- | -------------------- |
| salaries.emp_no     | dept_manager.dept_no |
| dept_manager.emp_no | dept_emp.dept_no     |
| dept_emp.emp_no     |                      |
| titles.emp_no       |                      |

向结构中添加出版物表，与员工为多对多关系。

![Publication-schema-added-to-employees-schema](/static/img/数据库/Publication-schema-added-to-employees-schema.png)

department表仍然在所有节点上，也有新增表的外键参照，可以对新增表进行分片。这样就存在多个独立的分片索引了。

这也引入了一个问题，可以独立的分别查询两个分片索引的多表查询，而不能执行跨分片索引的连接查询。

分片索引及列：

| Index name  | Sharding column set                                                                    |
| ----------- | -------------------------------------------------------------------------------------- |
| si_emps     | employees.emp_no, dept_emp.emp_no, salaries.emp_no, dept_manager.emp_no, titles.emp_no |
| si_pubs     | publications.pub_id, dept_pub.pub_id                                                   |

###### 分配分片

要有效地使用shards，您需要以一种加速物理访问的方式存储它们。
最直接的方法是每个服务器保留一个shard，但是也可以在每个服务器上保留多个虚拟分片。

怎样分配分片：

* 应用程序使用跨schema的查询吗
	* 单个schema比较容易，可以在一个服务器上存储多个分片，每个分片保存一个schema，也不需要重写查询
* 查询根据分片方案调整吗
	* 可以要求开发者在写查询的时候考虑分片方案，就仍然能够在一个服务器上存储多个分片
	* 这样就可以以一种可控的方式重写查询，比如可以在所有数据名字后面加上分片号作为后缀
* 需要常常重新分片吗
	* 如果重写查询并不容易，或是要求开发者以某种特定的方式写查询，就必须一个服务器保存一个分片，因为这些查询可能是跨schema的
	* 如果要常常重新分片，一个服务器一个分片可能带来性能瓶颈，但是一个服务器保存多个分片也是可能的，能够在服务器之间迁移分片以达到负载均衡，但是如果某个分片成为热点，可能还是需要继续分片
* 如何备份分片
	* 用于备份和迁移
	* 多数备份方法都是对整个服务器或一个（多个）模式创建备份，所以要谨慎确保某个模式整体保存在同一个分片中（但是一个分片中可能有多个模式）。

**每个服务器一个分片**

最直接的方法是每个服务器上保存一个分片，这种情况允许跨模式查询，所以不需要重写查询。

缺点：

1. 多个表可能超出服务器的主存大小，从而影响性能
	* 打破了小表可以装入内存的性能优势
2. 如果需要对做这些表进行重新分片的话，那么服务器之间负载均衡操作更加昂贵

如果某个服务器过载需要减轻负载，方案是：

分割分片，要么用一个备用服务器创建一个新的分片，要么把那些不相干的行迁移到另一个分片

如果把行迁移到另一个分片，而且每个服务器只有一个分片，迁移过来的行必须与分片上已有的行合并，合并很难联机完成，在一个服务器一个分片的情况下，分割和重新合并操作很昂贵。

**每个服务器多个分片（虚拟分片）**

如果能够在单个机器上保存多个分片，数据就能够更加高效的在服务器之间迁移，因为数据已经是分片的。
但是，这么做就要区分一台服务器上的不同分片。

常用的方法是在模式名上附加分片标识符，如employees_1，表也可以增加分片名后缀employees_1.dept_emp_1。  
如果不跨schema，可以通过USE employee_1来解决模式名后缀的问题而不重写查询，但是跨模式就需要重写查询。重写可以借助代理中间件实现。

由于每个模式存储在不同目录下，大多数备份都可以多模式进行备份，但是备份单个表就会有问题。
只需将不同分片的表分别存放在不同的目录，就很容易应对分片备份。
可以将replicate-do-db限定为服务器上的某个模式，把变更复制到单个分片上，这在服务器之间迁移分片非常有用。

在一个服务器上保存多个分片，就可以通过迁移分片减轻负载。并且不需要合并分片。

##### 映射分片关键字

计算正确的分片需要哪些分片元数据，以及怎样将已分片的表映射到实际分片上。

###### 分片方案

分区函数可以通过静态分片方案或者动态分片方案来实现。

* 静态分片方案
	* 在静态分片方案中，通常通过固定不变的分配方法将分片关键字映射到分片标识符
	* 计算通常由连接器或应用程序完成，非常高效
* 动态分片方案
	* 分片关键字通过字典查询，该字典表明哪个分片包含数据。
	* 这种方案比静态分片更加灵活，但是需要一个中心存储，称为分片数据库

**静态分片方案**

如果查询分布不均，静态分片方案会遇到问题。如果哈希分布不好，也会产生这种问题。  
所以选择合适的分区关键字和区分函数非常重要。

**动态分片方案**

动态分片方案非常灵活，不仅允许更改分片位置，如果需要迁移数据，也很容易实现。  
动态方案计算分片的时候需要一些额外的查询，增加了复杂度，也会影响性能。增加缓存以缓解。

将分片数据库以一组表的形式保存在一个分片服务器上的MySQL数据库中。

* 包含每个分片信息的locations表
* 包含每个分区函数信息的partition_function表

```sql
CREATE TABLE locations (
       shard_id INT AUTO_INCREMENT,
       host VARCHAR(64),
       port INT UNSIGNED DEFAULT 3306,
       PRIMARY KEY (shard_id)
);

CREATE TABLE partition_functions (
       func_id INT AUTO_INCREMENT,
       sharding_type ENUM('RANGE','HASH','LIST'),
       PRIMARY KEY (func_id)
);
```

###### 分片映射函数

* 列表映射
	* 根据分片列中的一组不同的值，将行分布在分片上。例如，这个列表可以是一个国家列表。
	* 容易实现，不能有效分摊负载，适合分区域
* 区间映射
	* 根据分片列在一个范围内的位置，行分布在分片上。当您在ID列、日期或其他信息上很方便地进入范围时，这是很方便的。
	* 消除了某些分摊负载问题，但是很难达到负载均衡
* 散列映射
	* 根据分片键值的散列值，将行分布在分片上。这在理论上提供了最均匀的数据分布。
	* 最有效负载均衡的，但是最难有效实现

每个分片映射都要考虑两个问题：如何添加新的分片，以及如何根据分片关键字选择正确的分片。

**区间映射**

虽然容易实现，问题是区间可能变的零碎，并且要求数据有效支持区间。

创建索引表：包含区间和映射信息的表，并将这些区间映射到分片标识符

```sql
CREATE TABLE ranges (
       shard_id INT,
       func_id INT,
       lower_bound INT,
       UNIQUE INDEX (lower_bound),
       FOREIGN KEY (shard_id)
           REFERENCES locations(shard_id),
       FOREIGN KEY (func_id)
           REFERENCES partition_functions(func_id)
)
```

区间映射表区间：

| Lower bound  | Key ID   | Shard ID  |
| ------------ | -------- | --------- |
| 0            | 0        | 1         |
| 1000         | 0        | 2         |
| 5500         | 0        | 4         |
| 7000         | 0        | 3         |

添加新的分片：向ranges表和locations表分别插入一行

```sql
INSERT INTO locations(host) VALUES ('shard-1.example.com');
SET @shard_id = LAST_INSERT_ID();
INSERT INTO ranges VALUES (@shard_id, @func_id, 1000);
```

获取分片：使用查询获取分片

```sql
-- ？替换为分区关键字，另一种选择是存储上边界，但是更新分片数据库就会变得复杂
SELECT shard_id, hostname, port
  FROM ranges JOIN locations USING (shard_id)
 WHERE func_id = 0 AND ? >= ranges.lower_bound
ORDER BY ranges.lower_bound DESC
LIMIT 1;
```

**哈希映射与一致性哈希**

适合应对数据热点无法分散，某个分片过载而导致需要分割分片问题。

![Hash-ring-used-for-consistent-hashing](/static/img/数据库/Hash-ring-used-for-consistent-hashing.png)

常用的密码哈希函数：

提供一个包含大量比特位的哈希值，以及将输入字符串平均分布到输出区间。

| Hash function  | Output size (bits)  |
| -------------- | ------------------- |
| MD5            | 128                 |
| SHA-1          | 160                 |
| SHA-256        | 256                 |
| SHA-512        | 512                 |

创建索引表：

```sql
-- 添加索引加速检索哈希值
CREATE TABLE hashes (
    shard_id INT,
    func_id INT,
    hash BINARY(32),
    UNIQUE INDEX (hash)
    FOREIGN KEY (shard_id)
        REFERENCES locations(shard_id),
    FOREIGN KEY (func_id)
        REFERENCES partition_functions(func_id)
)
```

table hashes：

| Key ID  | Shard ID   | Hash                             |
| ------- | ---------- | -------------------------------- |
| 1       | 0          | dfd59508d347f5e4ba41defcb973d9de |
| 2       | 0          | 2e7d453c8d2f9d2b75a421569f758da0 |
| 3       | 0          | 468934ac4c69302a77cbe5e7fa7dcb13 |
| 4       | 0          | 47a9ae8f8b8d5127fc6cc46b730f4f22 |

添加分片：向locations和hashes各插入一行

```sql
INSERT INTO locations(host) VALUES ('shard-1.example.com');
SET @shard_id = LAST_INSERT_ID();
INSERT INTO hashes VALUES (@shard_id, @func_id, MD5('shard-1.example.com'));
```

获取分片：根据分片关键字查找分片位置，计算分片关键字的哈希值，然后招待小小于这个哈希值的最大哈希值对应的分片标识符，如果没有，就选最大的哈希值。

```sql
(
  SELECT shard_id FROM hashes 
  WHERE MD5(sharding key) > hash
  ORDER BY hash DESC
) UNION ALL (
  SELECT shard_id FROM shard_hashes 
  WHERE hash = (SELECT MAX(hash) from hashes)
) LIMIT 1
```

##### 处理查询和事务调度

* 如何将事务分配到合适的分片
* 如何获取事务的分片关键字
* 如何使用缓存提高性能

broker可以是中间代理，或者由连接器实现，看上去是一个透明的方案，但是实际不是，在处理事务时，使用代理需要扩展协议，而且（或者）会限制应用程序。

###### 处理事务

broker需要知道待处理事务的参数。

从应用程序的角度看，每个事务包含一个查询序列或语句序列，其中最后一个语句时提交或中止。

```sql
-- 开启事务
START TRANSACTION; 
-- 读写事务体
SELECT salary INTO @s FROM salaries WHERE emp_no = 20101; 
SET @s = 1.1 * @s; 
INSERT INTO salaries(emp_no, salary) VALUES (20101, @s); 
-- 提交
COMMIT; 
START TRANSACTION; 
INSERT INTO …;
COMMIT;
```

代理需要处理以下几个问题：

* 为了把事务事务发送到正确的分片，broker必须在看到事务的第一个语句的时候就知道分片关键字
	* 可以约定在第一局中暴漏关键字，但是容易出错
	* 事务的第一个语句显示提供分片关键字，特定的注释或者允许broker接收频带外的分片关键字（即不作为查询的一部分）
* 必须在第一个语句发送到服务器值钱，知道事务事读事务还是写事务
	* 将事务标记为读写事务或者只读事务，在查询中加入特殊的注释或者将这个信息带外发送给broker
* 能够推断是否处于某个事务内部，而且同一个事务的下一个语句应该使用相同的链接
	* SERVER_STATUS_IN_TRANS和SERVER_STATUS_AUTOCOMMIT在5.6中被增加。
	* 如果事务通过START TRANSACTION开始，第一个标记为真；如果AUTOCOMMIT=0;就不设置标记。
	* 如果设置了自动提交，就设置SERVER_STATUS_AUTOCOMMIT；否则清空标记
	* 联合使用两个标记，就能知道某个语句是否是事务的一部分，以及下一个语句是否应该使用相同的连接。
	* 但是连接器不支持，只能在broker中跟踪
* 能够看到上一个语句是否提交了某个事务，从而确定是否切换到另一个连接
	* 需要监控，还要考虑语句隐式提交事务问题
* 确定如何处理会话特定的状态信息，比如用户自定义变量、临时表以及服务器变量的特定设置等。

1、2两个问题需要检测用户是否发送出错。MySQL 5.6添加了START TRANSACTION READONLY，保证程序不会接受更新语句。  
检查分片如果使用分片名区分则很容易，否则需要引入类似断言的功能。

###### 分配查询

在分片环境中处理事务是极不透明的，应用程序必须考虑是否使用分片的数据库。考虑分配查询帮助应用开发者使用

如果查询中给出了需要访问的表，就可以推导出函数标识符，而不需要开发者提供。
此外，还可以检查这个查询是否真的只访问基于该分区函数分区的表，可能需要参考一些全局表的信息。

需要引入一个新的表，保存从表到分区函数的映射。

```sql
-- 记录各个表及其分区函数的表
CREATE TABLE columns (
       schema_name VARCHAR(64),
       table_name VARCHAR(64),
       func_id INT,
       PRIMARY KEY (schema_name, table_name),
       FOREIGN KEY (func_id) REFERENCES partition_functions(func_id)
)
```

##### 分片管理

分片迁移或者在分片之间迁移数据。

###### 将分片迁移到其他的节点

尽可能少的宕机时间，主要思想是为分片做备份，在目标节点上恢复备份，然后使用复制重新执行这期间发生的变更

1. 在源节点上创建模式的备份。在线或离线备份方法都可以
2. 记录某个特定的binlog文职
3. 停止服务器，将目标节点离线
4. 服务器停止过程中
	* 将replicate-do-db=schema_1选项设置为需要迁移的那个分片
	* 按需要从源节点恢复备份
5. 将目标节点恢复运行
6. 将复制配置从第2步的位置开始，然后在目标服务器上启动复制。从源服务器上读取事件，并将变更应用到要迁移的分片上
	* 保证目标节点有足够的处理能力
7. 如果目标节点与源节点差距较大，锁定源节点的分片模式，阻止变更。不需要停止目标节点上的分片变更，因为还没有写操作访问它。
	* LOCK TABLES命令
8. 检查源服务器上的日志位置，因为没有继续变更，这就是需要的最高日志位置
9. 等待目标服务器同步到这个位置，使用START SLAVE UNTIL和MASTER_POS_WAIT。
10. 在目标服务器上通过RESET SLAVE关闭复制
	* 这会删除所有复制信息
11. 将目标服务器离线，删除replicate-do-db选项，然后在恢复服务器，这是可选的
12. 更新分片信息，使得请求被定向到新的分片位置
13. 将模式解锁，重新启动分片的写操作
14. 删除源服务器的分片模式，取决于分片是如何锁定的。

借助Replicant库自动化实现这个过程。

###### 分割分片

如果分片太热，可以分割分片后迁移

1. 对分片中的所有模式使用在线备份方法，如MEB、XtraDB或系统文件快照等
2. 记下备份对应的binlog位置
3. 在目标节点上恢复备份
4. 启动从源节点到目标节点的复制，使用binlog-do-db或replication-do-db选项只复制要迁移的模式的变更。
5. 等待复制使目标节点跟上源节点，然后锁定源分片，即不能读也不能写
6. 等待目标主机完成与源主机的同步，这是分片的所有数据不可用
7. 更新分片数据库，使所有请求都被定向到新分片
8. 解锁源分片。这是所有数据都有了，但是两个分片上有数据冗余，但是冗余数据不会被访问
9. 使用LIMIT语句删除冗余数据，防止占用过多资源

#### 深入复制

* 如何更加安全的将slave提升为master
* 崩溃后避免数据库损坏
* 多源复制
* 基于行的复制
* 全局事务标识符
* 多线程复制

##### 复制架构基础

master和若干slave的内部结构：

![Master-and-several-slaves-with-internal-architecture](/static/img/数据库/Master-and-several-slaves-with-internal-architecture.png)

事件通过复制系统从master到slave，以如下方式:

* 会话接受来自客户机的语句，执行该语句，并与其他会话同步，以确保每个事务执行，而不与其他会话所做的其他更改相冲突。
* 在语句完成执行之前，一个包含一个或多个事件的条目被写入到二进制日志中。
* 在将事件写入到二进制日志之后，主服务器中的一个转储线程接管，从二进制日志中读取事件，并将它们发送到slave的I/O线程。
* 当slave的I/O线程接收事件时，它将其写入到中继日志的末尾。
* 在中继日志中，一个slave的SQL线程从中继日志读取事件，并执行该事件，将更改应用到slave的数据库中。

如果丢失了master的链接，slave的I/O线程将试图重连服务器

###### 中继日志的结构

中继日志结构：

![Structure-of-the-relay-log](/static/img/数据库/Structure-of-the-relay-log.png)

除了二进制日志的内容未见和索引文件以外，中继日志还维护两个文件来跟踪复制的进度，即中继日志信息文件和master日志信息文件。名称可有my.cnf配置。

```conf
# 默认为relay-log.info
relay-log-info-file=filename
# 默认为master.info
# 这个文件信息优于my.cnf，推荐直接使用CHANGE MASTER TO命令配置复制
master-info-file=filename
```

master.info文件包含了master读取位置以及连接到master服务器并开始复制所需的所有信息。当slave的I/O线程启动时，该文件如果可用就从中读取信息。

```info
23                                         1   Number of lines in the file
master-bin.000001                          2   Current binlog file being read (Master_Log_File)
151                                        3   Last binlog position read (Read_Master_Log_Pos)
localhost                                  4   Master host connected to (Master_Host)
root                                       5   Replication user (Master_User)
                                           6   Replication password
13000                                      7   Master port used (Master_Port)
60                                         8   Number of times slave will try to  reconnect (Connect_Retry)
0                                          9   1 if SSL is enabled, otherwise 0
                                           10  SSL Certification Authority (CA)
                                           11  SSL CA Path
                                           12  SSL Certificate
                                           13  SSL Cipher
                                           14  SSL Key
0                                          15  SSL Verify Server Certificate 
60.000                                     16  Heartbeat 
                                           17  Bind Address 
0                                          18  Ignore Server IDs 
8c6d027e-cf38-11e2-84c7-0021cc6850ca       19  Master UUID
10                                         20  Retry Count 
                                           21  SSL CRL 
                                           22  SSL CRL Path 
0                                          23  Auto Position
```

info文件跟踪复制的进度，并由SQL线程更新。

```info
./slave-relay-bin.000003     Relay log file (Relay_Log_File)
380                          Relay log position (Relay_Log_Pos)
master1-bin.000001           Master log file (Relay_Master_Log_File)
234                          Master log position (Exec_Master_Log_Pos)
```

如果有任何文件不可用，在slave启动的时候将从my.cnf文件中的信息及CHANGE MASTER TO命令的参数重建这些文件。需要START SLAVE。

###### 复制线程

* master转储线程
	* 当一个slave I/O线程连接的时候，这个线程被创建在master服务器上。转储线程负责从master服务器上读取条目并将其发送给slave。
	* 每个连接的slave有一个转储线程。
* slave I/O线程
	* 该线程连接到master服务器，请求转储发生的所有更改，并将它们写入到中继日志中，以供SQL线程进一步处理。
	* 每个slave上都有一个I/O线程。一旦连接建立起来，它就会被保持打开，这样master的任何变化都会立即被slave接收。
* slave SQL线程
	* 该线程从中继日志读取更改并将其应用到slave数据库。该线程负责协调其他MySQL线程，以确保更改不会影响MySQL服务器上正在进行的其他活动。

从master的角度来看，I/O线程只是另一个客户机线程，它可以同时执行转储请求和master服务器上的SQL语句。
这意味着客户端可以连接到服务器，并假装是一个slave，以便让master服务器从二进制日志中转储更改。这就是mysqlbinlog程序的操作方式。

SQL线程在处理数据库时就像一个会话。但是它还需要处理一些context信息保证复制的正确性。

I/O线程的速度比SQL线程快得多，因此，在复制期间，在中继日志中通常会缓冲几个事件。如果master服务器崩溃，您必须在连接到新master之前处理这些问题。  
为了避免丢失这些事件，在尝试重新连接到另一个master服务器之前，等待SQL线程处理完这些事件。

###### 启动和终止slave线程

* slave I/O现场称从master.info文件读取最后读位置进行恢复
	* 中继日志文件也存在轮换事件
* slave SQL线程从relay-log.info文件读取中继日志位置进行恢复。

停止和启动slave线程的命令：

* START SLAVE和STOP SLAVE
	* 两个线程
* START SLAVE TO_THREAD和STOP SLAVE TO_THREAD
	* I/O线程
* START SLAVE SQL_THREAD和STOP SLAVE SQL_THREAD
	* SQL线程

##### 通过Internet进行复制

保护数据，基本都需要用到SSL：

* 使用服务器内置的加密支持，对master到slave的复制进行加密
	* 权威认证机构的证书（CA）
	* 服务器的（共有）的证书
	* 服务器的（私有）的证书
* 对于不支持SSL的程序，使用Stunnel程序建立一个SSL隧道（虚拟私有网络）
* 在隧道模式下使用SSH

```shell
# 生成自签名的共有证书放在/etc/ssl/certs/master.pem
# 生成自签名的四有密钥放在/etc/ssl/private/master.key
# slave同样
sudo openssl req -new -x509 -days 365 -nodes \
        -config /etc/ssl/openssl.cnf \
        -out /etc/ssl/certs/master.pem -keyout /etc/ssl/private/master.key
```

###### 使用内置支持建立安全复制

```conf
# master
[mysqld]
ssl-capath=/etc/ssl/certs
ssl-cert=/etc/ssl/certs/master.pem
ssl-key=/etc/ssl/private/master.key
```

```sql
-- slave
CHANGE MASTER TO
    MASTER_HOST = 'master-1',
    MASTER_USER = 'repl_user',
    MASTER_PASSWORD = 'xyzzy',
    MASTER_SSL_CAPATH = '/etc/ssl/certs',
    MASTER_SSL_CERT = '/etc/ssl/certs/slave.pem',
    MASTER_SSL_KEY = '/etc/ssl/private/slave.key';
```

###### 使用Stunnel建立安全复制

slave服务器上的一个Stunnel实例接受来自从服务器的标准MySQL客户机连接上的数据，对它进行加密，并将其发送到master服务器上的Stunnel实例。
master服务器上的Stunnel实例依次侦听专用的SSL端口，接收加密数据，解密它，并将其发送到master服务器上的非SSL端口的客户机连接上。

![Replication-over-an-insecure-channel-using-Stunnel](/static/img/数据库/Replication-over-an-insecure-channel-using-Stunnel.png)

```conf
# /etc/stunnel/master.conf
cert=/etc/ssl/certs/master.pem
key=/etc/ssl/private/master.key
CApath=/etc/ssl/certs
[mysqlrepl]
accept = 3508
connect = 3306
```

```conf
# /etc/stunnel/slave.conf
cert=/etc/ssl/certs/slave.pem
key=/etc/ssl/private/slave.key
CApath=/etc/ssl/certs
[mysqlrepl]
accept = 3408
connect = master-1:3508
```

```sql
CHANGE MASTER TO
    MASTER_HOST = 'localhost',
    MASTER_PORT = 3408,
    MASTER_USER = 'repl_user',
    MASTER_PASSWORD = 'xyzzy';
```

##### 细粒度控制复制

###### 关于复制状态的信息

SHOW SLAVE HOSTS命令仅显示使用report-host参数的slave信息，slave使用report-host参数告诉master服务器的链接信息。
除了主机名外还有其他参数提供了关于连接slave的信息：

* report-host
* report-port
* report-user
* report-password
* show-slave-auth-info

```sql
SHOW SLAVE HOSTS;
-- 显示master的二进制文件
SHOW MASTER LOGS;
SHOW MASTER STATUS;
SHOW SLAVE STATUS;
```

SLAVE STATUS字段详解：

**I/O线程和SQL线程的状态**

* Slave_IO_Running和Slave_SQL_Running分别表示I/O线程或者SQL线程是否正在运行
* Slave_IO_State描述了当前正在运行的I/O线程的状态。
	* 等待master更新
	* 连接master
	* 检查master的版本
	* 在master上注册slave
	* 请求binlog转储
	* 等待master发送事件
	* master事件排队等待写入中继日志
	* action后等待重新连接
		* 失败重连时出现
	* action失败后重新连接
	* 等待slave互斥体退出
		* 关闭I/O线程时出现该消息
	* 等待slave的SQL线程释放中继日志空间
		* 等待处理中继日志轮换

![Slave-IO-thread-states](/static/img/数据库/Slave-IO-thread-states.png)

**二进制日志位置和中继日志位置**

* Master_Log_File和Read_Master_Log_Pos表示master的读位置
	* I/O线程即将从master二进制日志读取的下一个事件的位置，来自master.info 2,3
* Relay_Master_Log_File和Exec_Master_Log_Pos表示master的执行位置
	* SQL线程即将执行的master二进制日志的下一个事件位置，来自relay-log.info 3,4
* Relay_Log_File和Relay_Log_Pos表示中继日志执行位置
	* SQL线程即将执行slave中继日志中的下一个事件位置，来自relay-log.info 1,2

通过比较master的读位置和master的执行位置，如果相同，就可以安全的停止slave并将其重定向到新的master。  
也可以通过SHOW PROCESSLIST命令检查SQL线程的状态，如果State为“已经读取所有中继日志，等待slave I/O线程更新”，那么已经读取全部中继日志。

##### 处理断开连接的选项

如果I/O线程丢失了master的连接，则进行有限次尝试重新连接master。无响应时间、重试的时间间隔和重试次数由三个选项控制：

* --slave-net-timeout
	* 超时时间，默认3600秒
* --master-connect-retry
	* 重试间隔秒数，默认60秒
* --master-retry-count
	* 重试次数，默认为86400

##### slave如何处理事件

slave的SQL线程顺序执行来自master的所有会话的各个事件，带来的后果：

* slave响应是单线程的，而master是多线程的
	* 如果master上提交了很多事务，slave就难以与master保持同步
* 有些语句时会话特定的
	* slave上单线程执行的时候可能产生不同的结果
		* 每个用户变量都是特定于会话的
		* 临时表是特定于会话的
		* 有些函数也是特定于会话的
* 二进制日志决定了执行顺序
	* slave必须并行执行，才能保证和master一致

###### 管理I/O线程

I/O线程只使用某些字节来判断事件的类型，然后对中继日志采取必要的行动

* 停止事件
	* slave链中的下一个服务器被有序停止，I/O线程忽略这个时间，不把这个事件写入中继日志。
* 轮换事件
	* 如果master上的二进制日志被轮换，中继日志也要被轮换。
	* 中继日志轮换次数可能比master多，然是每次master轮换时，中继日志都要轮换。
* 格式化描述事件
	* 中继日志轮换时保存这种事件。应对连续的binlog文件格式不同问题。

每个服务器都要检查事件是否包含该服务器的ID，如果有，则忽略，说明本身是由这个服务器发出的，这在环形复制或双主复制中很有用。

###### SQL线程处理

有些事件需要SQL以外的特殊处理：

* 将master的上下文发送给slave
	* 处理master写的一个或多个上下文事件传递额外信息
* 处理不同线程的事件
	* master执行的事务来自多个会话。slave SQL现场称必须知道事件是由那个线程产生的。master了解每个语句，他会标记哪些线程特定的事件。
* 过滤事件和表
	* 负责数据库过滤和表过滤
* 跳过事件
	* 要恢复复制，重启复制时可以选择跳过事件

**上下文事件**

* 用户变量事件
	* 用户自定义变量名和值
	* 还可以用来避免非确定性函数的复制问题、提高性能，以及完整性检查等。
* 整型变量事件
	* 事件存储INSERT_ID或LAST_INSERT_ID会话变量的整型值
* Rand事件
	* 随机种子

**线程特定的事件**

不同线程导致结果不同的原因：

* 读写线程本地对象
	* 不同线程的本地对象的名字可以完全一样。临时表或用户自定义变量
	* 所有QUERY事件都有线程ID，salve收到一个线程特定的事件时，设值一个特定的复制slave线程变量，即pseudothreadID，对应事件的线程ID，然后使用这个ID创建临时表
* 使用具有线程特定结果的变量或函数
	* 变量和函数在不同线程中运行导致值不同。服务器变量和connect_id
	* 使用基于行的复制
	* 或使用临时变量

**过滤和跳过事件**

```sql
-- 恢复复制之前跳过3个事件
-- 如果会导致事务中断，则事务执行结束后跳过3个事件
SET GLOBAL SQL_SLAVE_SKIP_COUNTER = 3;
START SLAVE;
```

如果有slave过滤器，事件在SQL线程中过滤，过滤的事件依然会出现在中继日志中。

表过滤的使用原则：

* 不要限定数据表所在的数据库。在语句前使用USE。
* 不要在单个语句中更新不同数据库的表
* 不要在单个语句中更新多个表，除非你知道所有这些表都要过滤或都不会过滤

只要有一个表被过滤，整个语句都会被过滤。

复制过滤规则：

![Replication-filtering-rules](/static/img/数据库/Replication-filtering-rules.png)

##### 半同步复制

半同步复制的原理是复制继续运行之前，确保至少有一个slave将变更写到磁盘。对每个连接来说，如果发生master崩溃，至多只丢失一个事务。

半同步复制的事务提交：

![Transaction-commit-with-semisynchronous-replication](/static/img/数据库/Transaction-commit-with-semisynchronous-replication.png)

对于每个连接来说，如果事务在提交到存储引擎之后，发送到slave之前，发生了系统崩溃，那么这个事务就会丢失。  
由于slave确定事件提交后才会向客户端发送确认，所以至多只有一个事务丢失。

###### 配置半同步复制

5.5以后的master和slave支持才可以。

启用半同步复制的步骤：

1. 在master上安装master插件：
2. 在每个slave上安装插件
3. 启用插件
4. 重启服务器

```sql
-- master
INSTALL PLUGIN rpl_semi_sync_master SONAME 'semisync_master.so';
-- slave
INSTALL PLUGIN rpl_semi_sync_slave SONAME 'semisync_slave.so';
```

```conf
# master
[mysqld]
rpl-semi-sync-master-enabled = 1
# slave
[mysqld]
rpl-semi-sync-slave-enabled = 1
```

* 如果所有slave崩溃，就无法确认是否写入了中继日志
	* rpl-semi-sync-master-timeout=milliseconds 设置超时，如果超时则变为异步复制
* 如果所有slave连接都断了，也无法确认
	* rpl-semi-sync-master-wait-no-slave={ON|OFF} 设置是否等待slave连入

###### 监控半同步复制

* rpl_semi_sync_master_clients
	* 连接到master的支持半同步slave的数目
* rpl_semi_sync_master_status
	* master上的半同步状态，1表示活动
* rpl_semi_sync_slave_status
	* slave上的半同步状态，1表示活动

```sql
SHOW STATUS;
-- 如果上面命令不可用
SELECT Variable_value INTO @value
	   FROM INFORMATION_SCHEMA.GLOBAL_STATUS
	  WHERE Variable_name = 'Rpl_semi_sync_master_status';
```

##### 全局事务标识符

服务器上为每一个事务分配一个唯一的事务标识符，这是一个64位非0整数，根据事务提交的顺序分配。
这个值是本地的，要使事务标识符成为全局的，还要加上服务器的UUID（@@server_uuid），构成一对。

复制事务的时候如果启用了全局事务标识符，不管事务被赋值了多少次，事务的GTID保持不变。

GTID组定义某个或一组范围内的事务标识符。

```conf
# GTID
2298677f-c24b-11e2-a68b-0021cc6850ca:1477
# GTID组
2298677f-c24b-11e2-a68b-0021cc6850ca:911-1066:1477-1593
```

_注意事项：需要启动binlog才会记录这个GTID，否则不分配也不记录_

###### 使用GTID配置复制

```conf
[mysqld]
user            = mysql
pid-file        = /var/run/mysqld/mysqld.pid
socket          = /var/run/mysqld/mysqld.sock
port            = 3306
basedir         = /usr
datadir         = /var/lib/mysql
tmpdir          = /tmp
# 启用binlog
log-bin         = master-bin 
log-bin-index   = master-bin.index
server-id       = 1
# 启用GTID
gtid-mode       = ON 
# 对于备用服务器需要传递给slave来自master的变更
log-slave-updates 
# GTID强一致性，否则报错
enforce-gtid-consistency
```

启用后变更master步骤：

```sql
CHANGE MASTER TO
	MASTER_HOST = host_of_new_master,
	MASTER_PORT = port_of_new_master,
	MASTER_USER = replication_user_name,
	MASTER_PASSWORD = replication_user_password,
	MASTER_AUTO_POSITION = 1
```

master和slave会自动协商应该发送什么事务。

SHOW SLAVE STATUS：

```conf
Slave_IO_State: Waiting for master to send event
                .
                .
                .
  Slave_IO_Running: Yes
 Slave_SQL_Running: Yes
                .
                .
                .
       Master_UUID: 4e2018fc-c691-11e2-8c5a-0021cc6850ca
                .
                .
                .
Retrieved_Gtid_Set: 4e2018fc-c691-11e2-8c5a-0021cc6850ca:1-1477
 Executed_Gtid_Set: 4e2018fc-c691-11e2-8c5a-0021cc6850ca:1-1593
     Auto_Position: 1
```

* Master_UUID
* Retrieved_Gtid_Set
	* 存储在中继日志中的一组GTID
* Executed_Gtid_Set
	* 已经执行，并已经写入slave二进制日志的GTID

###### 使用GTID进行故障转移

切换到热备：

* 不在需要检查master上的位置了，所以也不需要停止
* slave没必要与master位置一致，备用服务器也没必要等待一个好的切换位置
* 不需要获取备用服务器位置
* 更改master时不需要提供位置

为了避免master失效时丢失事务，要养成执行故障转移钱清空中继日志的好习惯。这样避免了重复从master获取已经发送到slave的事务。

使用WAIT_UNTIL_SQL_THREAD_AFTER_GTIDS函数阻塞直到GTID组中的所有GTID都被SQL线程处理完毕。

```sql
SHOW SLAVE STATUS;
SELECT WAIT_UNTIL_SQL_THREAD_AFTER_GTIDS(Retrieved_Gtid_Set);
STOP SLAVE;
CHANGE MASTER TO 'standby.example.com';
START SLAVE;
```

###### 使用GTID提升slave

* GTID_EXECUTED 已写入二进制日志的GTID组
* GTID_PURGED	已从二进制日志中清除的GTID组

![GTID_EXECUTED-and-GTID_PURGED](/static/img/数据库/GTID_EXECUTED-and-GTID_PURGED.png)

使用GTID_EXECUTED很容易比较slave，然后决定那个slave“知道最多”。

```sql
SELECT @@GLOBAL.GTID_EXECUTED
SELECT @@GLOBAL.GTID_PURGED
```

###### GTID的复制

二进制为每个组分配了GTID，每个事务、单语句的DML语句及DDL语句。在写入组值钱写GTID时间，该事件包含事务的完整GTID。

![A-binary-logfile-with-GTIDs](/static/img/数据库/A-binary-logfile-with-GTIDs.png)

SQL线程按照以下方式处理GTID事件：

1. 如果GTID已经在GTID_EXECUTED中，跳过整个事务，也不写入二进制日志
2. 否则GTID就被分配给后面的事务，下一个事务正常执行
3. 如果事务提交，事务的GTID就用来产生一个新的GTID事件，然后这个事件在事务之前写入二进制日志
4. 在GTID事件之后，事务缓存的内容被写入二进制日志

在提交事务的时候，根据GTID_NEXT变量的值有不同的操作：

* 如果GTID_NEXT的值为AUTOMATIC，那么创建一个新的GTID并将其分配给事务
* 如果GTID_NEXT的值为GTID，那么使用这个GTID并且会随事务一起写入二进制日志

设值了GTID_NEXT并开启了事务，GTID就被这个事务拥有了

```sql
SELECT @@GLOBAL.GTID_OWNED;
```

mysqlbinlog with GTID events：

```conf
# at 410
#130603 20:57:54 server id 1  end_log_pos 458 CRC32 0xc6f8a5eb
#       GTID [commit=yes]
SET @@SESSION.GTID_NEXT= '01010101-0101-0101-0101-010101010101:3'/*!*/;
# at 458
#130603 20:57:54 server id 1  end_log_pos 537 CRC32 0x1e2e40d0
# Position  Timestamp   Type   Master ID        Size      Master Pos    Flags
#       Query   thread_id=4     exec_time=0     error_code=0
SET TIMESTAMP=1370285874/*!*/;
BEGIN
/*!*/;
# at 537
#130603 20:57:54 server id 1  end_log_pos 638 CRC32 0xc16f211d
#       Query   thread_id=4     exec_time=0     error_code=0
SET TIMESTAMP=1370285874/*!*/;
INSERT INTO t VALUES (1004)
/*!*/;
# at 638
#130603 20:57:54 server id 1  end_log_pos 669 CRC32 0x91980f0b
COMMIT/*!*/;
```

##### slave的安全和恢复

###### 同步、事务以及数据库崩溃问题

为了保证master或slave崩溃以后能够安全地恢复复制，需要考虑两个问题：

* 保证slave上存有恢复所需的所有数据
	* slave通过磁盘同步尽量满足这个条件
	* MySQL服务器定期在中继日志、master.info文件和relay-log.info文件上执行fsync调用，强制文件写入磁盘
* 执行slave的恢复

**I/O线程同步**

无论什么时候处理事件都有两个fsync调用：

* 一个将中继日志刷新到磁盘
* 一个将master.info文件刷新到磁盘

这两个刷新保证了没有事件丢失，以下几种情况发生崩溃，可能产生重复事件：

* 服务器刷新中继日志，正要更新master.info文件中的master读位置
* 服务器崩溃，也就是master读位置指向事件被刷新到中继日志之前的位置
* 服务器重启，并从master.info获得master读位置，即在最后一个事件写入中继日志之前的位置
* 从这个位置恢复复制，导致事件重复

如果按相反顺序刷新文件，可能丢失事件，，因为slave会在事件之后恢复复制。我们认为事件丢失比事件重复严重。

**SQL线程同步**

在处理组中所有事件时，SQL线程采用下面方式提交事务：

1. 将事务提交到存储引擎
2. 更新relay-log.info文件的下一个事件位置，这个位置也是处理下一个组的开始位置
3. 发出fsync调用，将relay-log.info文件写入磁盘

如果发生崩溃，从rela-log.info文件的最后一个记录位置恢复执行。

这种方式使得SQL线程的原子更新问题与I/O线程不同，所以下面的情况可能导致slave数据库和relay-log.info文件不同步：

1. 事件在数据库上应用，且事务已提交。下一步是更新relay-log.info文件
2. slave崩溃。relay-log.info文件指向刚刚完成的事务的开始
3. 恢复时，SQL线程从relay-log.info文件读取信息，并从保存的位置开始复制
4. 重复上一次执行的事务

这些情况都是因为slave上提交事务也更新复制信息不是一个原子操作，MySQL 5.6通过事务型复制解决这个问题。

###### 事务型复制

复制不是崩溃安全的，因为复制进度信息并不总是与数据库中的应用市级变更同步。
即使服务器崩溃时事务没有丢失，也要花点力气将slave恢复回来。

通过提交事务同时提交复制信息，增强了slave的复制安全性。
复制信息总是与数据库的变更应用一直，不论服务器是否发生崩溃。而且，master也做了调整保证能够正确恢复。

要实现事务型复制，将复制信息存储在文件或者表中。即数据和复制信息要么使用相同的事务型存储引擎，要么两个存储引擎都要支持XA。

**配置事务型复制**

```conf
[mysqld]
# 可选项为FILE和TABLE
master_info_repository = TABLE
relay_log_info_repository = TABLE
```

5.6.6之前，还要变更表的存储引擎：

```sql
ALTER TABLE mysql.slave_master_info ENGINE = InnoDB;
ALTER TABLE mysql.slave_relay_log_info ENGINE = InnoDB;
```

**事务型复制的细节**

保存事务型复制相关信息的两张表：

* slave_master_info对应master.info
* slave_relay_log_info对应relay_log.info

slave_master_info：

| Field                   | Line in file   | Slave status column           |
| ----------------------- | -------------- | ----------------------------- |
| Number_of_lines         | 1              |                               |
| Master_log_name         | 2              | Master_Log_File               |
| Master_log_pos          | 3              | Read_Master_Log_Pos           |
| Host                    | 3              | Master_Host                   |
| User_name               | 4              | Master_User                   |
| User_password           | 5              |                               |
| Port                    | 6              | Master_Port                   |
| Connect_retry           | 7              | Connect_Retry                 |
| Enabled_ssl             | 8              | Master_SSL_Allowed            |
| Ssl_ca                  | 9              | Master_SSL_CA_File            |
| Ssl_capath              | 10             | Master_SSL_CA_Path            |
| Ssl_cert                | 11             | Master_SSL_Cert               |
| Ssl_cipher              | 12             | Master_SSL_Cipher             |
| Ssl_key                 | 13             | Master_SSL_Key                |
| Ssl_verify_servert_cert | 14             | Master_SSL_Verify_Server_Cert |
| Heartbeat               | 15             |                               |
| Bind                    | 16             | Master_Bind                   |
| Ignored_server_ids      | 17             | Replicate_Ignore_Server_Ids   |
| Uuid                    | 18             | Master_UUID                   |
| Retry_count             | 19             | Master_Retry_Count            |
| Ssl_crl                 | 20             | Master_SSL_Crl                |
| Ssl_crlpath             | 21             | Master_SSL_Crlpath            |
| Enabled_auto_position   | 22             | Auto_Position                 |

slave_relay_log_info：

| Field             | Line in file   | Slave status column   |
| ----------------- | -------------- | --------------------- |
| Number_of_lines   | 1              |                       |
| Relay_log_name    | 2              | Relay_Log_File        |
| Relay_log_pos     | 3              | Relay_Log_Pos         |
| Master_log_name   | 4              | Relay_Master_Log_File |
| Master_log_pos    | 5              | Exec_Master_Log_Pos   |
| Sql_delay         | 6              | SQL_Delay             |
| Number_of_workers | 7              |                       |
| Id                | 8              |                       |

slave上每一个事务都被更新到slave_relay_log_info表。  
slave_master_info表只保存从master获取的事件的位置，
如果发生崩溃，slave将从上一次执行的位置恢复，而不是上一次获取的位置恢复，所以这个信息只对master崩溃有用。
这时，中继日志中的事件将被执行，避免更多事件丢失。  
slave_master_info表不包含事务型复制的重要信息，sync_master_info选项表示提交到slave_master_info表或刷新到磁盘的频率以提高性能。
0表示有操作系统控制文件刷新，当轮换或启动和停止的收，信息都会被刷新到磁盘或者表。

###### 保护非事务型语句的规则

master上崩溃，MyISAM表上的语句由于崩溃中断，这个语句不再计入日志，因为只有执行完的语句才记入日志。
重启时表包含一部分更新，但是二进制日志没有记录该语句。  
slave上如果执行过程中发生崩溃，表的变更可能还在，但是组位置不变，重启后将重复执行。

通过观察一些规则，可以观察到一些错误信息：

* INSERT语句
	* 要复制的表中必有主键，主键重复可能导致slave停止
* DELETE语句
	* 避免使用limit从句，这样重复执行也会没有影响
* UPDATE语句
	* 语句必须是幂等的，或者执行两次的偶然性是可以接受的

##### 多源复制

设计上有个问题：如何处理更新冲突

典型的实现方法：更新不同的数据库，或者更新同一张表的不同行

MySQL目前不支持多个源复制，可以近似实现：将slave在多个master之间切换，轮流从其中一个master定期复制，成为轮盘多源复制。

![Round-robin-multisource-replication-using-a-client-to-switch](/static/img/数据库/Round-robin-multisource-replication-using-a-client-to-switch.png)

1. 将slave配置为从一个master进行复制。
2. 设值slave复制的固定工作时间，slave从当前master中读取更新，然后应用更新，这是负责切换的客户端处于休眠状态。
3. 使用STOP SLAVE IO_THREAD停止slave的I/O线程
4. 等待中继日志为空
5. 使用STOP SLAVE SQL_THREAD停止SQL线程。CHANGE MASTER要求两个线程都停止
6. 保存当前master的slave位置，存储SHOW SLAVE STATUS命令输出的Exec_Master_Log_Pos和Relay_Master_Log_File的值
7. 将slave的复制按顺序切换到下一个master上：利用之前保存的位置，并使用CHANGE MASTER命令配置复制
8. 使用START SLAVE重启slave线程
9. 重复2-8步

_Tips：不执行3-5不也不会有问题，因为丢失的事件会从master重新读取_

##### 基于行复制的细节

基于行的复制方法不同，每个语句需要多个事件。

引入4个事件处理基于行的复制：

* Table_map
	* 将表ID映射为表名（包括数据名），以及关于master上的表的列的基本信息
	* 表信息只有类型，按位置复制
* Write_rows, Delete_rows, Update_rows
	* 除了行以外，每个事件还有一个表ID，来自Table_map事件，还有一个或两个列位图，说明影响了哪些列，节省空间。

每当执行一个语句时，它都会作为Table_map事件序列写入二进制日志，然后是行事件序列。
语句的最后一行事件被标记为一个特殊标志，指示它是语句的最后一个事件。

```sql
*************************** 1. row ***************************
   Log_name: master-bin.000054
        Pos: 106
 Event_type: Query
  Server_id: 1
End_log_pos: 174
       Info: BEGIN
*************************** 2. row ***************************
   Log_name: master-bin.000054
        Pos: 174
 Event_type: Table_map
  Server_id: 1
End_log_pos: 215
       Info: table_id: 18 (test.t1)
*************************** 3. row ***************************
   Log_name: master-bin.000054
        Pos: 215
 Event_type: Write_rows
  Server_id: 1
End_log_pos: 264
       Info: table_id: 18 flags: STMT_END_F
*************************** 4. row ***************************
   Log_name: master-bin.000054
        Pos: 264
		Event_type: Table_map
  Server_id: 1
End_log_pos: 305
       Info: table_id: 18 (test.t1)
*************************** 5. row ***************************
   Log_name: master-bin.000054
        Pos: 305
 Event_type: Write_rows
  Server_id: 1
End_log_pos: 354
       Info: table_id: 18 flags: STMT_END_F
*************************** 6. row ***************************
   Log_name: master-bin.000054
        Pos: 354
 Event_type: Xid
  Server_id: 1
End_log_pos: 381
       Info: COMMIT /* xid=23 */
6 rows in set (0.00 sec)
```

行事件大小通过binlog-row-event-max-size控制，表示它在二进制日志中的最大字节数。

###### Table_map事件

Table_map事件将表名映射为标识符，然后用于行事件，但这不是它唯一的用途。
它还包含master上表中字段的基本信息。slave确认结构匹配，从而复制继续。

![Table-map-event-structure](/static/img/数据库/Table-map-event-structure.png)

* 列类型数组
	* 表述所有列的基础数据类型数组，不包含参数
* 空比特数组
	* 表是每个字段是否是NULL的数组
* 列元数据
	* 表示字段元数据的数组，充实列类型数组的细节信息。如DECIMAL的精度和小数

无法区分的两种类型：

* 整型数据是否有符号
* 字符串类型的字符集

###### 行事件的结构

根据不同的事件类型，结构稍有不同。

![Row-event-header](/static/img/数据库/Row-event-header.png)

* 表宽
	* master上表的宽度，基于长度编码的，只有两个字节，大多数情况只有一个字节
* 列位图
	* 表示作为事件一部分发送的那些列。
		* 前映像，用于删除和更新
		* 后映像，用于插入和更新

行事件及其映像：

| Before image                | After image                | Event       |
| --------------------------- | -------------------------- | ----------- |
| None                        | Row to insert              | Write rows  |
| Row to delete               | None                       | Delete rows |
| Column values before update | Column values after update | Update rows |

###### 行事件的执行

因为多个事件可能表示master上执行的单个语句，所以slave需要保存状态信息，当有并发线程更新同一张表时，保证行时间的正确执行。

处理步骤：

1. 从中继日志中读取各个事件
2. 如果是表映射事件，SQL线程将提取表信息，并保存master对这个表的定义
3. 出现第一个行事件时，锁定列表中的所有表
4. 线程检查每张表是否一致
5. 如果不一致，就报错，停止复制
6. 继续行处理，直至最后一个行事件

拥有前映像的事件需要经过查找后正确定位到需要操作的行。按照查找优先级递减的顺序，查找操作包括：

* 主键查询
	* 最快
* 索引扫描
	* 没有主键，但有索引，找到则delete或update，否则报错
* 表扫描
	* 没有主键也没有索引，全表扫描

使用slave而不是master的主键或索引定位正确的行执行删除或更新操作，所以要注意：

* 有主键，很快，没有则很慢
* master和slave的索引可能不同

###### 事件和触发器

由于触发器引起变化的行也会被复制到slave上执行，所以slave上不能在执行一次触发器。  
事件复制后直接执行，不考虑触发器。

###### 基于行的复制中的过滤

基于行的复制的过滤是基于真正发生变化的表，而不是语句的当前数据库。

###### 部分行复制

5.6.2开始，可以通过binlog-row-image参数控制哪些列写入日志。参数有full、noblob和minimal。

* full
	* 默认值，复制全部列
* noblob
	* 忽略blob，除非他们需要被更新
* minimal
	* 只有主键和更改值的列

#### 备份和恢复

备份应对一下情况：

* 数据保护
	* 当错误语句slave已经生效后的错误处理
* 创建新服务器

```bat
# 备份数据库内容（结构加数据，没有数据库本身）
mysqldump -uusername -ppassword databasename>/bak.sql
# 恢复
mysql -uusername -ppassword databasename</bak.sql
# 登陆后恢复
mysql -uusername -ppassword
source /bak.sql
```

#### 监控

有许多不同的东西可以监视、测量和计划来处理这些类型的更改。下面是一些例子:

* 可以将索引添加到经常读取的表中。
* 可以重写查询或更改数据库结构，以加快执行时间。
* 如果锁被保存了很长时间，这表明几个连接在使用同一个表。更换存储引擎可能会有好处。
* 如果一些过热的slave正在处理不成比例的查询，系统可能需要进行一些重新均衡，以确保所有的过热的slave都被均匀地击中。
* 要处理资源使用的突然变化，必须确定每个服务器的正常负载，并理解系统何时因为负载突然增加开始缓慢响应。

如果没有监视，就无法发现问题查询、过热的slave或使用不当的表。

### failover

当异常数据库服务器宕机时，通过手工或自动化手段将主机流量切换至备机，这个动作叫做failover。

## Oracle

### 用户

默认用户

| 用户名 | 密码       | 备注      |
| ------ | ---------- | --------- |
| sys    | 安装时设置 | as sysdba |
| system | manager    |           |
| scott  | tigger     |           |

创建用户

```sql
sqlplus / as sysdba
set linesize 300

select * from dba_users;
select * from all_users;
select * from user_users;

create user username identified by password default tablespace users;
drop user username cascade;
-- 解锁用户
alter user scott account unlock;
```

### 表空间

```sql
select username,default_tablespace from   dba_users;
select table_name from user_tables;

sqlplus sys/sys as sysdba
--创建默认表空间
create tablespace mytbs datafile '/home/oracle/oradata/data.dbf' size 300M;
--创建用户
create user mytbs identified by mytbs default tablespace mytbs;
--赋权 需访问到dba_directories
grant dba to mytbs; 


desc user_tables;
SELECT * FROM DICTIONARY;-- 数据字典表
SELECT TABLE_NAME, TABLESPACE_NAME FROM USER_TABLES;
SELECT VIEW_NAME FROM USER_VIEWS;
SELECT TABLE_NAME,CONSTRAINT_NAME FROM USER_CONSTRAINTS;
SELECT INDEX_NAME,TABLE_NAME FROM USER_INDEXES;
SELECT SEQUENCE_NAME FROM USER_SEQUENCES;
```

### 权限

#### 系统权限

* 登陆权限

```sql
grant create session to username;
```

* 创建表

```sql
grant create table to username;
```

* 表空间

```sql
grant unlimited tablespace to username;
```

* 撤销权限

```sql
revoke create table from username;
```

* 赋予所有用户权限

```sql
grant create any table to public;
```

* 查询当前用户系统权限

```sql
select * from user_sys_privs;
```

#### 对象权限

* 赋予用户对象权限

```sql
grant select on tablename to username;
grant insert on tablename to username;
grant all on tablename to username;
revoke all on tablename to username;
```

* 列权限

查询和删除不能控制到列

```sql
grant insert(columnname) on tablename to username;
grant update(columnname) on tablename to username;
```

* 查询当前用户对象权限

```sql
select * from user_tab_privs;-- 表
select * from user_clo_privs;-- 列
```

#### 权限传递

* 赋予用户权限，被赋权限用户可以继续赋予其他用户

```sql
grant select on tablename to username with admin option;
grant alter any table to username with admin option;
grant select on tablename to username with grant option;
```

### 角色

```sql
create role rolename;
grant create session to rolename;
grant rolename to username;
-- 有些权限无法赋给角色，如unlimited tablespace
drop role rolename;
```

### 登陆验证机制

* 操作系统验证(首先采用)
* 密码文件验证
* 数据库验证

* 启动过程

linux

```shell
# new version
lsnrctl start
sqlplus sys/oracle as sysdba
startup
# old version
lsnrctl start
sqlplus /nolog
conn sys/oracle as sysdba
startup
```

windows

```bat
lsnrctl start
oradmin -startup -sid orcl
```

* 修改密码

```sql
alter user username identified by password;
```

### 表操作

```sql
CREATE TABLE tablename AS SELECT * FROM tablename1; -- 创建表并复制数据
INSERT INTO tablename (SELECT * FROM tablename1);
DROP TABLE tablename

ALTER TABLE tablename ADD (id NUMBER);
ALTER TABLE tablename MODIFY (id VARCHAR(10));
ALTER TABLE tablename DROP COLUMN ID;
ALTER TABLE tablename ADD CONSTRAINT pk_tablename PRIMARY KEY (id);
ALTER TABLE TABLENAME ADD CONSTRAINT fk_tablename FOREIGN KEY (EMPNO) REFERENCES EMP(EMPNO);
ALTER TABLE tablename DROP CONSTRAINT pk_tablename;

SELECT * FROM tablename;
DELETE FROM tablename;
```

### 索引

增加了查询效率，降低了插入效率

```sql
CREATE INDEX idx_tablename_columnname ON TABLENAME (columnname);
show index from tablename;
show keys from tablename;
```

### 序列

```sql
CREATE SEQUENCE SEQUENCE_NAME;

SELECT SEQUENCE_NAME.nextval FROM dual;
SELECT SEQUENCE_NAME.currval FROM dual;

SELECT SEQUENCE_NAME FROM USER_SEQUENCES;
```

### 字符串

```sql
select to_char(sal,'999,999,999.99') FROM EMP;-- 2,975.00
select to_char(sal,'L999,999,999.99') FROM EMP;-- ￥2,975.00
select to_char(sal,'000000.00') FROM EMP;-- 002975.00
select to_number('002975.00','000000.00') FROM dual;-- 2975
```

```sql
select col1 || col2 from tablename;
-- 两个引号转义成一个引号
select 'a' || 'b''c' from dual;-- abc
```

```sql
-- 指定转义字符
SELECT * FROM BONUS WHERE BONUS.ENAME LIKE '%$%%' ESCAPE '$';
-- 使用'转义'
SELECT * FROM BONUS WHERE BONUS.ENAME LIKE '%''%';
```

### 组函数

```sql
SELECT max(SAL) FROM EMP;
SELECT min(SAL) FROM EMP;
SELECT avg(SAL) FROM EMP;
SELECT round(avg(SAL),2) FROM EMP;-- 四舍五入两位
SELECT sum(SAL) FROM EMP;
SELECT count(*) FROM EMP;-- 非空字段
SELECT count(DISTINCT JOB) FROM EMP;

-- 不使用组函数获取最大值
SELECT
  SAL
FROM (
  SELECT
    ROWNUM ,
    EMP.*
  FROM EMP ORDER BY SAL DESC
) t WHERE ROWNUM <2
```

### 分组

```sql
SELECT JOB,count(*) FROM EMP GROUP BY JOB;
SELECT JOB,DEPTNO,count(*) FROM EMP GROUP BY JOB,DEPTNO;
SELECT ENAME FROM EMP WHERE COMM = (SELECT max(COMM) FROM EMP);

SELECT DEPTNO,avg(COMM) AVG_COMM FROM EMP 
WHERE JOB!='KING' GROUP BY DEPTNO 
HAVING avg(COMM)>350 ORDER BY AVG_COMM DESC
```

### 子查询

```sql
-- 查询每个部分薪水最高的员工和薪水
SELECT
  EMP.ENAME,
  SAL,
  t.DEPTNO
FROM EMP, (SELECT
             DEPTNO,
             MAX(SAL) MAXSAL
           FROM EMP
           GROUP BY DEPTNO) t
WHERE EMP.DEPTNO = t.DEPTNO AND EMP.SAL = t.MAXSAL

-- 查询部门平均薪资等级
SELECT
  SALGRADE.GRADE,
  t.DEPTNO,
  t.AVGSAL
FROM SALGRADE
  JOIN
  (SELECT
     DEPTNO,
     avg(SAL) AVGSAL
   FROM EMP
   GROUP BY DEPTNO) t ON
                        t.AVGSAL > SALGRADE.LOSAL AND t.AVGSAL < SALGRADE.HISAL;

-- 查询领导姓名
SELECT
  t1.EMPNO,
  t1.ENAME,
  t2.ENAME MGRNAME
FROM EMP t1, EMP t2
WHERE t1.MGR = t2.EMPNO;

-- 部门员工薪水等级的平均值
SELECT
  avg(GRADE),
  DEPTNO
FROM (
       SELECT
         DEPTNO,
         SALGRADE.GRADE
       FROM EMP
         LEFT JOIN SALGRADE ON EMP.SAL BETWEEN SALGRADE.LOSAL AND SALGRADE.HISAL) t
GROUP BY DEPTNO

-  不使用组函数获取最大值
SELECT SAL
FROM EMP
WHERE EMP.SAL NOT IN (
  SELECT DISTINCT e1.SAL
  FROM EMP e1, EMP e2
  WHERE e1.SAL < e2.SAL)

-- 平均薪水最高的部门
SELECT
  DEPTNO
FROM EMP
GROUP BY DEPTNO
HAVING avg(SAL) = (
  SELECT max(AVGSAL)
  FROM (
    SELECT
      DEPTNO,
      avg(SAL) AVGSAL
    FROM EMP
    GROUP BY DEPTNO
  )
)

SELECT DEPTNO
FROM (SELECT
        DEPTNO,
        avg(SAL) AVGSAL
      FROM EMP
      GROUP BY DEPTNO)
WHERE AVGSAL = (
  SELECT max(AVGSAL)
  FROM (
    SELECT
      DEPTNO,
      avg(SAL) AVGSAL
    FROM EMP
    GROUP BY DEPTNO
  )
)
```

### 空值

```sql
SELECT nvl(COMM, 0) FROM EMP;
```

### 时间

```sql
select sysdate from dual
SELECT to_date('1992-2-2','yyyy-MM-dd') FROM dual;
SELECT to_char(sysdate,'yyyy-MM-dd') FROM dual;
```

### 分页

```sql
-- 第一层：获取数据物理地址
-- 第二层：取得最大页数
-- 第三层：取得最小页数
-- 第四层：因为取得的页数都是物理地址，再根据物理地址，插叙出具体数据

--rowid分页，第一步
SELECT
  rowid rid
FROM emp
ORDER BY sal DESC;
--rowid分页，第二步
SELECT
  rownum rn,
  rid
FROM (SELECT
        rowid rid
      FROM emp
      ORDER BY sal DESC)
WHERE rownum < 10;
--rowid分页，第三步
SELECT rid
FROM (SELECT
        rownum rn,
        rid
      FROM (SELECT
              rowid rid
            FROM emp
            ORDER BY sal DESC)
      WHERE rownum < 10)
WHERE rn > 5;
--rowid分页，第四步
SELECT *
FROM emp
WHERE rowid IN (SELECT rid
                FROM (SELECT
                        rownum rn,
                        rid
                      FROM (SELECT
                              rowid rid
                            FROM emp
                            ORDER BY sal DESC)
                      WHERE rownum < 10)
                WHERE rn > 5);
```

### 修改编码

```shell
shutdown immediate;
startup mount;
ALTER SYSTEM ENABLE RESTRICTED SESSION;
ALTER SYSTEM SET JOB_QUEUE_PROCESSES=0;
ALTER SYSTEM SET AQ_TM_PROCESSES=0;
alter database open;
alter database character set INTERNAL_USE UTF8;
shutdown immediate;
startup;
exit;
```

### 备份还原

```shell
export ORACLE_SID=orcl
export ORACLE_HOME=/oracle/product/11gR1/db
export PATH=$PATH:.:/oracle/product/11gR1/db/bin

# 整个库备份还原
expdp system/manager DIRECTORY=dpdata1 DUMPFILE=full.dmp FULL=y;
impdb system/manager DIRECTORY=dump_dir DUMPFILE=full.dmp FULL=y;
```

### ORA错误

#### ORA-00845

```shell
mount -o size=2G -o nr_inodes=1000000 -o noatime,nodiratime -o remount /dev/shm
```

## 三范式

* 列不可分
* 要有主键，不能存在部分依赖，确保表中的每列都和主键相关（多对多关系拆分成三张表，防止非主键列部分依赖主键）
* 非主键列必须直接依赖于主键，不能存在传递依赖，（避免查询路径过长而导致询问时间过长或者更新异常）

## 行转列

### 静态拼接行转列

```sql
SELECT DISTINCT
  PRODID             AS ID,
  sum(CASE WHEN color = 'r'
    THEN COUNTS END) AS red,
  sum(CASE WHEN color = 'b'
    THEN COUNTS END) AS blue,
  sum(CASE WHEN color = 'y'
    THEN COUNTS END) AS yellow
FROM
  PROD
GROUP BY PRODID;
```

## 优化

* 表建立索引
* 查询时最左索引原则（索引列条件靠近where）

------

*以上概念总结于传智播客JavaWeb课程*