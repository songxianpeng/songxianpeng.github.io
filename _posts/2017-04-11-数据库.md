---
layout: post
title: 数据库
tags: Database
categories: Database
published: true
---

数据查询语言DQL（表记录查询），数据操纵语言DML(表记录操作，需要提交事务)，数据定义语言DDL（库或表结构操作），数据控制语言DCL（数据库操作及授权）。

## Mysql

### install

```shell
wget http://dev.mysql.com/get/Downloads/MySQL-5.6/MySQL-5.6.16-1.el6.x86_64.rpm-bundle.tar

rpm -ivh MySQL-client-5.6.16-1.el6.x86_64.rpm
rpm -ivh MySQL-devel-5.6.16-1.el6.x86_64.rpm
rpm -ivh MySQL-server-5.6.16-1.el6.x86_64.rpm
# 更新数据库
sudo mysql_upgrade -u root -p

/etc/my.cnf
/etc/mysql/my.cnf

[mysqld]
bind-address=0.0.0.0
lower_case_table_names=
```

### 启动和停止

#### windows

```bat
net start mysql
net stop mysql

myql -uroot -ppass -hlocalhost
```

#### linux

```shell
service mysqld start
service mysqld stop
/etc/init.d/mysql restart
```

### 创建用户和授权

```sql
select * from mysql.user;
-- 使用安装时生成的默认密码登陆并首次初始化
set password=PASSWORD('admin');
GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY 'admin' WITH GRANT OPTION;

-- 指定IP上登陆
CREATE USER username@ip IDENTIFIED BY 'password';
-- 任意IP登陆
CREATE USER username@'%' IDENTIFIED BY 'password';
SET PASSWORD FOR username=PASSWORD('password');
-- 关闭数据库安全修改（批量更新和删除会报错）
SET SQL_SAFE_UPDATES=0;
```

```sql
GRANT create,alter,drop,insert,update,delete,select ON databasename.* TO username@localhost;
GRANT all ON databasename.* TO username@localhost;
GRANT ALL PRIVILEGES ON *.* TO 'xpress'@'%' IDENTIFIED BY 'admin' WITH GRANT OPTION;
REVOKE all ON databasename.* FROM username@localhost;
FLUSH PRIVILEGES;
SHOW GRANTS FOR username@localhost;
```

### 数据库操作

```sql
show global variables like '%datadir%';
-- 创建数据库
CREATE DATABASE databasename CHARSET=utf8;
-- 删除数据库
DROP DATABASE databasename;
-- 修改数据库
ALTER DATABASE databasename CHARACTER SET utf8;
-- 查看数据
show databases;
-- 数据库切换
use databasename;
```

### 数据类型

| 类型       | 名称               | 备注                                                         |
| ---------- | ------------------ | ------------------------------------------------------------ |
| int        | 整型               |                                                              |
| double     | 浮点型             | double(5,2)表示最多五位，其中有两位是小树，最大值为999.99    |
| decimal    | 浮点型             | 不会出现精度缺失问题                                         |
| char       | 固定长度字符串类型 | char(255)，数据长度不足时补足到指定长度                      |
| varchar    | 可变长度字符串类型 | varchar(65535) 会占用字节存储实际长度                        |
| text(clob) | 字符串类型         | tinytext 2^8-1,text 2^16-1,mediumtext 2^24-1,longtext 2^32-1 |
| blob       | 字节类型           | tinyblob 2^8-1,blob 2^16-1,mediumblob 2^24-1,longblob 2^32-1 |
| date       | 日期类型           | yyyy-MM-dd                                                   |
| time       | 时间类型           | hh:mm:ss                                                     |
| tomestamp  | 时间戳类型         |                                                              |

*ps:使用blob类型时，在my.ini中配置调整允许发送的包大小*

```ini
max_allowed_packet=10485760
```

### 表操作

#### 创建和删除表

```sql
CREATE TABLE IF NOT EXISTS tablename(
    columnname int,
    columnname1 char(255)
);
DROP TABLE tablename
```

#### 查看表

```sql
show tables;
-- 查看创建语句
show create table tablename;
-- 查看表结构
desc tablename;
```

#### 修改表

* 修改表名

```sql
ALTER TABLE tablename tablename RENAME TO newtablename;
```

* 增加列

```sql
ALTER TABLE tablename ADD(
    columnname int,
    columnname1 char(20)
)
```

* 修改列类型

如果别修改列已存在数据，那么新的类型可能影响已存在的数据

```sql
ALTER TABLE tablename MODIFY columnname int;
```

* 修改列名

```sql
ALTER TABLE tablename CHANGE columnname newcolumnname int;
```

* 删除列

```sql
ALTER TABLE tablename DROP columnname;
```

### 数据操作

#### 插入

```sql
INSERT INTO tablename(columnname,columnname1) values ('value','value');
-- 与创建表时顺序相同
INSERT INTO tablename values ('value','value');
```

#### 更新

```sql
UPDATE tablename SET columnname='value',columnname1='value' where columnname='value';
```

查询条件

| 运算符                   | 备注                                                 |
| ------------------------ | ---------------------------------------------------- |
| `=`                      |                                                      |
| `!=`或`<>`               |                                                      |
| `>`、`<`和`<=`、`>=`     |                                                      |
| `BETWEEN AND`            | 检查你的数据库是如何处理 BETWEEN....AND 操作符边界的 |
| `IN(...)`                |                                                      |
| `IS NULL`和`IS NOT NULL` | =NULL必返回false                                     |
| `NOT`                    |                                                      |
| `OR`和`AND`              |                                                      |

#### 删除

```sql
DELETE FROM tablename WHERE columnname = 'value';
```

#### 查询

##### 单表查询

###### 检索去重

```sql
SELECT * FROM tablename;
-- 去除重复
SELECT DISTINCT columnname FROM tablename;
-- 查询到文件 需要权限
select count(1) from table into outfile '/tmp/1.xls';
-- 不需要权限
echo "select * from db_web.help_cat where 1 order by sort desc limit 0,20" | mysql -h127.0.0.1 -uroot > /data/sort.xls
```

###### 运算

```sql
SELECT columnname*1.5 FROM tablename;
-- 防止NULL值相加变成NULL
SELECT columnname+ifnull(columnname1,0) FROM tablename;
```

###### 拼接

```sql
SELECT CONCAT(columnname,'--',columnname1) as alias FROM tablename;
```

###### 模糊查询

```sql
SELECT * FROM tablename WHERE columnname LIKE 'value_';
```

| 符号 | 匹配规则      |
| :--: | :---------:   |
| _    | 匹配一个字符  |
| %    | 匹配0~n个字符 |

###### 排序

```sql
-- 默认ASC升序
SELECT * FROM tablename ORDER BY columnname ASC;
-- 多列排序
SELECT * FROM tablename ORDER BY columnname ASC,columnname1 DESC;
```

###### 聚合函数

```sql
-- 总数，列信息不为NULL则计数，*所有列不为NULL计数
SELECT COUNT(*) FROM tablename;
SELECT MIN(*) FROM tablename;
SELECT MAX(*) FROM tablename;
SELECT SUM(*) FROM tablename;
SELECT AVG(*) FROM tablename;
-- 组合使用
SELECT COUNT(*),MAX(columnname),AVG(columnname) FROM tablename;
```

###### 分组

```sql
-- 分组前条件用WHERE
-- 分组后条件用HAVING
SELECT 
    columnname,
    columnname1,
    COUNT(*),
    MAX(columnname),
    AVG(columnname2)
FROM
    tablename
WHERE
    columnname IS NOT NULL
GROUP BY columnname , columnname1
HAVING COUNT(*) > 1;
```

###### LIMIT方言

```sql
-- LIMIT begin,count 6-15
SELECT * FROM tablename LIMT 5,10;
```

##### 多表查询

###### 合并结果集

    - 两个结果集的列相同，结果在同列显示

```sql
-- 不去重
SELECT * FROM tablename
UNION ALL
SELECT * FROM tablename1
-- 去除重复
SELECT columnname FROM tablename
UNION
SELECT columnname FROM tablename1
```

###### 连接查询

    - 内连接
    - 外连接
        + 左外连接
        + 右外连接
        + 全外连接（mysql不支持）
    - 自然连接

*内连接*

必须满足两张表都有数据

```sql
-- 方言版本
SELECT * FROM tablename,tablename1 WHERE tablename.columnname = tablename1.columnname;
-- 标准版本
SELECT * FROM tablename INNER JOIN tablename1 ON tablename.columnname = tablename1.columnname;
-- 自然内连接：自动匹配两个table列名相同的列
SELECT * FROM tablename NATURAL JOIN tablename1;
```

*外连接*

外连接一主一次，左外左表为主，主表所有数据都会显示，不满足条件的右表数据为NULL

```sql
-- 左外连接
SELECT * FROM tablename LEFT OUTER JOIN tablename1 ON tablename.columnname = tablename1.columnname;
-- 右外连接
SELECT * FROM tablename RIGHT OUTER JOIN tablename1 ON tablename.columnname = tablename1.columnname;
-- 全外链接，左右表结构都在，不符合条件补NULL（mysql不支持）
SELECT * FROM tablename FULL OUTER JOIN tablename1 ON tablename.columnname = tablename1.columnname;
-- 使用合并结果集模拟全外连接
SELECT * FROM tablename LEFT OUTER JOIN tablename1 ON tablename.columnname = tablename1.columnname;
UNION
SELECT * FROM tablename RIGHT OUTER JOIN tablename1 ON tablename.columnname = tablename1.columnname;
-- 自然外连接：同自然内连接
```

###### 子查询

子查询条件组合

| 子查询结果集 | 可嵌套条件          |
| ------------ | ------------------- |
| 单行单列     | =、>、<、>=、<=、!= |
| 多行单列     | IN、ALL、ANY        |
| 单行多列     | 多列IN多列          |
| 多行多列     | 当作表连接查询      |

```sql
-- 单行单列
SELECT * FROM tablename WHERE columnname = (SELECT MAX(columnname) FROM tablename);
-- 多行单列
SELECT * FROM tablename WHERE columnname > ANY (SELECT columnname FROM tablename WHERE columnname1 = 'value');
SELECT * FROM tablename WHERE columnname > ALL (SELECT columnname FROM tablename WHERE columnname1 = 'value');
SELECT * FROM tablename WHERE columnname IN (SELECT columnname FROM tablename WHERE columnname1 = 'value');
-- 单行多列
SELECT * FROM tablename WHERE columnname,columnname1 IN (SELECT columnname,columnname1 FROM tablename WHERE columnname1 = 'value');
-- 多行多列 结果集为表要有别名
SELECT MAX(columnname) FROM (SELECT * FROM tablename  WHERE columnname < 'value') alias;
```

### 约束

* 非空约束
* 唯一约束
* 检查约束
* 主键约束
* 外键约束

#### 主键约束

* 非空
* 唯一
* 被引用（外键）

```sql
CREATE TABLE tablename (
    columnname INT PRIMARY KEY AUTO_INCREMENT,-- 自增长，必须整型
    columnname1 VARCHAR(20)
)

CREATE TABLE tablename (
    columnname INT,
    columnname1 VARCHAR(20),
    PRIMARY KEY (columnname)
)

ALTER TABLE tablename ADD PRIMARY KEY(columnname);
ALTER TABLE tablename DROP PRIMARY KEY;
```

#### 非空约束

```sql
CREATE TABLE tablename (
    columnname INT,
    columnname1 VARCHAR(20) NOT NULL -- 非空
)
```

#### 唯一约束

```sql
CREATE TABLE tablename (
    columnname INT,
    columnname1 VARCHAR(20) UNIQUE -- 唯一
)
```

#### 外键约束

* 外键必须是另一个表的主键（另一个表也可以是本表）
* 外键可以重复
* 外键可以为空
* 一张表可以有多个外键

```sql
CREATE TABLE tablename (
    columnname INT,
    columnname1 VARCHAR(20),
    CONSTRAINT fkname FOREIGN KEY (columnname1)
        REFERENCES tablename1 (colunmname) -- 指定外键，外键名和列名可以不同
)

ALTER TABLE tablename ADD
    CONSTRAINT fkname FOREIGN KEY (columnname1)
        REFERENCES tablename1 (colunmname)
```

##### 一对一关系

从表的主键既是外键

##### 一对多关系

普通外键表示一对多关系

##### 多对多关系

中间表两个外键映射多对多关系

### 事务

```sql
-- 开启事务
start transaction;
-- 提交事务
commit;
-- 回滚事务
rollback;
-- 查看隔离级别
select @@global.tx_isolation, @@tx_isolation;
select @@autocommit;
-- 查看支持的引擎
show engines;
-- 查看当前引擎
show variables like '%storage_engine%';
-- 查看引擎状态，查询上一次死锁
show engine innodb status;
-- 查看最近执行语句
select * from information_schema.innodb_trx;
-- 设置隔离级别isolationlevel 4选1
set transaction isolationlevel;
-- 查询正在进行的语句
show processlist;
kill <id>;
```

### 视图

视图是由查询结果形成的一张虚拟表，示表通过某种运算得到的一个投影

#### 作用

* 可以简化查询
* 可以进行权限控制
    - 表权限关闭，视图中放表的部分数据

#### 创建、修改和删除视图

```sql
create view view_name as select.....  
alter view view_name as select.....  
drop view view_name
```

* 视图和表同一级别，隶属于数据库
* 视图可以设定自己的字段名，通常不设置

#### 查询视图

同查询表，可以使用where

**查看所有视图**

```sql
show tables;
```

**查看视图结构**

```sql
desc view_name
```

#### 插入视图

* 视图必须包含表中没有默认值的所有列，才可以进行插入
* 一般来说，属兔只是用来查询的不应该执行增删改操作。

### 存储过程

把一段代码封装起来，当要调用这段代码时，可以通过调用储存过程实现。

* 经过一次编译后再次调用不需要再次编译
* 权限控制
* 可复用，配合数据库事务一起使用

```sql
show procedure status; --查询现有存储过程
```

#### 创建、删除存储过程

```sql
create procedure p_name(num int)
begin
...
end

drop procedure p_name;
```

#### 调用存储过程

```sql
call p_name(1);
```

#### 语句结束符

```xml
delimiter $
select * from users$
```

#### 变量

##### 会话变量

在编程环境和非编程环境都可以使用

```sql
set @var_name = 'value';
select @var_name;
```

##### 普通变量

在编程环境使用（存储过程、函数、触发器）

```sql
declare var_name type_name default default_value;
set varname = 'value';
```

##### 变量赋值

```sql
set @var_name = 表达式;
set varname = 表达式;
select @var_name := 表达式; -- 赋值并查询结果
select 表达式 into @var_name;
```

##### 系统变量

以@@开头的都是系统变量

```sql
SELECT @@version;
```

#### 运算符

略

#### 标识符

![begin_label.png](/static/img/数据库/begin_label.png "begin_label.png")

#### 条件

##### if判断

```sql
CREATE PROCEDURE p_name(num INT)
  BEGIN
    IF num = 1
    THEN
      SELECT...
    ELSEIF num = 2
      THEN
        SELECT...
    ELSE
      SELECT...
    END IF;
  END;
```

##### case判断

```sql
CREATE PROCEDURE p_name(num INT)
  BEGIN
    CASE num
      WHEN 1
      THEN
        SELECT 'spring' AS 'season';
      WHEN 2
      THEN
        SELECT 'summer' AS 'season';
      WHEN 3
      THEN
        SELECT 'autumn' AS 'season';
    ELSE SELECT '' AS 'season';
    END CASE;
  END;
```

##### loop循环

```sql
CREATE PROCEDURE p_name(num INT)
  BEGIN
    DECLARE current INT DEFAULT 1;
    DECLARE result INT DEFAULT 0;
    operate: LOOP
      SET result = current + result;
      SET current = current + 1;
      IF current > num
      THEN
        LEAVE operate;
      END IF;
    END LOOP;
    SELECT result;
  END;
```

##### while循环

```sql
CREATE PROCEDURE p_name(num INT)
  BEGIN
    DECLARE current INT DEFAULT 1;
    DECLARE result INT DEFAULT 0;
    WHILE current <= num DO

      SET result = current + result;
      SET current = current + 1;

    END WHILE;

    SELECT result;
  END;
```

##### repeat循环

```sql
CREATE PROCEDURE p_name(num INT)
  BEGIN
    DECLARE current INT DEFAULT 1;
    DECLARE result INT DEFAULT 0;
    REPEAT

      SET result = current + result;
      SET current = current + 1;

    UNTIL current > num
    END REPEAT;

    SELECT result;
  END;
```

#### 参数

* 输入参数（in，默认）
* 输出参数（out）
* 输入输出参数（inout）

```sql
CREATE PROCEDURE p_name(IN n INT, OUT result INT)
  BEGIN
    SET result = n * n;
  END;

SET @result = 0;
CALL p_name(100, @result);
SELECT @result;
```

```sql
CREATE PROCEDURE p_name(INOUT n INT)
  BEGIN
    SET n = n * n;
  END;

SET @n = 100;
CALL p_name(@n);
SELECT @n;
```

### 函数

创建的函数是隶属于库的，只能在创建函数的库中使用

* 函数内部可以有各种编程语言的元素（变量，流程控制，函数调用）
* 函数内部可以有增删改等语句
* 函数内部不可以有select、show、desc这种返回结果集的语句

#### 创建函数

```sql
CREATE FUNCTION mySum(n INT, m INT)
  RETURNS INT
  BEGIN
    RETURN m + n;
  END;

SELECT mySum(1, 2);
DROP FUNCTION mySum;
```

#### 系统函数

##### 数字

```sql
SELECT rand();

SELECT *
FROM users
ORDER BY rand()
LIMIT 2; -- 随机取出2个人

SELECT floor(3.9); -- 3
SELECT ceil(3.1); -- 4
SELECT round(3.5); -- 4 四舍五入
```

##### 字符串

```sql
-- 大小写转换
SELECT ucase('Hello');
SELECT lcase('Hello');
```

```sql
SELECT left('abcdef', 3); -- abc
SELECT right('abcdef', 3); -- def
SELECT substr('abcdef', 2, 3); -- bcd，从2开始截取3个，位置从1开始
SELECT concat('abcdef', 3); -- abcdef3
SELECT concat(USERNAME, '-', NICKNAME) FROM users;
SELECT coalesce(NULL, 123); -- 123 如果第一个值为null，就显示第二个值

SELECT length('abcdef'); -- 6
SELECT length('你好'); -- 6 字节个数
SELECT char_length('你好'); -- 2 字符个数
SELECT replace('abc','b','d'); -- adc
SELECT trim(' abc ');

-- 转义
SELECT * FROM BONUS WHERE BONUS.ENAME LIKE '%$%%' ESCAPE '$';-- 指定字符
SELECT * FROM BONUS WHERE BONUS.ENAME LIKE '%\'%';-- 默认转义为\
SELECT * FROM BONUS WHERE BONUS.ENAME LIKE '%''%';-- 是哦那个'转义'
```

##### 时间

```sql
SELECT unix_timestamp();-- 1495179836
SELECT FROM_UNIXTIME(unix_timestamp(),'%y-%m-%d');-- 17-05-19
SELECT FROM_UNIXTIME(unix_timestamp(),'%Y-%m-%d');-- 2017-05-19
SELECT curdate();-- 2017-05-19
SELECT now();-- 2017-05-19 15:44:46
SELECT
  year(now()),
  month(now()),
  day(now()),
  hour(now()),
  minute(now()),
  second(now());
SELECT datediff(now(),'1997-1-1');-- 7443天

SELECT date_sub(curdate(),INTERVAL 1 DAY);-- 2017-05-18
SELECT date_add(curdate(),INTERVAL 1 DAY);-- 2017-05-20
SELECT date_sub(curdate(),INTERVAL 1 HOUR);-- 2017-05-18 23:00:00

SELECT date_format(curdate(),'%Y-%m-%d');
SELECT str_to_date('2017-07-05 17:08:00','%Y-%m-%d %H:%i:%s');
select id from creative where update_time between str_to_date('2017-09-13 19:00:00','%Y-%m-%d %H:%i:%s') and now();
```

##### 表达式

```sql
SELECT concat(10, if(10 % 2 = 0, '偶数', '奇数'));
```

### 触发器

* 是一个特殊的存储过程，在insert、update、delete的时候自动执行的代码块
* 触发器必须定义在特定的表上
* 自动执行，不能直接调用

目前mysql不支持多个具有同一动作、同一时间、同一事件、同一地点的触发器

#### 触发器使用

```sql
SHOW TRIGGERS;
DROP TRIGGER t_name;

-- 对于新增而言，新增的行用new来表示
CREATE TRIGGER t_name
AFTER INSERT ON orderdetails
FOR EACH ROW
  BEGIN
    UPDATE items
    SET COUNT = COUNT - NEW.COUNT
    WHERE ID = NEW.ITEM_ID;
  END;
-- 对于删除而言，删除的行用old来表示
CREATE TRIGGER t_name
AFTER DELETE ON orderdetails
FOR EACH ROW
  BEGIN
    UPDATE items
    SET COUNT = COUNT + OLD.COUNT
    WHERE ID = OLD.ITEM_ID;
  END;
-- 更新前NEW和更新后OLD
CREATE TRIGGER t_name
AFTER UPDATE ON orderdetails
FOR EACH ROW
  BEGIN
    UPDATE items
    SET COUNT = COUNT + OLD.COUNT
    WHERE ID = OLD.ITEM_ID;
    UPDATE items
    SET COUNT = COUNT - NEW.COUNT
    WHERE ID = NEW.ITEM_ID;
  END;
```

#### before和after区别

* after是先完成数据的增删改，再触发，触发器中的语句晚于监视的增删改，无法影响前面的增删改动作
* before是完成触发，再做增删改，触发的语句优于监视的增删改发生，我们有机会判断修改即将发生的操作。

```sql
CREATE TRIGGER t_name
BEFORE UPDATE ON orderdetails
FOR EACH ROW
  BEGIN
    IF NEW.COUNT > 5
    THEN
      SET NEW.COUNT = 5;
    END IF;
  END;
```

### 编码

* 查询编码

```sql
SHOW VARIABLES LIKE 'char%';
```

| 变量名                | 作用       | 备注                          |
| --------------------- | ---------- | ----------------------------- |
| character_set_client  | 客户端编码 | mysql解析客户端发送数据的编码 |
| character_set_results | 结果集编码 | mysql返回结果集的编码         |

* 修改编码

```sql
-- 只在当前窗口有效
set character_set_client=gbk;
set character_set_results=gbk;
```

```ini
# 在配置文件中修改永久有效
# 影响三个变量：client、results、connection
[mysql]

default-character-set=utf8
```

### 高可用和可扩展

为了保证站点可响应和可用，需要三样东西：数据备份，系统冗余和响应性。

* 备份可以将节点恢复到崩溃前的状态
* 即使一个或多个节点停止运行，冗余也可以使站点继续运行
* 响应能力使系统在实践生产中可用

#### 复制

复制的两种最常见的用途是：

* 创建主服务器的备份，以避免主服务器崩溃时丢失任何数据
* 让主服务器的副本执行报表和分析工作，而不会影响其他业务

复制可以做的更多：

* 支持多个机房
* 有服务器停机时高可用
* 灾备
* 错误保护
	* slave比master落后一个周期，在master上发生错误时，找到出错的语句，在slave执行前删除它

在横向扩展场景中使用复制时，重要的是要明白，MySQL复制传统上是异步的，因为事务首先在主服务器上提交，
然后复制到从服务器并在此处应用。这意味着master和slave可能不一致，如果复制持续运行，则slave将落后于master。

使用异步复制的优点是它比同步复制更快、更有效，但是在需要有实时数据的情况下，必须处理不同步的问题以确保信息的时效性。

#### MySQL复制原理

* 通过热备份达到高可用性
* 产生报表
	* 创建一个额外的服务器来运行大量的后台作业
* 调试和审计

##### 复制的基本步骤

系统创建一个能访问关键文件的shell用户。

```conf
# master
[mysqld]
user            = mysql
pid-file        = /var/run/mysqld/mysqld.pid
socket          = /var/run/mysqld/mysqld.sock
port            = 3306
basedir         = /usr
datadir         = /var/lib/mysql
tmpdir          = /tmp
# 默认hostname-bin，来自pid-file选项
# 使用默认值有一个问题就是hostname一旦改变会找不到文件，下同
log-bin         = master-bin
# 默认与上面同名
log-bin-index   = master-bin.index
server-id       = 1
```

```conf
# slave
[mysqld]
user            = mysql
pid-file        = /var/run/mysqld/mysqld.pid
socket          = /var/run/mysqld/mysqld.sock
port            = 3306
basedir         = /usr
datadir         = /var/lib/mysql
tmpdir          = /tmp
# 与master不重复
server-id       = 2
relay-log-index = slave-relay-bin.index
relay-log       = slave-relay-bin
```

```sql
-- master server创建一个复制用户
CREATE USER repl_user;
GRANT REPLICATION SLAVE ON *.* TO repl_user IDENTIFIED BY 'password';
```

```sql
-- 配置master和slave的用户，slave上执行
-- 需要FLUSH LOGS、SHOW MASTER\SLAVE STAUS、CHANGE MASTER TO 、等命令的权限
GRANT REPLICATION SLAVE, RELOAD, CREATE USER, SUPER ON *.* TO mats@'192.168.2.%' WITH GRANT OPTION;
```

```sql
-- slave上使用mats执行
CHANGE MASTER TO MASTER_HOST = 'master-1',MASTER_PORT = 3306,MASTER_USER = 'repl_user',MASTER_PASSWORD = 'password';
```

```sql
-- 删除并清空二进制文件，确保没有slave链接到master
RESET MASTER;
-- 删除复制用的所有文件
STOP SLAVE;-- 首先执行确保没有活动的复制
RESET SLAVE;
```

##### 建立新slave（增加）

自举slave，而不是从头开始复制。参考《二进制日志》部分

1. 配置新的slave
2. 备份master（或者slave）
3. 记录备份的binlog位置
4. 从新的slave上恢复
5. 配置slave从binlog位置开始恢复

**方式1：克隆master**

这种方式需要离线master

_手动过程：_

```sql
-- 刷新所有表并锁定
FLUSH TABLES WITH READ LOCK;
SHOW MASTER STATUS\G
```

```conf
# binlog下一个写入位置为456552
*************************** 1. row ***************************
             File: mysql-bin.0000042
         Position: 456552
     Binlog_Do_DB: 
 Binlog_Ignore_DB: 
```

```shell
# 备份master
mysqldump --all-databases --host=master-1 >backup.sql
```

```sql
UNLOCK TABLES;
```

```shell
# 导入slave
mysql --host=slave-1 <backup.sql
```

```sql
CHANGE MASTER TO MASTER_HOST = 'master-1', MASTER_PORT = 3306, MASTER_USER = 'slave-1', MASTER_PASSWORD = 'password', MASTER_LOG_FILE = 'master-bin.000042', MASTER_LOG_POS = 456552;
START SLAVE;
```

_自动过程：_

```shell
# 自动生成CHANGE MASTER TO语句
mysqldump --host=master -all-databases --master-data=1 >backup-source.sql
```

```shell
mysql --host=slave-1 <backup-source.sql
```

**方式2：克隆slave**

```sql
STOP SLAVE;
SHOW SLAVE STATUS \G
```

执行后可以创建备份，参考《克隆master》部分

```conf
...
Relay_Master_Log_File: master-bin.000042
...
Exec_Master_Log_Pos: 546632
```

```sql
START SLAVE;
```

FLUSH TABLES WITH READ LOCK在InnoDB中使用是不安全的，后台仍有一些阻止不了的活动在运行，下面方法可安全的创建InnoDB数据表的备份：

* 关闭服务器并复制文件。 如果数据库很大，这可能是一个优势，因为使用mysqldump恢复数据可能会很慢。
* 在执行FLUSH TABLES WITH READ LOCK之后使用mysqldump（如上面的操作过程）。
	* 读取锁定可防止读取数据时发生更改。
	* 如果要读取大量数据，数据库可能会长时间处于锁定状态。
	* 可以使用--single-transaction选项获取一致的快照，但只有在使用InnoDB表时才可能。
* 在使用FLUSH TABLES WITH READ LOCK锁定数据库的同时，使用LVM（在Linux上）或ZFS（在Solaris上）等快照解决方案。
* 使用MySQL企业备份（或XtraBackup）进行MySQL的联机备份。

##### 执行常见的复制任务

横向扩展、热备份等

```sql
-- 查看二进制文件名称
SHOW BINARY LOGS;
```

```shell
# 停止slave后，指定binlog文件名称并指定binlog同步的日期区间来解析binlog内容
mysqlbinlog --force --read-from-remote-server --host=reporting.bigcorp.com --start-datetime='2009-09-25 23:55:00' --stop-datetime='2009-09-25 23:59:59' capulet-bin.000004
```

```sql
# 解析结果：
	.
	.
# at 2495
#090929 23:58:36 server id 1  end_log_pos 2650  Query   thread_id=27    exe...
SET TIMESTAMP=1254213690/*!*/;
SET /*!*/;
INSERT INTO message_board(user, message)
     VALUES ('mats@sun.com', 'Midnight, and I'm bored')
/*!*/;
```

```sql
-- 开启slave直到指定位置停止
START SLAVE UNTIL MASTER_LOG_POS='capulet-bin.000004', MASTER_LOG_POS=2650;
-- 阻塞检查直到同步完成，就可以进行其他操作了
SELECT MASTER_POS_WAIT('capulet-bin.000004',  2650);
```

任务调度：

```shell
# reporttab file content
# stop reporting slave five minutes before midnight, every day
55 23 * * * $HOME/mysql_control/stop_slave
# Run reporting script five minutes after midnight, every day
5 0 * * * $HOME/mysql_control/daily_report
```

```shell
crontab reporttab
```

#### 二进制日志

参考《复制》部分二进制日志的配置

复制过程中需要binlog，它记录了服务器数据库上的所有变更，对于不改变数据的语句不会写入二进制日志。  
二进制日志按照master上事务提交的顺序记录它们，每个事务在日志中是连续记录的，取决于事务提交的时间。

_Tips：master和slave上下文环境不完全一致的话，可能导致执行结果不同。MySQL还提供了基于行的复制_

##### 文件记录

```sql
-- 刷新binlog
FLUSH LOGS;
-- \G字段换行输出，只显示第一个
SHOW BINLOG EVENTS\G
SHOW BINLOG EVENTS IN 'master-bin.000002'\G
SHOW BINLOG EVENTS FROM 238\G
-- 查看正在写入的文件名称
SHOW MASTER STATUS\G
```

```log
*************************** 1. row ***************************
   Log_name: mysql-bin.000001
        Pos: 4
 Event_type: Format_desc
  Server_id: 1
End_log_pos: 107
       Info: Server ver: 5.5.34-0ubuntu0.12.04.1-log, Binlog ver: 4
*************************** 2. row ***************************
   Log_name: mysql-bin.000001
        Pos: 107
 Event_type: Query
  Server_id: 1
End_log_pos: 198
       Info: use `test`; CREATE TABLE tbl (text TEXT)
*************************** 3. row ***************************
...
*************************** 5. row ***************************
   Log_name: mysql-bin.000001
        Pos: 374
 Event_type: Xid
  Server_id: 1
End_log_pos: 401
       Info: COMMIT /* xid=188 */
*************************** 6. row ***************************
   Log_name: mysql-bin.000001
        Pos: 401
 Event_type: Rotate
  Server_id: 1
End_log_pos: 444
       Info: mysql-bin.000002;pos=4
6 rows in set (0.00 sec)
```

* Event_type：事件类型
* Server_id：事件服务器id
* Log_name：存储事件的文件名
* Pos：事件在文件中的开始位置
* End_log_pos：事件在文件中的结束位置
* Info：关于事件信息的可读文本

##### 结构和内容

二进制日志由一组包含真实内容的binlog文件和一个跟踪binlog文件存储位置的索引文件组成。  
有一个二进制文件是活动二进制文件，即当前被写入的文件。

![二进制日志的构成](/static/img/数据库/Structure-of-the-binary-log.png)

二进制日志文件都以格式描述时间开始，以日志轮换事件结束。

_注意事项：如果服务器突然停止或司机，binlog文件末尾可能不是轮换事件_

binlog文件中的事件组要么是不属于事务的单个语句，要么是由多条语句组成的事务。每个组要么全都执行，要么都不执行。

![包含多个事件组的单个binlog文件](/static/img/数据库/A-single-binlog-file-with-groups-of-events.png)

###### binlog事件的结构

* 通用头
	* 事件的基本信息，事件类型和事件大小
* 提交头
	* 与特定的事件类型有关
* 事件体
	* 存储事件的主要数据
* 校验和
	* 版本5.6开始可以产生，是一个32位整数，用于检查事件写入后是否有损坏
	* 默认开启，使用CRC32校验和

```shell
# 验证校验和
mysqlbinlog --verify-binlog-checksum master-bin.000001
```

##### 将语句写入日志

在事件组写二进制日志之前，二进制日志将获得一个互斥锁LOCK_log，然后在事件组写完成后释放。这个锁常常会阻塞某些会话线程。

###### 写入DML语句

数据操作语言（DML）语句通常是指DELETE，INSERT和UPDATE语句。  
为了以一致的方式支持日志记录更改，MySQL在获取了事务级锁的同时写入二进制日志，并在二进制日志写入后释放它们。

为了确保二进制日志与语句修改的表一致地更新，每个语句在语句提交期间都被记录到二进制日志中，就在表锁释放之前。
如果没有将日志记录作为语句的一部分，则可以在语句向数据库引入的更改和对二进制日志的语句的日志记录之间“注入”另一个语句。
这意味着语句将以不同的顺序记录，而不是在数据库中执行的顺序，这可能会导致manster和slave之间的不一致。

###### 写入DDL语句

数据定义语言(DDL)语句影响数据模式(schema)，例如CREATE TABLE和ALTER TABLE语句。
DDL语句会在文件系统中创建或改变对戏那个，例如表定义存储在.frm文件中，而数据表现为文件系统中的目录。因此服务洗需要将这些信息保存在内部数据结构中。  
为了保护这个内部数据结构的更新，在修改表定义之前需要先获得一个内部锁(称为LOCK_open)。

因为只有一个锁保护这些数据结构，所以数据库对象的创建、更新和销毁都可能带来性能问题。例如创建和销毁临时表。

###### 写入查询

无论那种情况，时间都在不同的上下文（context）中执行，上下文是指服务器执行语句时必须知道的隐式（implicit）信息，以保证语句能够正确执行

* 当前数据库
	* 向QUERY事件添加一个特殊字段，记录当前数据库
* 当前时间
	* SYSDATE()操作系统取时间，用于复制不安全，慎用；
	* NOW()开始执行语句的时间
	* 事件存储一个时间错，表明事件何时开始执行。
* 上下文事件
	* 用户自定义变量的值
		* 事件：User_var
		* 记录变量名及值
	* RAND函数的种子
		* 事件：Rand
		* 记录RAND随机函数的种子，种子取自会话内部状态。
	* AUTO_INCREMENT字段的插入值
		* 事件：Intvar
		* 记录增量计数器的值
	* 调用LAST_INSERT_ID的返回值
		* 事件：Intvar
		* 记录返回值
* 线程ID
	* 如CONNECTION_ID就必须知道线程ID，线程ID对临时表处理尤为重要
	* 临时表名称由服务器的进程ID，创建表的进程ID和一个线程计数器组成，计数器用来区分同一个线程中不同的临时表实例。
	* 线程ID作为一个独立字段存储在每个QUERY事件，因此可以用线程ID字段来计算线程特定的数据，并正确处理临时表

```shell
*************************** 1. row ***************************
   Log_name: mysqld1-bin.000001
        Pos: 238
 Event_type: Query
  Server_id: 1
End_log_pos: 306
       Info: BEGIN
*************************** 2. row ***************************
   Log_name: mysqld1-bin.000001
        Pos: 306
 Event_type: Intvar
  Server_id: 1
End_log_pos: 334
       Info: INSERT_ID=1
*************************** 3. row ***************************
   Log_name: mysqld1-bin.000001
        Pos: 334
 Event_type: RAND
 Server_id: 1
End_log_pos: 369
       Info: rand_seed1=952494611,rand_seed2=949641547
*************************** 4. row ***************************
   Log_name: mysqld1-bin.000001
        Pos: 369
 Event_type: User var
  Server_id: 1
End_log_pos: 413
       Info: @`foo`=12
*************************** 5. row ***************************
...
*************************** 9. row ***************************
   Log_name: mysqld1-bin.000001
        Pos: 681
 Event_type: Intvar
  Server_id: 1
End_log_pos: 709
       Info: LAST_INSERT_ID=1
```

###### LOAD DATA INFILE语句

* Begin_load_query
	* 这个事件标志着文件中数据传输的开始。
* Append_block
	* 一个或多个这些事件的序列遵循Begin_load_query事件，以包含文件的其余数据，如果文件大于连接上允许的最大数据包大小。
* Execute_load_query
	* 该事件是QUERY事件的一种特殊变体，它包含在master服务器上执行的LOAD DATA INFILE语句。
	* 即使该事件中包含的语句包含了master服务器上使用的文件的名称，但这个文件将不会被slave找到。相反，使用前面的Begin_load_query和Append_block事件获取文件的内容。

```sql
SHOW BINLOG EVENTS IN 'master-bin.000042' FROM 269\G
*************************** 1. row ***************************
   Log_name: master-bin.000042
        Pos: 269
 Event_type: Begin_load_query
  Server_id: 1
End_log_pos: 16676
       Info: ;file_id=1;block_len=16384
*************************** 2. row ***************************
   Log_name: master-bin.000042
        Pos: 16676
 Event_type: Append_block
  Server_id: 1
End_log_pos: 33083
       Info: ;file_id=1;block_len=16384
*************************** 3. row ***************************
   Log_name: master-bin.000042
        Pos: 33083
 Event_type: Append_block
  Server_id: 1
End_log_pos: 33633
       Info: ;file_id=1;block_len=527
*************************** 4. row ***************************
   Log_name: master-bin.000042
        Pos: 33633
 Event_type: Execute_load_query
  Server_id: 1
End_log_pos: 33756
       Info: use `test`; LOAD DATA INFILE 'foo.dat' INTO...;file_id=1
4 rows in set (0.00 sec)
Binary Log Filters
```

##### 将事务写进日志

以下情况开启事务：

* 用户发出START TRANSACTION或BEGIN命令时
* 当AUTOCOMMIT=1，且开始执行访问事务型表的语句时（事务型表）
* 当AUTOCOMMIT=0，且上一个事务已经隐式或显示地被提交或终止时

非事务型语句之后执行的事务型语句仍然属于当前活动的事务。

隐式提交的语句：

* 写文件的语句
	* 大多数的DDL语句
* 修改MySQL数据表的语句
	* 所有创建、删除或修改用户账户或用户权限的语句都是隐式提交的，而且不是事务的一部分。
* 出于实践原因要求隐式提交的语句
	* 锁定表、用于管理的语句和LOAD DATA INFILE语句都会导致隐式提交，这是具体实现的需要。

###### 事务缓存

二进制日志包含所有会话的事务信息，按照它们提交的顺序保存，就好像它们都是顺序执行的。

为了确保每个事务都是作为二进制日志的一个单元来编写的，服务器必须在不同的线程中分别执行不同的语句。
在提交事务时，服务器将所有作为事务部分的语句写入到二进制日志中，作为单个单元。
为此，服务器为每个线程保留一个事务缓存（transaction cache）。为事务执行的每个语句都放在事务缓存中，事务缓存的内容随后被复制到二进制日志中，并在事务提交时清空。

![transaction-cache](/static/img/数据库/transaction-cache.png)

非事务型语句如果同事影响事务型表和非事务型表，情况更加复杂，下面是记录时采取的一些方法：

_如何写入非事务型语句：_

当没有事务打开时，非事务型语句被写入到语句执行结束时的二进制日志中，并且在结束二进制日志之前不会在事务缓存中“中转”。但是，如果事务是打开的，规则如下:

* 如果该语句被标记为事务型的，那么它将被写入到事务缓存中。
* 如果语句没有被标记为事务型的，并且在事务缓存中没有语句，那么该语句将直接写入到二进制日志中。
* 如果语句没有被标记为事务型的，但是在事务缓存中有语句，那么语句将写到事务缓存中。
	* 避免了事务型操作和非事务型操作顺序乱序问题
	* 会引起非事务型数据表操作顺序与写入binlog的顺序不同

_如何避免非事务型语句的复制问题：_

* 不使用非事务型表
* 确保事务中影响非事务型表的语句先写入日志。这样就先写入日志。

`binlog_direct_non_transactional_updates`选项强制非事务型语句直接写入二进制日志。
这要保证这些语句之间没有依赖关系，否则就要使用基于行的复制。

###### 使用XA进行分布式事务处理

MySQL版本5.0允许使用X/Open DT[模型即XA来协调涉及不同资源的事务。
在5.0版本中，服务器在内部使用XA来协调二进制日志和存储引擎。

XA包括一个事务管理器，该事务管理器协调一组资源管理器，以便它们以原子单元的形式提交全局事务。
每个事务分配一个唯一的XID，由事务管理器和资源管理器使用。当在MySQL服务器内部使用时，事务管理器通常是二进制日志，资源管理器是存储引擎。

![提交XA事务的过程](/static/img/数据库/XA-commit.png)

* 在阶段1中，每个存储引擎被要求准备提交。在准备过程中，存储引擎会写入任何需要正确提交到安全存储的信息，然后返回一个OK消息。如果任何存储引擎的回答是否定的，即它不能提交事务，那么提交将被中止，所有的引擎都被指示回滚事务。
	* 在所有存储引擎都报告了它们已经准备好了没有错误的情况下，在第2阶段开始之前，事务缓存被写入到二进制日志中。与正常的事务不同，正常的事务以一个提交的普通查询事件结束，XA事务以包含Xid的Xid事件终止。
* 在第2阶段中，在第1阶段准备的所有存储引擎都被要求提交事务。当提交时，每个存储引擎将报告它已经提交了在稳定存储中的事务。
	* 重要的是要理解commit不能失败:一旦阶段1通过，存储引擎保证事务可以提交，因此不允许在第2阶段报告失败。当然，硬件故障可能导致崩溃，但由于存储引擎存储了持久存储中的信息，因此当服务器重启时，它们将能够正确地恢复。
* 在第2阶段之后，事务管理器就可以丢弃共享资源。二进制日志不需要做任何清理操作，因此在这一步中它对XA没有任何特别的作用。

如果提交XA事务的时候发生系统崩溃，服务器重启后进入恢复过程。

启动后，服务器打开上一个二进制文件并检查Format_description事件。如果binlog_in_use标记被设置，说明服务器发生了崩溃，需要进行XA恢复。

![XA恢复过程](/static/img/数据库/XA-recovery-process.png)

服务器首先检查二进制日志,通过读取Xid事件确定所有事务的XID，然后服务器中加载的存储引擎将根据这个清单来提交事务。
对于列表中的每个XID，存储引擎将判断是否准备了与XID的事务，但没有提交，如果是这样，则提交它。如果存储引擎已经准备了一个没有在这个列表中的XID的事务，那么在服务器崩溃之前，XID显然没有写入二进制日志，因此事务应该回滚。

###### 二进制日志的组提交

由于数据库系统必须能够安全应对崩溃情况，所以需要在事务提交的时候，强制将数据写回磁盘。
如果每个事务都要写磁盘会带来性能问题，为了避免这个问题，多个独立事务可以按组的形式，一起写入磁盘，这就是组提交(group commit)。  
不仅要考虑存储引擎提交事务数据的效率，还好考虑写二进制日志的效率。为此MySQL 5.6增加了二进制日志组提交（binary log group commit）。

每个事务完全提交之前增加一些步骤，每个步骤引入了一个互斥对象，确保每个步骤最多只有一个线程。

![二进制日志的组提交架构](/static/img/数据库/Binary-log-group-commit-architecture.png)

各个步骤负责处理一部分提交过程。

* 第一步将线程的事务缓存到文件页
* 第二步执行一个同步操作将文件写到磁盘
* 最后一步提交所有事务

为了以有序的方式在各个阶段之间移动会话，每个阶段都有一个相关的队列，其中会话可以排队等待处理。每个阶段队列都由在操作队列时短暂持有的互斥锁保护。

Binlog组提交阶段和互斥对象：

| Stage  | Stage mutex   | Stage queue mutex  |
| ------ | ------------- | ------------------ |
| Flush  | LOCK_log      | LOCK_flush_queue   |
| Sync   | LOCK_sync     | LOCK_sync_queue    |
| Commit | LOCK_commit   | LOCK_commit_queue  |

通常一个会话对应一个线程，在flush步骤，任何想要提交事务的会话线程会进入队列：

1. 如果会话线程排队到一个非空的队列，则它是一个follower，并将等待它的事务由其他会话线程提交。
2. 如果会话线程排队到一个空的队列，它是一个leader，并注册所有进入该队列的会话。
3. leader在一个步骤中清空队列的所有会话。会话的顺序将被维护，新的会话可以进入到队列。
4. 阶段处理完成如下:
	* 对于flush，每个会话的事务按照他们进入flush队列的顺序被flush到二进制日志。
		* 做了优化，每次“搬”一个会话，flush它。只要还有会话进入队列，就没必要处理整个队列，逐个处理能让更多会话入队。
		* binlog_max_flush_queue_time参数控制leader线程从flush队列“搬”会话的时间。
	* 对于sync，执行一个fsync调用。
	* 对于commit，事务在存储引擎中按照注册的顺序提交。
5. 这些会话将按照与此阶段注册的相同顺序排队等待下一个阶段的队列。
	* 如果队列是非空的，leader就变成了follower，但是follower不能变成leader
	* 新的leader线程会将提交过程进行到一半的旧线程合并到会话队列中，从而系统可以动态适应各种情况。

_注意事项：binlog_order_commits控制事务是否按顺序提交，如果为OFF，则平行提交事务，线程本身以任意顺序提交，而不用等待leader。_

##### 基于行的复制

基于语句的复制仍然无法正确处理：

* 如果UPDATE、DELETE或INSERT语句包含一个LIMIT子句，那么在执行过程中数据库崩溃可能会导致问题。
* 如果在执行非事务性语句时出现错误，则不能保证对主和从器的效果是相同的。
* 如果一个语句包含对UDF的调用，那么就没有办法确保对这个奴隶使用相同的值。
* 如果该语句包含任何不确定的功能——比如USER、CURRENT_USER或connection_id——结果可能会在master和slave之间有所不同。
* 如果一个语句更新了两个带有自动递增列的表，那么它将不能正常工作，因为只有一个最后的插入ID可以被复制，这将被用于两个表上的从属，而在主服务器上，每个表的插入ID将被单独使用。

上述情况下，最好复制插入表中的真实数据，这就是基于行的复制。  
基于行的复制不复制产生变更的语句，而是复制每个被插入、删除、更新的行。发给slave的行与发给存储引擎的行是一样的，包含插入表的真是数据。

基于行与基于语句复制的选择：

* 语句是否会更新大量的行，还是只做少量行的更新或插入
	* 更新大量的行，那么基于语句的复制更快，但并不总是这样，如果语句的优化和执行计划很复杂，可能基于行的复制更快，因为寻找行的逻辑快的多。
	* 如果只更新或插入少量的行，则基于行的复制更快，因为不需要解析直接交给存储引擎处理。
* 是否需要知道执行了哪些语句
	* 基于行的复制中，事件难以解码
	* 基于语句的复制中，语句被写入二进制日志中，因此可以直接读取
		* 5.6后支持产生行的语句和行一起写入日志

###### 启用基于行的复制

可以通过binlog-format选项控制使用那种格式。该参数可以作为全局变量也可以作为会话变量。
此选项可以使用值STATEMENT, MIXED, 或者 ROW。

```conf
[mysqld]
user            = mysql
pid-file        = /var/run/mysqld/mysqld.pid
socket          = /var/run/mysqld/mysqld.sock
port            = 3306
basedir         = /usr
datadir         = /var/lib/mysql
tmpdir          = /tmp
log-bin         = master-bin
log-bin-index   = master-bin.index
server-id       = 1
# 基于行复制的参数
binlog-format   = ROW
```

###### 使用混合模式

混合模式：正常情况下使用基于语句的复制，而对不安全的语句则切换到基于行的复制。

切换到行复制的情况：

* 语句调用了
	* UUID函数
	* 用户自定义函数
	* CURRENT_USER或USER函数
	* LOAD_FILE函数
* 一个语句同时更新了两个或两个以上含有AUTO_INCREMENT列的表
* 语句中使用了服务器变量
* 存储引擎不允许使用基于语句的复制，如MySQL Cluster引擎
* 后续增加的其他影响安全的因素

##### 二进制日志管理

二进制文件有多个文件组成，将它们分割成适当的组，构成一个binlog文件序列。
为了操作安全，向二进制日志添加一些特殊事件（轮换事件）。

###### 二进制日志和系统崩溃安全

如果更新没有写入二进制日志，就不会提交到存储引擎，反之亦然。

非事务引擎情况下，存储引擎在语句写入日志值钱，早就完成了所有变更；  
为了解决此问题，事件写入二进制入职的时机是表上的锁释放之前，所有变更提交给存储引擎之后。
因此如果在存储引擎释放锁之前系统崩溃，服务器必须确保写入二进制日志的变更实际存在于磁盘上的表中，然后才能提交语句或事务。
这些需要与标准文件系统之间的同步与协调。

操作系统将文件的一部分缓存在内存的某个特殊位置，通常称之为页面缓存。  
XA第一阶段后，所有数据被写入磁盘，以正确的应对崩溃。每次提交事务事，页面缓存都会被写入磁盘（实际由组提交控制）。

sync-binlog选项可以控制写入磁盘的频率，数值表示提交固定次数后写入磁盘。默认为0，由操作系统控制。

对于支持XA的存储引擎，例如InnoDB，设置sync-binlog=1,一般的系统崩溃情况下，都不会丢失任何数据。  
而不支持XA的引擎，可能会至少丢失一个事务。

###### binlog文件轮换

4种行为导致轮换：

* 服务器停止
* binlog文件大小达到最大限制
	* binlog-cache-size来控制文件大小
* 二进制日志被显式刷新
	* FLUSH LOGS命令
	* 建议使用binlog文件进行恢复前，强制执行显示刷新而不是使用活动文件
* 服务器上发生事故

Format_desc事件：

* binlog-in-use标记
	* 写入轮换事件后设置该标记
* binlog文件格式版本
* 服务器版本

为了应对崩溃时候也能安全地轮换二进制日志，服务器采用预写策略，把这个意图存到一个名为清除索引文件的临时文件中，这个文件也被用于清除binlog文件。

如`master-bin.index`对应`master-bin.~rec~`

###### 事故

指在服务器上不会产生数据变更但是必须写入二进制日志的时间，因为他们潜在的影响了复制。

二进制日志中有以下两种incident事件：

* Stop
	* 表示服务器正常停止
	* slave上重放二进制文件，将忽略任何Stop事件
* Incident
	* 表示通用的事故事件，from 5.1
	* 该事件包含一个标识符指定发生的事故类型。表明服务器被迫执行了一些操作，可能导致二进制日志变更丢失。
	* 如数据库重新装载或者非事务型事件由于过大无法写入binlog文件。
	* slave上重放二进制日志时，遇到Incident时间，就会因错误而停止。
	* 如果在集群重载时发现Incident事件，表明需要重新同步集群，很可能还要找到丢失的事件。

###### 清除binlog文件

expire-logs-days选项，服务器可以自动清除旧的binlog文件。

手动清除：

* PURGE BINARY LOGS BEFORE datetime
* PURGE BINARY LOGS TO 'filename'

如果发生崩溃，服务器通过对比清除索引文件和索引文件内容来继续清除（参考轮换部分），并删除哪些因系统崩溃而没有被删除的文件。  
清除索引文件也会在轮换时使用，因此在索引文件正确更新之前发生崩溃，新的binlog文件将被删除，然后在每次轮换时重新创建binlog文件。

##### mysqlbinlog实用工具

###### 基本用法

```sql
SHOW BINARY LOGS;
```

```shell
sudo mysqlbinlog --short-form --force-if-open --base64-output=never /var/lib/mysql1/mysqld1-bin.000038
```

文件可以指定多个

* short-form
	* 只输出发出的sql语句信息，忽略注释
* force-if-open
	* 禁止输出警告
* base64-output=never
	* 阻止输出base64编码的事件
* start-position=bytepos
	* 转储的第一个事件的字节位置，多个文件中的第一个
* stop-position=bytepos
	* 最后输出的事件的字节位置，多个文件中的最后一个
* start-datetime=datetime
* stop-datetime=datetime

**读取远程文件**

只需要服务器上有一个用于REPLICATION SLAVE权限的用户即可

使用read-from-remote-server选项读取binlog文件，参数包括歍的主机和用户、可选的端口号和密码，以及binlog文件名称

```shell
$ sudo mysqlbinlog
>    --read-from-remote-server
>    --host=master.example.com
>    --base64-output=never
>    --user=repl_user --password
>    --start-position=294
>    mysqld1-bin.000038
```

**读取日志文件的原始二进制文件**

mysqlbinlog工具不仅可以用于审查二进制日志，还可以获取binlog文件的备份。

```shell
# 文件会存储与当前目录
mysqlbinlog --raw --read-from-remote-server \
   --host=master.example.com --user=repl_user \
   master-bin.000012 master-bin.000013 ...
```

* --result-file=prefix
	* 创建写入文件的前缀，可以是目录名（反斜杠）或任何其他前缀
* --to-last-log
	* 给定开始的文件，会传送剩余的文件
* --stop-never
	* 达到一个日志文件末尾也不停止，等待更多输入。

###### 解释事件

hexdump选项告诉mysqlbinlog去写事件的市集字节。

```shell
$ sudo mysqlbinlog                       \
   >     --force-if-open                    \
   >     --hexdump                          \
   >     --base64-output=never              \
   >     /var/lib/mysql1/mysqld1-bin.000038
```

##### 二进制日志的选项和变量

* expire-log-days=days
	* 文件保留天数，重启或轮换时删除
	* 默认0，永不删除
* log-bin[=basename]
	* 开启二进制日志，及指定binlog文件的文件名
* log-bin-index[=filename]
	* 索引文件名
* log-bin-trust-function-creators
	* 废除创建存储函数时需要SPUER权限的要求
* binlog-cache-size=bytes
	* 事务缓存在内存中的部分的大小，以字节数计
	* 大事务中增加这个值可以提高性能
* max-binlog-cache-size=bytes
	* 日志文件中每个事务的大小，如果事务大小超过这个值，将出错终止，防止长时间阻塞二进制日志
* max-binlog-size=bytes
	* 每个binlog文件的大小，超过则轮换
* sync-binlog=period
	* 事务调用次数需写入磁盘的阈值，0表示由操作系统控制
* read-only
	* 阻止任何客户端进程（除了SUPER权限的slave线程和用户）更改服务器上的任何数据
	* 对于slave服务器的复制工作非常有用，可以保证slave客户端不破坏数据

###### 基于行的复制参数

binlog-format参数可以设置为以下几种模式：

* STATEMENT
	* 基于语句的复制
* ROW
	* 基于行的复制
	* DDL语句还是基于语句的复制
* MIXED
	* 以语句方式写入二进制文件，如果语句不安全，切换为基于行的复制

binlog-max-row-event-size：

指定何时开始下一个包含行的事件。由于事件在处理时被完全读入内存，该参数粗略控制那些包含行的事件的大小，保证处理行的时候不会消耗过多的内存。

binlog-rows-query-log-events (new in MySQL 5.6.2以后的版本支持，否则导致slave停止复制)：

在行事件值钱向二进制日志添加一个信息事件，这个信息事件包含产生这些行的原始查询。

_Tips：5.6.2以后的版本会忽略不支持的事件_

#### 面向高可用性的复制

确保高可用的三件事：

* 冗余
	* 如果一个组件出现故障，必须有一个替代品；替代品可以使闲置的，也可以是系统中的一部分。
* 应急计划
	* 故障后应该做什么。取决于那个组件出现故障，以及为何出现故障
* 程序
	* 必须能检测出故障原因并迅速解决

如果系统中单个组件的故障导致整个系统瘫痪，成为单点故障。如果系统中存在单点故障，就会严重限制我们实现高可用性的能力。
因此，首要目标是找到这些单点故障，确保我们做了冗余处理。

##### 冗余

一旦确定了哪里需要冗余，我们需要从两个基本方案选择：

1. 为每个组件保留副本，一旦原先的组件发生故障，副本马上接管
	* 切换时不会影响性能
	* 速度快与系统故障恢复
2. 确保系统有额外的处理能力，一旦组件出现故障时，依然可以处理负载
	* 需要更多的处理能力，如果在故障时负载满载，也就失去了继续冗余处理故障的能力
3. 这不是二选一，你可以将两者相结合

服务器发生故障的概率：

| 单点故障概率 | 1   | 2   | 3 |
| ------------ | --- | --- |--|
|1.00% | 100.00% | 49.50% | 16.17%|
|0.50% | 50.00% | 12.38% | 2.02%|
|0.10% | 10.00% | 0.50% | 0.02%|

##### 计划

* slave故障怎么处理已经存在的链接
	* 通常由应用层向另一个服务器重新尝试查询
* master故障
	* 如果有冗余的master，需要将所有的slave都移到master上

###### slave故障

负载均衡将新的查询定位到正常工作的slave，由于失去连接报错后，应用重新递交给正常工作的slave。

###### master故障

迅速替换，防止写操作中断时间过长。  
所有slave上存在过时的数据

###### relay故障

对中继服务器（relay）的故障，需要特殊处理。

剩余的slave必须重定向到其他中继服务器或master，由于添加中继服务器就是为了减轻master的负载，有可能出现master无法处理某个中继服务器上的所有slave的负载

###### 灾难恢复

不可抗拒力，多种故障同时发生。

将数据保存在另一个物理位置。

##### 方法

准备工作：

* 添加新的slave
	* 创建现有slave的快照，恢复后从合适的位置启动复制
	* 方法
		* 使用mysqldump
			* 不用关闭服务器，安全，速度慢
			* 参数可以直接获取快照位置
		* 复制数据库文件
			* 先将服务器离线，速度快
			* 需要mysqldump获取正确启动复制的位置
		* 使用在线备份方法
			* MySQL Enterprise Backup和XtraBackup
		* 使用LVM获取快照
			* Linux逻辑卷管理器（LVM）得到快照。
			* 自己管理复制位置
		* 使用文件系统快照的方法
			* 操作系统支持的快照功能
			* 自己管理复制位置
* 从拓扑结构中删除slave
	* 在负载均衡中剔除slave，然后删除它
* 切换master
	* 将连接在master上的所有slave切换到副master，然后通知负载均衡剔除原来的master
	* 另一种方法是使用slave提升
	* 热备份
* slave故障处理
	* 检测到slave不存在了就在负载均衡池中剔除
* master故障处理
	* 把slave转移到奥一个备用master上或者选择一个slave提升为master
* 升级slave
	* 需要在负载均衡中剔除后升级
* 升级master
	* 首先要升级所有的slave，这样才能读取master全部的复制事件
	* 通常升级时使用备用master或者使用slave提升的master

###### 热备份

做服务器副本最简单的拓扑结构就是热备份（hot standby）。

热备份是一个专用服务器，它是主master的副本，以slave方式连接到master，以读取和应用更新。

这种配置通常称为主-备份配置（primary-backup configuraion），可以有多个热备份。

![具有一个热备份的master](/static/img/数据库/Master-with-a-hot-standby.png)

热备份为我们提供了修复master的机会，修复master后，需要让他重新工作，要么将它设置为热备份，要么把所有的slave再重定向回来。

**主master还在运行的时候，切换到热备份**

_处理切换：_

slave从standby上开始复制的位置，同它在master上停止复制的位置，要完全一致。通常位置是不同的。

在完全相同的位置停止运行slave和standby，然后把slave重定向到standby，由于standby停止后位置没有发生变动，只需确定
standby的binlog位置，然后让slave从那个位置启动。这个任务必须手动执行，因为简单的停止无法使它们之间是同步的。

```sql
-- 检查standby和slave的状态
SHOW SLAVE STATUS;
-- 使用该命令使slave同步到相同位置
START SLAVE UNTIL
       MASTER_LOG_FILE = 'master-bin.000096',
       MASTER_LOG_POS =  756648;
-- 等待slave同步完成
SELECT MASTER_POS_WAIT('master-bin.000096',  756648);
-- standby上运行查看停止节点
SHOW MASTER STATUS;
-- 调整slave重定向到standby
CHANGE MASTER TO
       MASTER_HOST = 'standby.example.com',
       MASTER_PORT = 3306,
	   MASTER_USER = 'repl_user',
       MASTER_PASSWORD = 'xyzzy',
       MASTER_LOG_FILE = 'standby-bin.000019',
       MASTER_LOG_POS = 56447;
-- 如果slave在standby前面，则把上面某些步骤的slave和standby对调
```

```python
# 使用python处理切换
from mysql.replicant.commands import (
    fetch_slave_position,
    fetch_master_position,
    change_master,
)
def replicate_to_position(server, pos):
    server.sql("START SLAVE UNTIL MASTER_LOG_FILE=%s, MASTER_LOG_POS=%s",
               (pos.file, pos.pos))
    server.sql("SELECT MASTER_POS_WAIT(%s,%s)", (pos.file, pos.pos))
def switch_to_master(server, standby, master_pos=None):
    server.sql("STOP SLAVE")
    server.sql("STOP SLAVE")
    if master_pos is None:
        server_pos = fetch_slave_position(server)
        standby_pos = fetch_slave_position(standby)
        if server_pos < standby_pos:
            replicate_to_position(server, standby_pos)
        elif server_pos > standby_pos:
            replicate_to_position(standby, server_pos)
        master_pos = fetch_master_position(standby)
    change_master(server, standby, master_pos)
	standby.sql("START SLAVE")
    server.sql("START SLAVE")
```

###### 双主结构

两个master互相复制，保持同步。双主结构是对称的，用起来非常简单。
将故障切换到备份master上不需要重新配置主master，备用master故障时切换回来也非常简单。

服务器可以是主动的（active），也可以是被动的（passive）：  
如果是主动的，是指服务器接受写操作，这些写操作可以通过复制传播到其他地方；  
如果是被动的，只是跟随主动的master，一旦主动master发生故障可以替代它。

根据目的不同，有两种不同的配置：

* 主动-主动
	* 写操作同时到达两个服务器，然后将变更发送给对方
	* 用于不同地区的用户集同构访问地理位置较近的服务器
	* 由于事务在本地被提交，系统响应更快，这也意味着两个master不是一致的。一个master上提交的变更最终会传播到另一个master，在此之前，两个master上的数据是不一致的

* 主动-被动
	* 负责写操作的成为主动master，另外一个为被动master，与主动master保持同步
	* 和热备份差不多，很容易在两个master之间进行切换
	* 然而不需要被动master响应查询，有些方案中被动master实际是一个冷备份。

主主不同步造成两个后果需要注意：

* 如果两个master都更新了同样的信息，这两个变更之间将会产生冲突，可能会导致复制停止。
* 如果两个master不一致的时候发生了系统崩溃，有些事务将丢失。

只允许写一个master可以从一定程度上避免变更冲突的问题，从而使另一个master成为被动maaster，即主动-被动模式。

使用异步复制不可避免的结果是服务器崩溃时会丢失事务，MySQL 5.5新功能半同步复制，可以限制事务丢失的数量。  
原理是：提交线程的事务会被阻塞，直到至少一个slave确认收到这个事务。由于事务提交到存储引擎后事件才会发给slave，所以事务丢失睡昂可以控制到最多每个线程1个。

主动-被动配置的一个重要问题是，解决两台服务器同时成为主master的风险问题，有称为脑裂综合症。
如果网络连接丢失，被动master将自己提升为主动，后来主动master又重新联机，这时就会产生这个问题。  
为了阻止这个问题发生，通过一种称为STONITH的技术实现，实现有很多种，如连接到服务器然后使用`kill -9`（如果服务器可达），
关闭网卡隔离服务器，或者关掉机器电源等。如果服务器真的不可达，下次服务器又能访问的时候要使用“毒丸”让他自杀。  
处理脑裂综合症为题依赖于使用共享磁盘解决方案，如SCSI支持服务器预留磁盘，服务器发现磁盘被另一个服务器预留，意识到自己不再是primary，就把自己离线。

**共享磁盘**

![使用共享磁盘的双主结构](/static/img/数据库/Dual-masters-using-a-shared-disk.png)

忧点：不用切换binlog的位置，master切换速度很快，只需要记住slave停止的位置，执行CHANGE MASTER命令，然后再次启动复制。

问题：要确保两个master不会同时写文件，在被动master上执行任务时必须小心，重写配置文件，哪怕时失误，都可能时灾难性的。只读模式仍然不够，因为InnoDB处于只读模式还是会写文件。

**使用DRBD（分布式复制块设备）复制磁盘**

行为和外观上和正常磁盘一样，不需要mysql做特殊配置。

![Using-DRBD-to-replicate-disks](/static/img/数据库/Using-DRBD-to-replicate-disks.png)

只能在主动-被动配置中使用DRBD技术，被动磁盘完全不能访问，被动master也不能访问。  
切换速度比共享磁盘方案慢。  
和共享磁盘相同，需要在服务器联机之前恢复数据库文件，所以建议使用恢复性能搞的事务性引擎，MyISAM表的恢复成本相当高，InnoDB是一个好选择。

相对于共享磁盘方案的优点：

* 避免了磁盘的单点故障。
* DRBD还内置了脑裂综合症问题的解决反感，可以配置为自动恢复

**双向复制**

双向复制可以邮主动-主动配置，也可以使用在主动-被动结构中。

![Bidirectional-replication](/static/img/数据库/Bidirectional-replication.png)

配置双向复制的步骤：

1. 确保两台服务器拥有不同的服务器Id
2. 确保两台服务器具有不同的数据（并且在复制启动之前量个系统没有变更）
	* 确定复制的数据没有冲突
3. 创建一个复制用户，在两台服务器上准备复制，参考《复制》部分
4. 在两台服务器上准备复制

如果要把一个slave连接到其中一个服务器，要启用log-slave-updates选项。（使用服务器ID跳过自己发出的事件被重复传播回来的问题）

主动-主动配置的唯一推荐的方法，是保证不同的主动服务器写不同的区域

方案之一是为不同的master分配不同的数据库（或者不同的表），如使用视图连接不同的表。以下问题使管理变的复杂：

* 对不同的表进行读写
	* 应用程序将读写分离，从表写入，从表或视图读取
* 准确数据和当前数据
	* 快照数据不准确，要求准确信息要依赖于应用程序
* 优化视图
	* 利用创建视图和结果集有两个方法，MERGE和TEMPTABLE
	* 对视图做仔细设计是获得良好性能的因素

如果更新同一张表，MySQL服务器设了两个变量用于处理这种情况(会话的或者是全局的)。

* auto_increment_offset
* aotu_increment_increment

```shell
value = auto_increment_offset + N * aotu_increment_increment
```

```sql
-- The common table can be created on either server
CREATE TABLE Employee (
   uid INT AUTO_INCREMENT PRIMARY KEY,
   name VARCHAR(20),
   office VARCHAR(20)
);
-- Setting for first master
SET GLOBAL AUTO_INCREMENT_INCREMENT = 2;
SET GLOBAL AUTO_INCREMENT_OFFSET = 1;
-- Setting for second master
SET GLOBAL AUTO_INCREMENT_INCREMENT = 2;
SET GLOBAL AUTO_INCREMENT_OFFSET = 2;
```

_注意事项：使用这种方法应该控制对应序列Id的处理发送给正确的服务器，否则会导致不一致问题，一种可行方案是划分表权限，但并不总是可行_

###### 提升slave

如果备用服务器之后与任何一个slave，就不能使用备用服务器作为master

提升slave处理master故障的方法：不是保持一个专门的备用服务器（当然也就没有最佳候选备用），
而是确保任何一个连接到master的slave都能被提升为master，并且从master故障的位置接管。
选择“知道最多”的slave成为master，将他妈呢连接到新的master，然后从新的master上读取事件。

**提升slave的传统方法**

![提升slave替代故障的master](/static/img/数据库/Promoting-a-slave-to-replace-a-failed-master.png)

要求：

* 每个可提升的slave必须有一个复制用户账户
* 每个可提升的slave运行时必须使用log-bin选项，即启动二进制日志
* 每个可提升的slave运行时必须不适用log-slave-updates选项

步骤：

1. 使用STOP SLAVE停止slave
2. 使用RESET MASTER重置迹象成为新master的slave。slave将以master身份启动，其他连接的slave从提升的那个时刻开始读取事件
3. 使用CHANGE MASTER将其他slave连接到新的master上。由于重置了新的master，直接从二进制的七点开始复制，不需要额外的位置参数。

每个slave都需要获取丢失的事务，如果slave没有启动二进制日志，可以复制整个库或使用类似mysqldbcompare的工具获取变更。

_注意事项：大多数情况下，传统方法并不适用，因为slave往往落后于master_

**提升slave的修正方法**

![Binary-log-positions-of-the-master-and-the-connected-slaves](/static/img/数据库/Binary-log-positions-of-the-master-and-the-connected-slaves.png)

即使知道最多的那个slave，也没有从故障master那里获得全部变更。没有复制到新master的变更将丢失。5.6引入了GTID就不存在这个问题，或者实现一个类似GTID的机制。

**环形复制**

环形复制：所有用户数据被复制到所有站点，所有的数据中心都可以进行数据更新。

由于slave只能连接一个master，所以两个以上master互相复制，只能以环形的方式搭建。

MySQL 5.6引入了全局事务ID后，很多不推荐环形复制的原因都失效了，其中一个主要原因是一旦发生故障系统将无法运行。

![Circular-replication-setup](/static/img/数据库/Circular-replication-setup.png)

某台服务器出现故障，其他服务器重新连接至上游服务器，使得复制继续。有三个问题：

* 下游服务器需要连接上游服务器，并且从最近的位置开始复制，怎么确定位置
* 故障服务器崩溃前发出了一些事件，这些事件怎么处理
* 怎样把故障服务器重新接入拓扑结构，以及写入日志而为发出的事件丢失问题或者在接入时被重新发送

![Changing-topology-in-response-to-a-failing-server](/static/img/数据库/Changing-topology-in-response-to-a-failing-server.png)

所有问题可以通过全局事务标识符解决，使用CHANGE MASTER命令加上MASTER_AUTO_POSITION=1选项，将下游服务器连接到上游服务器。

```sql
CHANGE MASTER TO MASTER_HOST='stockholm.example.com', MASTER_AUTO_POSITION = 1;
```

由于每个服务器都有事务记录，故障服务器发出的任何事务都会在剩余的每个服务器上执行一次，问题2和3丢失问题自动解决了。  
将服务器恢复到环中的方式是，从环中任意一台服务器恢复，然后接入环中，防止重新发送。

#### 面向横向扩展的MySQL复制

当负载开始增加，有两种解决办法：

* 第一种方法时购买更大的服务器来应对增加的负载，成为纵向扩展（或向上扩展，scale up）
* 第二种方法时添加更多的服务器，成为横向扩展（或向外扩展，scale out）
	* 更常用，只需购买低成本的标准服务器，更具有成本效益
	* 添加服务器不仅可以处理增加的负载，还可以支持高可用性及其他商业要求。如果有效使用，可以综合并利用所有的服务器资源

横向扩展和复制的常见用途：

* 读操作的负载均衡
	* master忙于更新数据，所以将响应查询的服务器分离出来
* 写操作的负载均衡
	* 高流量的部署将处理分发到很多计算机上，复制在分发信息的过程中起着关键作用。
		* 基于信息角色的分发。很少更新的表在一个服务器上，频繁更新的表分割到多个服务器上
		* 按地理区域分割，这样流量可以直接定向到最近的服务器
* 通过热备份进行灾难避免
	* 通过slave热备份防止master单点故障
* 通过远程复制进行灾难避免
	* 远程数据中心之间进行数据传输
* 制作备份
	* 备份服务器离线，然后备份
* 生成报表
	* 离线一个slave产生报表
* 过滤或分区数据
	* 如果网络连接很慢，或者有些数据对某些客户端不可用，可以添加一个服务器进行数据过滤
	* 同样适用于将数据区分到独立的服务器

##### 横向扩展读操作

横向扩展只能扩展读操作，而不是写操作。写操作使用分片技术扩展

单个服务器每秒有10000个事务，master每秒的写负载为4000个事务，而每秒的读事务为6000个：

![average-load-before](/static/img/数据库/average-load-before.png)

添加三个slave，每秒的总负载量就增加到40000个，由于写操作也会被复制，每个写操作都会执行4次（1次master，3个slave 3次），读取负载被分发到各个slave，总的读负载没有增加：

![average-load-before](/static/img/数据库/average-load-after.png)

##### 异步复制的价值

异步复制比同步复制快的多，同步需要额外的同步机制来保持一致性，一般通过两段提交协议来实现。
两端提交协议保证了master和slave之间的一致性，但却需要他们之间有额外的通信消息传递。工作流程如下：

1. 当执行commit语句时，事务被发送给slave，而slave被要求准备提交。
2. 每个slave都准备事务，以便提交，然后向master发送一个OK(或ABORT)消息，表示事务已经准备好(或者是不能准备的)。
3. master等待所有的slave发送OK或ABORT消息:
	* 如果master从所有的slave那里收到了一个OK的信息，它会向所有的slave发送一个提交信息，要求他们提交交易。
	* 如果master收到来自任何一个slave的中止消息，它会向所有的slave发送一个中止消息，请求他们中止交易。
4. 然后，每个slave都在等待master的一个OK或ABORT消息。
	* 如果slave收到提交请求，他们就提交事务并向master发送确认该事务是提交的。
	* 如果slave收到中止请求，他们会取消任何更改并释放他们所持有的任何资源，从而中止事务，然后向master发送确认该事务被中止。
5. 当master服务器收到来自所有slave的确认时，它会将事务报告为提交(或中止)并继续处理下一个事务。

这个协议之所以慢，是因为它一共需要4次消息传递，准备及确认和终止或提交及确认。
主要问题不在于处理同步的网络流量，而是由于网络和slave提交产生的延迟，而且master的提交会被阻塞直到所有的slave确认事务。  
而异步复制只需要一条消息即可，master不需要等待slave，就可以立即报告事务的提交，从而极大的提高了性能。

| 网络延迟 (ms) | 事务提交时间 (ms) | 每秒提交的事务数量 | 示例                 |
| ------------- | ----------------- | ------------------ | -------------------- |
| 0.01          | 0.14              | ~7,100             | Same computer        |
| 0.1           | 0.5               | ~2,000             | Small LAN            |
| 1             | 4.1               | ~240               | Bigger LAN           |
| 10            | 40.1              | ~25                | Metropolitan network |
| 100           | 400.1             | ~2                 | Satellite            |

而异步就像没有slave一样。是以一致性为代价换取性能。

* 如果master出现故障，事务就会消失
* slave上执行的查询可能会返回旧数据

##### 管理复制拓扑

简单拓扑、树形拓扑、双主拓扑和环形拓扑：

![Simple-tree-dual-master-and-circular-replication-topologies](/static/img/数据库/Simple-tree-dual-master-and-circular-replication-topologies.png)

* 双主拓扑用来处理故障转义，环形复制和双主结构允许各个站点在本地运行的同时还能将变更复制到其他站点
* 简单拓扑和树形拓扑用于横向扩展

复制的使用导致读取的数量大大超过写入的数量，这种部署有两种特殊要求：

* 需要负载均衡
	* 写操作交给master
	* 读操作交给slave
	* 特定的查询发给特定的slave
* 需要管理拓扑
	* 应对master或者slave崩溃的情况

为了处理负载均衡更加高效，服务器要保留空闲处理能力：

* 峰值负载的处理
	* 要有余力处理峰值负载，需要密切监控应用以确定什么时候响应时间变慢
* 分布成本
	* 要有空闲处理能力来运行复制，包括管理分布式系统所需的额外查询
	* 每个slave上的写操作和master一样，slave需要一些处理能力来完成复制
* 管理性任务
	* 重新建立复制需要有空闲处理能力，如在服务器之间移动数据的时候重建复制

两种情况处理负载均衡：

* 应用程序根据查询类型请求服务器
* 中间层（通常指代理）分析查询，然后发给适当的服务器

使用中间层分析和分发查询是目前最灵活的方式，但有两点不足：

* 代理导致性能下降
	* 分析查询消耗资源
	* 查询多了一次节点转移，查询被分析两次一次是代理，一次是MySQL
* 正确的查询分析很难实现，有时甚至不可能实现

![Using-a-proxy-to-distribute-queries](/static/img/数据库/Using-a-proxy-to-distribute-queries.png)

###### 应用层的负载均衡

应用程序根据要发出的查询类型向负载均衡服务器请求链接。

应用层的负载均衡需要一个中心存储，存储服务器信息以及这些服务器能够进行哪些查询。

![Load-balancing-on-the-application-level](/static/img/数据库/Load-balancing-on-the-application-level.png)

##### 级联复制

从实践上说，一个master可以处理70个slave，但很大程度上取决于应用程序，master无响应永远是个问题。  
这时候需要添加一个或多个额外的slave作为中继slave（或简称中继服务器，relay），其目的事通过管理一群slave来减轻slave上的复制负载。这种使用中继的方式成为级联复制。

包括一个master、一个relay和若干个连接到relay的slave

![Hierarchical-topology-with-master-relay-and-slaves](/static/img/数据库/Hierarchical-topology-with-master-relay-and-slaves.png)

默认情况下，slave从master那里得到的变更不会写入slave的二进制日志中，如果出现问题，总是可以通过克隆master或另一个slave来恢复它  
另一方面，relay需要进行二进制日志记录所有变更，因为relay需要把变更传给其他slave。与slave不同的是，relay不需要应用这些变更，因为它不响应任何查询。

为此，建立一个Blackhole的存储引擎，它接受所有语句，总是报告语句执行成功，单丢弃任何数据变更。

relay引入了额外延迟，slave滞后master的程度比直接连接master的时候还多。

###### 配置relay

1. 将slave配置成发送任何slave线程执行的事件，并将这些事件写入relay的binlog
	* 主配置文件中配置log-slave-updates选项
2. 将relay上所有表的存储引擎都改成BLACKHOLE存储引擎，保留空间并提高性能
	* SET SQL_LOG_BIN=0;
	* ALTER TABLE user_data ENGINE='BLACKHOLE';
	* SET SQL_LOG_BIN=1;
3. 保证relay上的所有新表都使用BALCKHOLLE引擎
	* 主配置文件中配置default-storage-engine更改默认存储引擎
	* 通过命令SET STORAGE_ENGINE='BLACKHOLE'可暂时修改，重启无效

引入relay：

1. 将relay连接到master，并将其角色配置为relay
2. 一次将slave的连接切换到relay

##### 专用slave

将访问很少的数据放到每个slave上是一种资源浪费。为此需要在复制的之后分离表，MySQL通过过滤事件实现，在事件离开master或到达slave的时候过滤它们。

master和专用slave的复制拓扑：

![Replication-topology-with-master-and-specialized-slaves](/static/img/数据库/Replication-topology-with-master-and-specialized-slaves.png)

###### 过滤复制事件

1. 在master上过滤事件，称为master过滤器
	* 控制哪些被写入二进制日志以及哪些被发送给slave
2. 在slave上过滤事件，称为slave过滤器
	* 控制哪些被执行

如果使用master过滤，意味着无法使用PITR正确的恢复数据库，备份可以恢复，而之后的变更无法恢复，因为二进制日志中没有记录这些变更。  
如果使用slave过滤器，所有变更都会通过网络传输，浪费带宽。

**master过滤器**

创建master过滤器需要两个选项，不推荐同时使用。不接受多个参数但是可以重复使用。

* binlog-do-db=db
	* 如果当前库是db，则写入binlog
* binlog-ignore-db=db
	* 如果当前库是db，则忽略

**slave过滤器**

可以基于数据库的过滤，还可以过滤单个表，甚至使用通配符过滤一组表。

* replicate-do-db=db
* replicate-ignore-db=db
* replicate-do-table=db_name.tbl_name
* replicate-wild-do-table=db_pattern.tbl_pattern
* replicate-ignore-table=db_name.tbl_name
* replicate-wild-ignore-table=db_pattern.tbl_pattern

pattern可以使用`_`和`%`匹配

###### 使用过滤将时间分配给slave

master过滤的问题：

* 因为事件是从二进制日志中过滤出来的，而且只有一个二进制日志，所以不可能“切分”更改，并将数据库的不同部分发送到不同的服务器。
* 二进制日志也用于PITR，因此如果服务器存在任何问题，就不可能恢复所有内容。
* 如果由于某种原因，需要以不同的方式分割数据，那么它将不再可能，因为二进制日志已经被过滤，不能“撤销过滤”。

如果担心流量问题，可以在master上配置一个relay，保留master二进制日志的过滤后的版本。

![Filtering-by-putting-master-and-relay-on-the-same-machine](/static/img/数据库/Filtering-by-putting-master-and-relay-on-the-same-machine.png)

##### 数据一致性管理

为了避免数据过于陈旧，要保证slave提供的是有用的最新数据。如果还要添加relay，问题就更加棘手。  
解决的基本思路是在master上提交的事务做个标记，等slave渠道这个事务的时候（或更晚），才在slave上执行查询

MySQL 5.6引入了全局事务标识符（GTID）,slave和客户端的故障转移变得简单多了，因为大多数问题都可以自动处理了。  
5.6之前，是否存在relay服务器，有不同的解决办法。

###### 非级联部署的一致性

使用SHOW MASTER STATUS获取masster的binlog位置，然后在slave上调用MASTER_POS_WAIT函数等待slave到达位置。

###### 级联部署的一致性

由于每个中间的中继服务器都会更改binlog位置，所以无法等待master位置到达最终slave。

* 利用自定义全局事务标识符来提升slave，并反复轮询slave有没有处理过这个事务。
	* 与5.6的全局事务标识符不同，这里没有wait函数，需要轮询
	* 如果master和slave基本同步，时间较短，只需关心最终slave即可
* 用MASTER_POS_WAIT函数将从master到最终slave路径上的所有relay都连接起来，保证所有变化都能传递到slave。
	* 如果slave大多是滞后的，等待复制树向下扩散，然后执行查询。避免轮询间隔过大导致响应性问题。
	* 应用程序代码需要访问relay
	* 应用程序需要知道复制架构

![Synchronizing-with-all-servers-in-a-relay-chain](/static/img/数据库/Synchronizing-with-all-servers-in-a-relay-chain.png)

5.6以后，使用WAIT_UNTIL_SQL_THREAD_AFTER_GTIDS函数代替MASTER_POS_WAIT

```sql
SELECT WAIT_UNTIL_SQL_THREAD_AFTER_GTIDS($gtids)
```

#### 数据分片

将数据库分割有两种方法：

* 将某些表分别放在不同的机器上，又称为功能分割
* 将某些表分割成不同的行分别存储在不同的机器上，成为水平分割

##### 什么是数据分片

双主结构并不能扩展写操作，因为所有的写操作都会被复制并执行两次。  
最直接的办法就是服务器之间不再有复制机制，这样他们就是完全分离的。
这样就可以将数据分成两个完全独立的子集，然后将客户端定向到它试图变更的数据所在的分区，从而实现扩展写操作。  
此次更新处理并不需要其他的分片消耗资源。这种分割数据的方式通常称为分片（sharding，又称水平分割）。每个分区成为一个分片。

###### 为什么分片

分片的原因取决于应用程序的巨大压力。分片的好处（原因）：

* 将数据放在地理位置接近用户的位置。
	* 减少延迟，提升性能
* 减少工作集（working set）的大小。
	* 如果表比较小，大部分数据甚至整张表可以装入内存
	* 检索表的算法在表较小的时候更有效
* 分发工作
	* 将工作并行化

并不是所有数据都需要分片：

* 可以将某些大表附近进行拆分，然后在每个分片上对小表做全量副本（这些通常是全局表）
* 可以同时使用分片和功能分割，对庞大的数据做分片（文章、评论），而将索引数据（如用户和目录）放在不分片的中心存储

带有中心数据库的分片：

![Shards-with-a-centralized-database](/static/img/数据库/Shards-with-a-centralized-database.png)

###### 分片的局限性

分片可以提高性能，也有一些局限性

挑战是确保所有查询在向未分片的数据库和分片数据库执行时给出相同的结果。
如果您的查询访问多个表(通常是这样的情况)，必须确保对未分片的数据库和分片数据库得到相同的结果。
这意必须选择一个分片索引，以确保查询在共享或不共享的数据库中得到相同的结果。

**跨分片连接**

* 以map-reduce的方式执行查询，即将查询发送到所有分片，然后将查询结果收集到单个结果集中
	* 需要占用一定的服务资源，需要监控资源占用
* 将所有分片复制到某个单独的报表服务器，然后在报表服务器上运行查询
	* 简单的复制，一般采用这种方法完成报表

**使用AUTO_INCREMENT**

分片不同步AUTO_INCREMENT标识符。

如果需要一个唯一标识符，有两种方法：

* 生成一个唯一的UUID
	* 缺点是占用128个比特位，也存在极小的可能重复
* 使用符合标识符（composite identifier），前半部分是分片标识符，后半部分是本地生成的标识符（比如AUTO_INCREMENT生成的）
	* 除了AUTO_INCREMENT列以外，还要增加一列用于维护分片标识符

复合关键字：

![A-composite-key](/static/img/数据库/A-composite-key.png)

##### 分片方案的要素

如何分布数据以及如何有效地对数据进行重新分片：

* 确定如何为应用数据分区
	* 哪些表应该分割
	* 哪些表在所有分片上都应该有
	* 应该在什么列上进行分片
* 确定需要什么分片元数据以及如何管理元数据
	* 如何将分片分配到MySQL服务器
	* 如果将分片关键字映射到分片
	* 分片数据库需要存储哪些数据
* 确定如何分发查询
	* 如何获取分片关键字将查询和事务定向到正确的分片
* 创建分片管理的模式
	* 如何监控分片负载
	* 如何迁移分片
	* 如何通过数据分割和合并分片使系统重新负载均衡

###### 高级分片架构

查询来自应用程序，并由broker接收。broker决定发送查询到哪里，可能需要根据一个记录分片信息的分片数据库来决定。
然后将查询发送到应用程序数据库的一个或多个分片并执行。执行的结果集由broker收集，有可能对结果集进行处理，然后再发送回应用程序。

![High-level-sharding-architecture](/static/img/数据库/High-level-sharding-architecture.png)

##### 数据分区

高效的数据检索同样重要，为此，需要将相关数据放在一起。因此，高效分片的最大挑战是创建一个高效的分片索引（sharding index），使经常一起访问的数据落在一个分片上。

分片索引是定义在多个表的多个列之上的，通常每个表只用一个列（一般为主键，也便于做再次分割），也可以每个表多个列（不便于维护）。分片索引决定哪些表需要分片，以及怎样分片。

数据库表：

| Table        | Rows    |
| ------------ | ------- |
| departments  | 9       |
| dept_emp     | 331603  |
| dept_manager | 24      |
| employees    | 300024  |
| salaries     | 2844047 |
| titles       | 443308  |

![Employee schema](/static/img/数据库/Employee-schema.png)

带有分片表和全局表的模式：

![Schema-with-sharded-and-global-tables](/static/img/数据库/Schema-with-sharded-and-global-tables.png)

分片索引取决于你要做怎样的查询，以及表之间的依赖关系和记录行数。

使用MySQL的information_schema模式，能够计算出相关列上所有可能的分片索引。

```sql
USE information_schema;
SELECT
   GROUP_CONCAT(
     CONCAT_WS('.', table_schema, table_name, column_name)
   ) AS indexes
FROM
   key_column_usage JOIN table_constraints
      USING (table_schema, table_name, constraint_name)
WHERE
   constraint_type = 'FOREIGN KEY'
GROUP BY
   referenced_table_schema,
   referenced_table_name,
   referenced_column_name
ORDER BY
   table_schema, table_name, column_name;
```

在上述结构中使用查询得到两个分片索引：

| Candidate #1        | Candidate #2         |
| ------------------- | -------------------- |
| salaries.emp_no     | dept_manager.dept_no |
| dept_manager.emp_no | dept_emp.dept_no     |
| dept_emp.emp_no     |                      |
| titles.emp_no       |                      |

向结构中添加出版物表，与员工为多对多关系。

![Publication-schema-added-to-employees-schema](/static/img/数据库/Publication-schema-added-to-employees-schema.png)

department表仍然在所有节点上，也有新增表的外键参照，可以对新增表进行分片。这样就存在多个独立的分片索引了。

这也引入了一个问题，可以独立的分别查询两个分片索引的多表查询，而不能执行跨分片索引的连接查询。

分片索引及列：

| Index name  | Sharding column set                                                                    |
| ----------- | -------------------------------------------------------------------------------------- |
| si_emps     | employees.emp_no, dept_emp.emp_no, salaries.emp_no, dept_manager.emp_no, titles.emp_no |
| si_pubs     | publications.pub_id, dept_pub.pub_id                                                   |

###### 分配分片

要有效地使用shards，您需要以一种加速物理访问的方式存储它们。
最直接的方法是每个服务器保留一个shard，但是也可以在每个服务器上保留多个虚拟分片。

怎样分配分片：

* 应用程序使用跨schema的查询吗
	* 单个schema比较容易，可以在一个服务器上存储多个分片，每个分片保存一个schema，也不需要重写查询
* 查询根据分片方案调整吗
	* 可以要求开发者在写查询的时候考虑分片方案，就仍然能够在一个服务器上存储多个分片
	* 这样就可以以一种可控的方式重写查询，比如可以在所有数据名字后面加上分片号作为后缀
* 需要常常重新分片吗
	* 如果重写查询并不容易，或是要求开发者以某种特定的方式写查询，就必须一个服务器保存一个分片，因为这些查询可能是跨schema的
	* 如果要常常重新分片，一个服务器一个分片可能带来性能瓶颈，但是一个服务器保存多个分片也是可能的，能够在服务器之间迁移分片以达到负载均衡，但是如果某个分片成为热点，可能还是需要继续分片
* 如何备份分片
	* 用于备份和迁移
	* 多数备份方法都是对整个服务器或一个（多个）模式创建备份，所以要谨慎确保某个模式整体保存在同一个分片中（但是一个分片中可能有多个模式）。

**每个服务器一个分片**

最直接的方法是每个服务器上保存一个分片，这种情况允许跨模式查询，所以不需要重写查询。

缺点：

1. 多个表可能超出服务器的主存大小，从而影响性能
	* 打破了小表可以装入内存的性能优势
2. 如果需要对做这些表进行重新分片的话，那么服务器之间负载均衡操作更加昂贵

如果某个服务器过载需要减轻负载，方案是：

分割分片，要么用一个备用服务器创建一个新的分片，要么把那些不相干的行迁移到另一个分片

如果把行迁移到另一个分片，而且每个服务器只有一个分片，迁移过来的行必须与分片上已有的行合并，合并很难联机完成，在一个服务器一个分片的情况下，分割和重新合并操作很昂贵。

**每个服务器多个分片（虚拟分片）**

如果能够在单个机器上保存多个分片，数据就能够更加高效的在服务器之间迁移，因为数据已经是分片的。
但是，这么做就要区分一台服务器上的不同分片。

常用的方法是在模式名上附加分片标识符，如employees_1，表也可以增加分片名后缀employees_1.dept_emp_1。  
如果不跨schema，可以通过USE employee_1来解决模式名后缀的问题而不重写查询，但是跨模式就需要重写查询。重写可以借助代理中间件实现。

由于每个模式存储在不同目录下，大多数备份都可以多模式进行备份，但是备份单个表就会有问题。
只需将不同分片的表分别存放在不同的目录，就很容易应对分片备份。
可以将replicate-do-db限定为服务器上的某个模式，把变更复制到单个分片上，这在服务器之间迁移分片非常有用。

在一个服务器上保存多个分片，就可以通过迁移分片减轻负载。并且不需要合并分片。

##### 映射分片关键字

计算正确的分片需要哪些分片元数据，以及怎样将已分片的表映射到实际分片上。

###### 分片方案

分区函数可以通过静态分片方案或者动态分片方案来实现。

* 静态分片方案
	* 在静态分片方案中，通常通过固定不变的分配方法将分片关键字映射到分片标识符
	* 计算通常由连接器或应用程序完成，非常高效
* 动态分片方案
	* 分片关键字通过字典查询，该字典表明哪个分片包含数据。
	* 这种方案比静态分片更加灵活，但是需要一个中心存储，称为分片数据库

**静态分片方案**

如果查询分布不均，静态分片方案会遇到问题。如果哈希分布不好，也会产生这种问题。  
所以选择合适的分区关键字和区分函数非常重要。

**动态分片方案**

动态分片方案非常灵活，不仅允许更改分片位置，如果需要迁移数据，也很容易实现。  
动态方案计算分片的时候需要一些额外的查询，增加了复杂度，也会影响性能。增加缓存以缓解。

将分片数据库以一组表的形式保存在一个分片服务器上的MySQL数据库中。

* 包含每个分片信息的locations表
* 包含每个分区函数信息的partition_function表

```sql
CREATE TABLE locations (
       shard_id INT AUTO_INCREMENT,
       host VARCHAR(64),
       port INT UNSIGNED DEFAULT 3306,
       PRIMARY KEY (shard_id)
);

CREATE TABLE partition_functions (
       func_id INT AUTO_INCREMENT,
       sharding_type ENUM('RANGE','HASH','LIST'),
       PRIMARY KEY (func_id)
);
```

###### 分片映射函数

* 列表映射
	* 根据分片列中的一组不同的值，将行分布在分片上。例如，这个列表可以是一个国家列表。
	* 容易实现，不能有效分摊负载，适合分区域
* 区间映射
	* 根据分片列在一个范围内的位置，行分布在分片上。当您在ID列、日期或其他信息上很方便地进入范围时，这是很方便的。
	* 消除了某些分摊负载问题，但是很难达到负载均衡
* 散列映射
	* 根据分片键值的散列值，将行分布在分片上。这在理论上提供了最均匀的数据分布。
	* 最有效负载均衡的，但是最难有效实现

每个分片映射都要考虑两个问题：如何添加新的分片，以及如何根据分片关键字选择正确的分片。

**区间映射**

虽然容易实现，问题是区间可能变的零碎，并且要求数据有效支持区间。

创建索引表：包含区间和映射信息的表，并将这些区间映射到分片标识符

```sql
CREATE TABLE ranges (
       shard_id INT,
       func_id INT,
       lower_bound INT,
       UNIQUE INDEX (lower_bound),
       FOREIGN KEY (shard_id)
           REFERENCES locations(shard_id),
       FOREIGN KEY (func_id)
           REFERENCES partition_functions(func_id)
)
```

区间映射表区间：

| Lower bound  | Key ID   | Shard ID  |
| ------------ | -------- | --------- |
| 0            | 0        | 1         |
| 1000         | 0        | 2         |
| 5500         | 0        | 4         |
| 7000         | 0        | 3         |

添加新的分片：向ranges表和locations表分别插入一行

```sql
INSERT INTO locations(host) VALUES ('shard-1.example.com');
SET @shard_id = LAST_INSERT_ID();
INSERT INTO ranges VALUES (@shard_id, @func_id, 1000);
```

获取分片：使用查询获取分片

```sql
-- ？替换为分区关键字，另一种选择是存储上边界，但是更新分片数据库就会变得复杂
SELECT shard_id, hostname, port
  FROM ranges JOIN locations USING (shard_id)
 WHERE func_id = 0 AND ? >= ranges.lower_bound
ORDER BY ranges.lower_bound DESC
LIMIT 1;
```

**哈希映射与一致性哈希**

适合应对数据热点无法分散，某个分片过载而导致需要分割分片问题。

![Hash-ring-used-for-consistent-hashing](/static/img/数据库/Hash-ring-used-for-consistent-hashing.png)

常用的密码哈希函数：

提供一个包含大量比特位的哈希值，以及将输入字符串平均分布到输出区间。

| Hash function  | Output size (bits)  |
| -------------- | ------------------- |
| MD5            | 128                 |
| SHA-1          | 160                 |
| SHA-256        | 256                 |
| SHA-512        | 512                 |

创建索引表：

```sql
-- 添加索引加速检索哈希值
CREATE TABLE hashes (
    shard_id INT,
    func_id INT,
    hash BINARY(32),
    UNIQUE INDEX (hash)
    FOREIGN KEY (shard_id)
        REFERENCES locations(shard_id),
    FOREIGN KEY (func_id)
        REFERENCES partition_functions(func_id)
)
```

table hashes：

| Key ID  | Shard ID   | Hash                             |
| ------- | ---------- | -------------------------------- |
| 1       | 0          | dfd59508d347f5e4ba41defcb973d9de |
| 2       | 0          | 2e7d453c8d2f9d2b75a421569f758da0 |
| 3       | 0          | 468934ac4c69302a77cbe5e7fa7dcb13 |
| 4       | 0          | 47a9ae8f8b8d5127fc6cc46b730f4f22 |

添加分片：向locations和hashes各插入一行

```sql
INSERT INTO locations(host) VALUES ('shard-1.example.com');
SET @shard_id = LAST_INSERT_ID();
INSERT INTO hashes VALUES (@shard_id, @func_id, MD5('shard-1.example.com'));
```

获取分片：根据分片关键字查找分片位置，计算分片关键字的哈希值，然后招待小小于这个哈希值的最大哈希值对应的分片标识符，如果没有，就选最大的哈希值。

```sql
(
  SELECT shard_id FROM hashes 
  WHERE MD5(sharding key) > hash
  ORDER BY hash DESC
) UNION ALL (
  SELECT shard_id FROM shard_hashes 
  WHERE hash = (SELECT MAX(hash) from hashes)
) LIMIT 1
```

##### 处理查询和事务调度

* 如何将事务分配到合适的分片
* 如何获取事务的分片关键字
* 如何使用缓存提高性能

broker可以是中间代理，或者由连接器实现，看上去是一个透明的方案，但是实际不是，在处理事务时，使用代理需要扩展协议，而且（或者）会限制应用程序。

###### 处理事务

broker需要知道待处理事务的参数。

从应用程序的角度看，每个事务包含一个查询序列或语句序列，其中最后一个语句时提交或中止。

```sql
-- 开启事务
START TRANSACTION; 
-- 读写事务体
SELECT salary INTO @s FROM salaries WHERE emp_no = 20101; 
SET @s = 1.1 * @s; 
INSERT INTO salaries(emp_no, salary) VALUES (20101, @s); 
-- 提交
COMMIT; 
START TRANSACTION; 
INSERT INTO …;
COMMIT;
```

代理需要处理以下几个问题：

* 为了把事务事务发送到正确的分片，broker必须在看到事务的第一个语句的时候就知道分片关键字
	* 可以约定在第一局中暴漏关键字，但是容易出错
	* 事务的第一个语句显示提供分片关键字，特定的注释或者允许broker接收频带外的分片关键字（即不作为查询的一部分）
* 必须在第一个语句发送到服务器值钱，知道事务事读事务还是写事务
	* 将事务标记为读写事务或者只读事务，在查询中加入特殊的注释或者将这个信息带外发送给broker
* 能够推断是否处于某个事务内部，而且同一个事务的下一个语句应该使用相同的链接
	* SERVER_STATUS_IN_TRANS和SERVER_STATUS_AUTOCOMMIT在5.6中被增加。
	* 如果事务通过START TRANSACTION开始，第一个标记为真；如果AUTOCOMMIT=0;就不设置标记。
	* 如果设置了自动提交，就设置SERVER_STATUS_AUTOCOMMIT；否则清空标记
	* 联合使用两个标记，就能知道某个语句是否是事务的一部分，以及下一个语句是否应该使用相同的连接。
	* 但是连接器不支持，只能在broker中跟踪
* 能够看到上一个语句是否提交了某个事务，从而确定是否切换到另一个连接
	* 需要监控，还要考虑语句隐式提交事务问题
* 确定如何处理会话特定的状态信息，比如用户自定义变量、临时表以及服务器变量的特定设置等。

1、2两个问题需要检测用户是否发送出错。MySQL 5.6添加了START TRANSACTION READONLY，保证程序不会接受更新语句。  
检查分片如果使用分片名区分则很容易，否则需要引入类似断言的功能。

###### 分配查询

在分片环境中处理事务是极不透明的，应用程序必须考虑是否使用分片的数据库。考虑分配查询帮助应用开发者使用

如果查询中给出了需要访问的表，就可以推导出函数标识符，而不需要开发者提供。
此外，还可以检查这个查询是否真的只访问基于该分区函数分区的表，可能需要参考一些全局表的信息。

需要引入一个新的表，保存从表到分区函数的映射。

```sql
-- 记录各个表及其分区函数的表
CREATE TABLE columns (
       schema_name VARCHAR(64),
       table_name VARCHAR(64),
       func_id INT,
       PRIMARY KEY (schema_name, table_name),
       FOREIGN KEY (func_id) REFERENCES partition_functions(func_id)
)
```

##### 分片管理

分片迁移或者在分片之间迁移数据。

###### 将分片迁移到其他的节点

尽可能少的宕机时间，主要思想是为分片做备份，在目标节点上恢复备份，然后使用复制重新执行这期间发生的变更

1. 在源节点上创建模式的备份。在线或离线备份方法都可以
2. 记录某个特定的binlog文职
3. 停止服务器，将目标节点离线
4. 服务器停止过程中
	* 将replicate-do-db=schema_1选项设置为需要迁移的那个分片
	* 按需要从源节点恢复备份
5. 将目标节点恢复运行
6. 将复制配置从第2步的位置开始，然后在目标服务器上启动复制。从源服务器上读取事件，并将变更应用到要迁移的分片上
	* 保证目标节点有足够的处理能力
7. 如果目标节点与源节点差距较大，锁定源节点的分片模式，阻止变更。不需要停止目标节点上的分片变更，因为还没有写操作访问它。
	* LOCK TABLES命令
8. 检查源服务器上的日志位置，因为没有继续变更，这就是需要的最高日志位置
9. 等待目标服务器同步到这个位置，使用START SLAVE UNTIL和MASTER_POS_WAIT。
10. 在目标服务器上通过RESET SLAVE关闭复制
	* 这会删除所有复制信息
11. 将目标服务器离线，删除replicate-do-db选项，然后在恢复服务器，这是可选的
12. 更新分片信息，使得请求被定向到新的分片位置
13. 将模式解锁，重新启动分片的写操作
14. 删除源服务器的分片模式，取决于分片是如何锁定的。

借助Replicant库自动化实现这个过程。

###### 分割分片

如果分片太热，可以分割分片后迁移

1. 对分片中的所有模式使用在线备份方法，如MEB、XtraDB或系统文件快照等
2. 记下备份对应的binlog位置
3. 在目标节点上恢复备份
4. 启动从源节点到目标节点的复制，使用binlog-do-db或replication-do-db选项只复制要迁移的模式的变更。
5. 等待复制使目标节点跟上源节点，然后锁定源分片，即不能读也不能写
6. 等待目标主机完成与源主机的同步，这是分片的所有数据不可用
7. 更新分片数据库，使所有请求都被定向到新分片
8. 解锁源分片。这是所有数据都有了，但是两个分片上有数据冗余，但是冗余数据不会被访问
9. 使用LIMIT语句删除冗余数据，防止占用过多资源

#### 深入复制

* 如何更加安全的将slave提升为master
* 崩溃后避免数据库损坏
* 多源复制
* 基于行的复制
* 全局事务标识符
* 多线程复制

##### 复制架构基础

master和若干slave的内部结构：

![Master-and-several-slaves-with-internal-architecture](/static/img/数据库/Master-and-several-slaves-with-internal-architecture.png)

事件通过复制系统从master到slave，以如下方式:

* 会话接受来自客户机的语句，执行该语句，并与其他会话同步，以确保每个事务执行，而不与其他会话所做的其他更改相冲突。
* 在语句完成执行之前，一个包含一个或多个事件的条目被写入到二进制日志中。
* 在将事件写入到二进制日志之后，主服务器中的一个转储线程接管，从二进制日志中读取事件，并将它们发送到slave的I/O线程。
* 当slave的I/O线程接收事件时，它将其写入到中继日志的末尾。
* 在中继日志中，一个slave的SQL线程从中继日志读取事件，并执行该事件，将更改应用到slave的数据库中。

如果丢失了master的链接，slave的I/O线程将试图重连服务器

###### 中继日志的结构

中继日志结构：

![Structure-of-the-relay-log](/static/img/数据库/Structure-of-the-relay-log.png)

除了二进制日志的内容未见和索引文件以外，中继日志还维护两个文件来跟踪复制的进度，即中继日志信息文件和master日志信息文件。名称可有my.cnf配置。

```conf
# 默认为relay-log.info
relay-log-info-file=filename
# 默认为master.info
# 这个文件信息优于my.cnf，推荐直接使用CHANGE MASTER TO命令配置复制
master-info-file=filename
```

master.info文件包含了master读取位置以及连接到master服务器并开始复制所需的所有信息。当slave的I/O线程启动时，该文件如果可用就从中读取信息。

```info
23                                         1   Number of lines in the file
master-bin.000001                          2   Current binlog file being read (Master_Log_File)
151                                        3   Last binlog position read (Read_Master_Log_Pos)
localhost                                  4   Master host connected to (Master_Host)
root                                       5   Replication user (Master_User)
                                           6   Replication password
13000                                      7   Master port used (Master_Port)
60                                         8   Number of times slave will try to  reconnect (Connect_Retry)
0                                          9   1 if SSL is enabled, otherwise 0
                                           10  SSL Certification Authority (CA)
                                           11  SSL CA Path
                                           12  SSL Certificate
                                           13  SSL Cipher
                                           14  SSL Key
0                                          15  SSL Verify Server Certificate 
60.000                                     16  Heartbeat 
                                           17  Bind Address 
0                                          18  Ignore Server IDs 
8c6d027e-cf38-11e2-84c7-0021cc6850ca       19  Master UUID
10                                         20  Retry Count 
                                           21  SSL CRL 
                                           22  SSL CRL Path 
0                                          23  Auto Position
```

info文件跟踪复制的进度，并由SQL线程更新。

```info
./slave-relay-bin.000003     Relay log file (Relay_Log_File)
380                          Relay log position (Relay_Log_Pos)
master1-bin.000001           Master log file (Relay_Master_Log_File)
234                          Master log position (Exec_Master_Log_Pos)
```

如果有任何文件不可用，在slave启动的时候将从my.cnf文件中的信息及CHANGE MASTER TO命令的参数重建这些文件。需要START SLAVE。

###### 复制线程

* master转储线程
	* 当一个slave I/O线程连接的时候，这个线程被创建在master服务器上。转储线程负责从master服务器上读取条目并将其发送给slave。
	* 每个连接的slave有一个转储线程。
* slave I/O线程
	* 该线程连接到master服务器，请求转储发生的所有更改，并将它们写入到中继日志中，以供SQL线程进一步处理。
	* 每个slave上都有一个I/O线程。一旦连接建立起来，它就会被保持打开，这样master的任何变化都会立即被slave接收。
* slave SQL线程
	* 该线程从中继日志读取更改并将其应用到slave数据库。该线程负责协调其他MySQL线程，以确保更改不会影响MySQL服务器上正在进行的其他活动。

从master的角度来看，I/O线程只是另一个客户机线程，它可以同时执行转储请求和master服务器上的SQL语句。
这意味着客户端可以连接到服务器，并假装是一个slave，以便让master服务器从二进制日志中转储更改。这就是mysqlbinlog程序的操作方式。

SQL线程在处理数据库时就像一个会话。但是它还需要处理一些context信息保证复制的正确性。

I/O线程的速度比SQL线程快得多，因此，在复制期间，在中继日志中通常会缓冲几个事件。如果master服务器崩溃，您必须在连接到新master之前处理这些问题。  
为了避免丢失这些事件，在尝试重新连接到另一个master服务器之前，等待SQL线程处理完这些事件。

###### 启动和终止slave线程

* slave I/O现场称从master.info文件读取最后读位置进行恢复
	* 中继日志文件也存在轮换事件
* slave SQL线程从relay-log.info文件读取中继日志位置进行恢复。

停止和启动slave线程的命令：

* START SLAVE和STOP SLAVE
	* 两个线程
* START SLAVE TO_THREAD和STOP SLAVE TO_THREAD
	* I/O线程
* START SLAVE SQL_THREAD和STOP SLAVE SQL_THREAD
	* SQL线程

##### 通过Internet进行复制

保护数据，基本都需要用到SSL：

* 使用服务器内置的加密支持，对master到slave的复制进行加密
	* 权威认证机构的证书（CA）
	* 服务器的（共有）的证书
	* 服务器的（私有）的证书
* 对于不支持SSL的程序，使用Stunnel程序建立一个SSL隧道（虚拟私有网络）
* 在隧道模式下使用SSH

```shell
# 生成自签名的共有证书放在/etc/ssl/certs/master.pem
# 生成自签名的四有密钥放在/etc/ssl/private/master.key
# slave同样
sudo openssl req -new -x509 -days 365 -nodes \
        -config /etc/ssl/openssl.cnf \
        -out /etc/ssl/certs/master.pem -keyout /etc/ssl/private/master.key
```

###### 使用内置支持建立安全复制

```conf
# master
[mysqld]
ssl-capath=/etc/ssl/certs
ssl-cert=/etc/ssl/certs/master.pem
ssl-key=/etc/ssl/private/master.key
```

```sql
-- slave
CHANGE MASTER TO
    MASTER_HOST = 'master-1',
    MASTER_USER = 'repl_user',
    MASTER_PASSWORD = 'xyzzy',
    MASTER_SSL_CAPATH = '/etc/ssl/certs',
    MASTER_SSL_CERT = '/etc/ssl/certs/slave.pem',
    MASTER_SSL_KEY = '/etc/ssl/private/slave.key';
```

###### 使用Stunnel建立安全复制

slave服务器上的一个Stunnel实例接受来自从服务器的标准MySQL客户机连接上的数据，对它进行加密，并将其发送到master服务器上的Stunnel实例。
master服务器上的Stunnel实例依次侦听专用的SSL端口，接收加密数据，解密它，并将其发送到master服务器上的非SSL端口的客户机连接上。

![Replication-over-an-insecure-channel-using-Stunnel](/static/img/数据库/Replication-over-an-insecure-channel-using-Stunnel.png)

```conf
# /etc/stunnel/master.conf
cert=/etc/ssl/certs/master.pem
key=/etc/ssl/private/master.key
CApath=/etc/ssl/certs
[mysqlrepl]
accept = 3508
connect = 3306
```

```conf
# /etc/stunnel/slave.conf
cert=/etc/ssl/certs/slave.pem
key=/etc/ssl/private/slave.key
CApath=/etc/ssl/certs
[mysqlrepl]
accept = 3408
connect = master-1:3508
```

```sql
CHANGE MASTER TO
    MASTER_HOST = 'localhost',
    MASTER_PORT = 3408,
    MASTER_USER = 'repl_user',
    MASTER_PASSWORD = 'xyzzy';
```

##### 细粒度控制复制

###### 关于复制状态的信息

SHOW SLAVE HOSTS命令仅显示使用report-host参数的slave信息，slave使用report-host参数告诉master服务器的链接信息。
除了主机名外还有其他参数提供了关于连接slave的信息：

* report-host
* report-port
* report-user
* report-password
* show-slave-auth-info

```sql
SHOW SLAVE HOSTS;
-- 显示master的二进制文件
SHOW MASTER LOGS;
SHOW MASTER STATUS;
SHOW SLAVE STATUS;
```

SLAVE STATUS字段详解：

**I/O线程和SQL线程的状态**

* Slave_IO_Running和Slave_SQL_Running分别表示I/O线程或者SQL线程是否正在运行
* Slave_IO_State描述了当前正在运行的I/O线程的状态。
	* 等待master更新
	* 连接master
	* 检查master的版本
	* 在master上注册slave
	* 请求binlog转储
	* 等待master发送事件
	* master事件排队等待写入中继日志
	* action后等待重新连接
		* 失败重连时出现
	* action失败后重新连接
	* 等待slave互斥体退出
		* 关闭I/O线程时出现该消息
	* 等待slave的SQL线程释放中继日志空间
		* 等待处理中继日志轮换

![Slave-IO-thread-states](/static/img/数据库/Slave-IO-thread-states.png)

**二进制日志位置和中继日志位置**

* Master_Log_File和Read_Master_Log_Pos表示master的读位置
	* I/O线程即将从master二进制日志读取的下一个事件的位置，来自master.info 2,3
* Relay_Master_Log_File和Exec_Master_Log_Pos表示master的执行位置
	* SQL线程即将执行的master二进制日志的下一个事件位置，来自relay-log.info 3,4
* Relay_Log_File和Relay_Log_Pos表示中继日志执行位置
	* SQL线程即将执行slave中继日志中的下一个事件位置，来自relay-log.info 1,2

通过比较master的读位置和master的执行位置，如果相同，就可以安全的停止slave并将其重定向到新的master。  
也可以通过SHOW PROCESSLIST命令检查SQL线程的状态，如果State为“已经读取所有中继日志，等待slave I/O线程更新”，那么已经读取全部中继日志。

##### 处理断开连接的选项

如果I/O线程丢失了master的连接，则进行有限次尝试重新连接master。无响应时间、重试的时间间隔和重试次数由三个选项控制：

* --slave-net-timeout
	* 超时时间，默认3600秒
* --master-connect-retry
	* 重试间隔秒数，默认60秒
* --master-retry-count
	* 重试次数，默认为86400

##### slave如何处理事件

slave的SQL线程顺序执行来自master的所有会话的各个事件，带来的后果：

* slave响应是单线程的，而master是多线程的
	* 如果master上提交了很多事务，slave就难以与master保持同步
* 有些语句时会话特定的
	* slave上单线程执行的时候可能产生不同的结果
		* 每个用户变量都是特定于会话的
		* 临时表是特定于会话的
		* 有些函数也是特定于会话的
* 二进制日志决定了执行顺序
	* slave必须并行执行，才能保证和master一致

###### 管理I/O线程

I/O线程只使用某些字节来判断事件的类型，然后对中继日志采取必要的行动

* 停止事件
	* slave链中的下一个服务器被有序停止，I/O线程忽略这个时间，不把这个事件写入中继日志。
* 轮换事件
	* 如果master上的二进制日志被轮换，中继日志也要被轮换。
	* 中继日志轮换次数可能比master多，然是每次master轮换时，中继日志都要轮换。
* 格式化描述事件
	* 中继日志轮换时保存这种事件。应对连续的binlog文件格式不同问题。

每个服务器都要检查事件是否包含该服务器的ID，如果有，则忽略，说明本身是由这个服务器发出的，这在环形复制或双主复制中很有用。

###### SQL线程处理

有些事件需要SQL以外的特殊处理：

* 将master的上下文发送给slave
	* 处理master写的一个或多个上下文事件传递额外信息
* 处理不同线程的事件
	* master执行的事务来自多个会话。slave SQL现场称必须知道事件是由那个线程产生的。master了解每个语句，他会标记哪些线程特定的事件。
* 过滤事件和表
	* 负责数据库过滤和表过滤
* 跳过事件
	* 要恢复复制，重启复制时可以选择跳过事件

**上下文事件**

* 用户变量事件
	* 用户自定义变量名和值
	* 还可以用来避免非确定性函数的复制问题、提高性能，以及完整性检查等。
* 整型变量事件
	* 事件存储INSERT_ID或LAST_INSERT_ID会话变量的整型值
* Rand事件
	* 随机种子

**线程特定的事件**

不同线程导致结果不同的原因：

* 读写线程本地对象
	* 不同线程的本地对象的名字可以完全一样。临时表或用户自定义变量
	* 所有QUERY事件都有线程ID，salve收到一个线程特定的事件时，设值一个特定的复制slave线程变量，即pseudothreadID，对应事件的线程ID，然后使用这个ID创建临时表
* 使用具有线程特定结果的变量或函数
	* 变量和函数在不同线程中运行导致值不同。服务器变量和connect_id
	* 使用基于行的复制
	* 或使用临时变量

**过滤和跳过事件**

```sql
-- 恢复复制之前跳过3个事件
-- 如果会导致事务中断，则事务执行结束后跳过3个事件
SET GLOBAL SQL_SLAVE_SKIP_COUNTER = 3;
START SLAVE;
```

如果有slave过滤器，事件在SQL线程中过滤，过滤的事件依然会出现在中继日志中。

表过滤的使用原则：

* 不要限定数据表所在的数据库。在语句前使用USE。
* 不要在单个语句中更新不同数据库的表
* 不要在单个语句中更新多个表，除非你知道所有这些表都要过滤或都不会过滤

只要有一个表被过滤，整个语句都会被过滤。

复制过滤规则：

![Replication-filtering-rules](/static/img/数据库/Replication-filtering-rules.png)

##### 半同步复制

半同步复制的原理是复制继续运行之前，确保至少有一个slave将变更写到磁盘。对每个连接来说，如果发生master崩溃，至多只丢失一个事务。

半同步复制的事务提交：

![Transaction-commit-with-semisynchronous-replication](/static/img/数据库/Transaction-commit-with-semisynchronous-replication.png)

对于每个连接来说，如果事务在提交到存储引擎之后，发送到slave之前，发生了系统崩溃，那么这个事务就会丢失。  
由于slave确定事件提交后才会向客户端发送确认，所以至多只有一个事务丢失。

###### 配置半同步复制

5.5以后的master和slave支持才可以。

启用半同步复制的步骤：

1. 在master上安装master插件：
2. 在每个slave上安装插件
3. 启用插件
4. 重启服务器

```sql
-- master
INSTALL PLUGIN rpl_semi_sync_master SONAME 'semisync_master.so';
-- slave
INSTALL PLUGIN rpl_semi_sync_slave SONAME 'semisync_slave.so';
```

```conf
# master
[mysqld]
rpl-semi-sync-master-enabled = 1
# slave
[mysqld]
rpl-semi-sync-slave-enabled = 1
```

* 如果所有slave崩溃，就无法确认是否写入了中继日志
	* rpl-semi-sync-master-timeout=milliseconds 设置超时，如果超时则变为异步复制
* 如果所有slave连接都断了，也无法确认
	* rpl-semi-sync-master-wait-no-slave={ON|OFF} 设置是否等待slave连入

###### 监控半同步复制

* rpl_semi_sync_master_clients
	* 连接到master的支持半同步slave的数目
* rpl_semi_sync_master_status
	* master上的半同步状态，1表示活动
* rpl_semi_sync_slave_status
	* slave上的半同步状态，1表示活动

```sql
SHOW STATUS;
-- 如果上面命令不可用
SELECT Variable_value INTO @value
	   FROM INFORMATION_SCHEMA.GLOBAL_STATUS
	  WHERE Variable_name = 'Rpl_semi_sync_master_status';
```

##### 全局事务标识符

服务器上为每一个事务分配一个唯一的事务标识符，这是一个64位非0整数，根据事务提交的顺序分配。
这个值是本地的，要使事务标识符成为全局的，还要加上服务器的UUID（@@server_uuid），构成一对。

复制事务的时候如果启用了全局事务标识符，不管事务被赋值了多少次，事务的GTID保持不变。

GTID组定义某个或一组范围内的事务标识符。

```conf
# GTID
2298677f-c24b-11e2-a68b-0021cc6850ca:1477
# GTID组
2298677f-c24b-11e2-a68b-0021cc6850ca:911-1066:1477-1593
```

_注意事项：需要启动binlog才会记录这个GTID，否则不分配也不记录_

###### 使用GTID配置复制

```conf
[mysqld]
user            = mysql
pid-file        = /var/run/mysqld/mysqld.pid
socket          = /var/run/mysqld/mysqld.sock
port            = 3306
basedir         = /usr
datadir         = /var/lib/mysql
tmpdir          = /tmp
# 启用binlog
log-bin         = master-bin 
log-bin-index   = master-bin.index
server-id       = 1
# 启用GTID
gtid-mode       = ON 
# 对于备用服务器需要传递给slave来自master的变更
log-slave-updates 
# GTID强一致性，否则报错
enforce-gtid-consistency
```

启用后变更master步骤：

```sql
CHANGE MASTER TO
	MASTER_HOST = host_of_new_master,
	MASTER_PORT = port_of_new_master,
	MASTER_USER = replication_user_name,
	MASTER_PASSWORD = replication_user_password,
	MASTER_AUTO_POSITION = 1
```

master和slave会自动协商应该发送什么事务。

SHOW SLAVE STATUS：

```conf
Slave_IO_State: Waiting for master to send event
                .
                .
                .
  Slave_IO_Running: Yes
 Slave_SQL_Running: Yes
                .
                .
                .
       Master_UUID: 4e2018fc-c691-11e2-8c5a-0021cc6850ca
                .
                .
                .
Retrieved_Gtid_Set: 4e2018fc-c691-11e2-8c5a-0021cc6850ca:1-1477
 Executed_Gtid_Set: 4e2018fc-c691-11e2-8c5a-0021cc6850ca:1-1593
     Auto_Position: 1
```

* Master_UUID
* Retrieved_Gtid_Set
	* 存储在中继日志中的一组GTID
* Executed_Gtid_Set
	* 已经执行，并已经写入slave二进制日志的GTID

###### 使用GTID进行故障转移

切换到热备：

* 不在需要检查master上的位置了，所以也不需要停止
* slave没必要与master位置一致，备用服务器也没必要等待一个好的切换位置
* 不需要获取备用服务器位置
* 更改master时不需要提供位置

为了避免master失效时丢失事务，要养成执行故障转移钱清空中继日志的好习惯。这样避免了重复从master获取已经发送到slave的事务。

使用WAIT_UNTIL_SQL_THREAD_AFTER_GTIDS函数阻塞直到GTID组中的所有GTID都被SQL线程处理完毕。

```sql
SHOW SLAVE STATUS;
SELECT WAIT_UNTIL_SQL_THREAD_AFTER_GTIDS(Retrieved_Gtid_Set);
STOP SLAVE;
CHANGE MASTER TO 'standby.example.com';
START SLAVE;
```

###### 使用GTID提升slave

* GTID_EXECUTED 已写入二进制日志的GTID组
* GTID_PURGED	已从二进制日志中清除的GTID组

![GTID_EXECUTED-and-GTID_PURGED](/static/img/数据库/GTID_EXECUTED-and-GTID_PURGED.png)

使用GTID_EXECUTED很容易比较slave，然后决定那个slave“知道最多”。

```sql
SELECT @@GLOBAL.GTID_EXECUTED
SELECT @@GLOBAL.GTID_PURGED
```

###### GTID的复制

二进制为每个组分配了GTID，每个事务、单语句的DML语句及DDL语句。在写入组值钱写GTID时间，该事件包含事务的完整GTID。

![A-binary-logfile-with-GTIDs](/static/img/数据库/A-binary-logfile-with-GTIDs.png)

SQL线程按照以下方式处理GTID事件：

1. 如果GTID已经在GTID_EXECUTED中，跳过整个事务，也不写入二进制日志
2. 否则GTID就被分配给后面的事务，下一个事务正常执行
3. 如果事务提交，事务的GTID就用来产生一个新的GTID事件，然后这个事件在事务之前写入二进制日志
4. 在GTID事件之后，事务缓存的内容被写入二进制日志

在提交事务的时候，根据GTID_NEXT变量的值有不同的操作：

* 如果GTID_NEXT的值为AUTOMATIC，那么创建一个新的GTID并将其分配给事务
* 如果GTID_NEXT的值为GTID，那么使用这个GTID并且会随事务一起写入二进制日志

设值了GTID_NEXT并开启了事务，GTID就被这个事务拥有了

```sql
SELECT @@GLOBAL.GTID_OWNED;
```

mysqlbinlog with GTID events：

```conf
# at 410
#130603 20:57:54 server id 1  end_log_pos 458 CRC32 0xc6f8a5eb
#       GTID [commit=yes]
SET @@SESSION.GTID_NEXT= '01010101-0101-0101-0101-010101010101:3'/*!*/;
# at 458
#130603 20:57:54 server id 1  end_log_pos 537 CRC32 0x1e2e40d0
# Position  Timestamp   Type   Master ID        Size      Master Pos    Flags
#       Query   thread_id=4     exec_time=0     error_code=0
SET TIMESTAMP=1370285874/*!*/;
BEGIN
/*!*/;
# at 537
#130603 20:57:54 server id 1  end_log_pos 638 CRC32 0xc16f211d
#       Query   thread_id=4     exec_time=0     error_code=0
SET TIMESTAMP=1370285874/*!*/;
INSERT INTO t VALUES (1004)
/*!*/;
# at 638
#130603 20:57:54 server id 1  end_log_pos 669 CRC32 0x91980f0b
COMMIT/*!*/;
```

##### slave的安全和恢复

###### 同步、事务以及数据库崩溃问题

为了保证master或slave崩溃以后能够安全地恢复复制，需要考虑两个问题：

* 保证slave上存有恢复所需的所有数据
	* slave通过磁盘同步尽量满足这个条件
	* MySQL服务器定期在中继日志、master.info文件和relay-log.info文件上执行fsync调用，强制文件写入磁盘
* 执行slave的恢复

**I/O线程同步**

无论什么时候处理事件都有两个fsync调用：

* 一个将中继日志刷新到磁盘
* 一个将master.info文件刷新到磁盘

这两个刷新保证了没有事件丢失，以下几种情况发生崩溃，可能产生重复事件：

* 服务器刷新中继日志，正要更新master.info文件中的master读位置
* 服务器崩溃，也就是master读位置指向事件被刷新到中继日志之前的位置
* 服务器重启，并从master.info获得master读位置，即在最后一个事件写入中继日志之前的位置
* 从这个位置恢复复制，导致事件重复

如果按相反顺序刷新文件，可能丢失事件，，因为slave会在事件之后恢复复制。我们认为事件丢失比事件重复严重。

**SQL线程同步**

在处理组中所有事件时，SQL线程采用下面方式提交事务：

1. 将事务提交到存储引擎
2. 更新relay-log.info文件的下一个事件位置，这个位置也是处理下一个组的开始位置
3. 发出fsync调用，将relay-log.info文件写入磁盘

如果发生崩溃，从rela-log.info文件的最后一个记录位置恢复执行。

这种方式使得SQL线程的原子更新问题与I/O线程不同，所以下面的情况可能导致slave数据库和relay-log.info文件不同步：

1. 事件在数据库上应用，且事务已提交。下一步是更新relay-log.info文件
2. slave崩溃。relay-log.info文件指向刚刚完成的事务的开始
3. 恢复时，SQL线程从relay-log.info文件读取信息，并从保存的位置开始复制
4. 重复上一次执行的事务

这些情况都是因为slave上提交事务也更新复制信息不是一个原子操作，MySQL 5.6通过事务型复制解决这个问题。

###### 事务型复制

复制不是崩溃安全的，因为复制进度信息并不总是与数据库中的应用市级变更同步。
即使服务器崩溃时事务没有丢失，也要花点力气将slave恢复回来。

通过提交事务同时提交复制信息，增强了slave的复制安全性。
复制信息总是与数据库的变更应用一直，不论服务器是否发生崩溃。而且，master也做了调整保证能够正确恢复。

要实现事务型复制，将复制信息存储在文件或者表中。即数据和复制信息要么使用相同的事务型存储引擎，要么两个存储引擎都要支持XA。

**配置事务型复制**

```conf
[mysqld]
# 可选项为FILE和TABLE
master_info_repository = TABLE
relay_log_info_repository = TABLE
```

5.6.6之前，还要变更表的存储引擎：

```sql
ALTER TABLE mysql.slave_master_info ENGINE = InnoDB;
ALTER TABLE mysql.slave_relay_log_info ENGINE = InnoDB;
```

**事务型复制的细节**

保存事务型复制相关信息的两张表：

* slave_master_info对应master.info
* slave_relay_log_info对应relay_log.info

slave_master_info：

| Field                   | Line in file   | Slave status column           |
| ----------------------- | -------------- | ----------------------------- |
| Number_of_lines         | 1              |                               |
| Master_log_name         | 2              | Master_Log_File               |
| Master_log_pos          | 3              | Read_Master_Log_Pos           |
| Host                    | 3              | Master_Host                   |
| User_name               | 4              | Master_User                   |
| User_password           | 5              |                               |
| Port                    | 6              | Master_Port                   |
| Connect_retry           | 7              | Connect_Retry                 |
| Enabled_ssl             | 8              | Master_SSL_Allowed            |
| Ssl_ca                  | 9              | Master_SSL_CA_File            |
| Ssl_capath              | 10             | Master_SSL_CA_Path            |
| Ssl_cert                | 11             | Master_SSL_Cert               |
| Ssl_cipher              | 12             | Master_SSL_Cipher             |
| Ssl_key                 | 13             | Master_SSL_Key                |
| Ssl_verify_servert_cert | 14             | Master_SSL_Verify_Server_Cert |
| Heartbeat               | 15             |                               |
| Bind                    | 16             | Master_Bind                   |
| Ignored_server_ids      | 17             | Replicate_Ignore_Server_Ids   |
| Uuid                    | 18             | Master_UUID                   |
| Retry_count             | 19             | Master_Retry_Count            |
| Ssl_crl                 | 20             | Master_SSL_Crl                |
| Ssl_crlpath             | 21             | Master_SSL_Crlpath            |
| Enabled_auto_position   | 22             | Auto_Position                 |

slave_relay_log_info：

| Field             | Line in file   | Slave status column   |
| ----------------- | -------------- | --------------------- |
| Number_of_lines   | 1              |                       |
| Relay_log_name    | 2              | Relay_Log_File        |
| Relay_log_pos     | 3              | Relay_Log_Pos         |
| Master_log_name   | 4              | Relay_Master_Log_File |
| Master_log_pos    | 5              | Exec_Master_Log_Pos   |
| Sql_delay         | 6              | SQL_Delay             |
| Number_of_workers | 7              |                       |
| Id                | 8              |                       |

slave上每一个事务都被更新到slave_relay_log_info表。  
slave_master_info表只保存从master获取的事件的位置，
如果发生崩溃，slave将从上一次执行的位置恢复，而不是上一次获取的位置恢复，所以这个信息只对master崩溃有用。
这时，中继日志中的事件将被执行，避免更多事件丢失。  
slave_master_info表不包含事务型复制的重要信息，sync_master_info选项表示提交到slave_master_info表或刷新到磁盘的频率以提高性能。
0表示有操作系统控制文件刷新，当轮换或启动和停止的收，信息都会被刷新到磁盘或者表。

###### 保护非事务型语句的规则

master上崩溃，MyISAM表上的语句由于崩溃中断，这个语句不再计入日志，因为只有执行完的语句才记入日志。
重启时表包含一部分更新，但是二进制日志没有记录该语句。  
slave上如果执行过程中发生崩溃，表的变更可能还在，但是组位置不变，重启后将重复执行。

通过观察一些规则，可以观察到一些错误信息：

* INSERT语句
	* 要复制的表中必有主键，主键重复可能导致slave停止
* DELETE语句
	* 避免使用limit从句，这样重复执行也会没有影响
* UPDATE语句
	* 语句必须是幂等的，或者执行两次的偶然性是可以接受的

##### 多源复制

设计上有个问题：如何处理更新冲突

典型的实现方法：更新不同的数据库，或者更新同一张表的不同行

MySQL目前不支持多个源复制，可以近似实现：将slave在多个master之间切换，轮流从其中一个master定期复制，成为轮盘多源复制。

![Round-robin-multisource-replication-using-a-client-to-switch](/static/img/数据库/Round-robin-multisource-replication-using-a-client-to-switch.png)

1. 将slave配置为从一个master进行复制。
2. 设值slave复制的固定工作时间，slave从当前master中读取更新，然后应用更新，这是负责切换的客户端处于休眠状态。
3. 使用STOP SLAVE IO_THREAD停止slave的I/O线程
4. 等待中继日志为空
5. 使用STOP SLAVE SQL_THREAD停止SQL线程。CHANGE MASTER要求两个线程都停止
6. 保存当前master的slave位置，存储SHOW SLAVE STATUS命令输出的Exec_Master_Log_Pos和Relay_Master_Log_File的值
7. 将slave的复制按顺序切换到下一个master上：利用之前保存的位置，并使用CHANGE MASTER命令配置复制
8. 使用START SLAVE重启slave线程
9. 重复2-8步

_Tips：不执行3-5不也不会有问题，因为丢失的事件会从master重新读取_

##### 基于行复制的细节

基于行的复制方法不同，每个语句需要多个事件。

引入4个事件处理基于行的复制：

* Table_map
	* 将表ID映射为表名（包括数据名），以及关于master上的表的列的基本信息
	* 表信息只有类型，按位置复制
* Write_rows, Delete_rows, Update_rows
	* 除了行以外，每个事件还有一个表ID，来自Table_map事件，还有一个或两个列位图，说明影响了哪些列，节省空间。

每当执行一个语句时，它都会作为Table_map事件序列写入二进制日志，然后是行事件序列。
语句的最后一行事件被标记为一个特殊标志，指示它是语句的最后一个事件。

```sql
*************************** 1. row ***************************
   Log_name: master-bin.000054
        Pos: 106
 Event_type: Query
  Server_id: 1
End_log_pos: 174
       Info: BEGIN
*************************** 2. row ***************************
   Log_name: master-bin.000054
        Pos: 174
 Event_type: Table_map
  Server_id: 1
End_log_pos: 215
       Info: table_id: 18 (test.t1)
*************************** 3. row ***************************
   Log_name: master-bin.000054
        Pos: 215
 Event_type: Write_rows
  Server_id: 1
End_log_pos: 264
       Info: table_id: 18 flags: STMT_END_F
*************************** 4. row ***************************
   Log_name: master-bin.000054
        Pos: 264
		Event_type: Table_map
  Server_id: 1
End_log_pos: 305
       Info: table_id: 18 (test.t1)
*************************** 5. row ***************************
   Log_name: master-bin.000054
        Pos: 305
 Event_type: Write_rows
  Server_id: 1
End_log_pos: 354
       Info: table_id: 18 flags: STMT_END_F
*************************** 6. row ***************************
   Log_name: master-bin.000054
        Pos: 354
 Event_type: Xid
  Server_id: 1
End_log_pos: 381
       Info: COMMIT /* xid=23 */
6 rows in set (0.00 sec)
```

行事件大小通过binlog-row-event-max-size控制，表示它在二进制日志中的最大字节数。

###### Table_map事件

Table_map事件将表名映射为标识符，然后用于行事件，但这不是它唯一的用途。
它还包含master上表中字段的基本信息。slave确认结构匹配，从而复制继续。

![Table-map-event-structure](/static/img/数据库/Table-map-event-structure.png)

* 列类型数组
	* 表述所有列的基础数据类型数组，不包含参数
* 空比特数组
	* 表是每个字段是否是NULL的数组
* 列元数据
	* 表示字段元数据的数组，充实列类型数组的细节信息。如DECIMAL的精度和小数

无法区分的两种类型：

* 整型数据是否有符号
* 字符串类型的字符集

###### 行事件的结构

根据不同的事件类型，结构稍有不同。

![Row-event-header](/static/img/数据库/Row-event-header.png)

* 表宽
	* master上表的宽度，基于长度编码的，只有两个字节，大多数情况只有一个字节
* 列位图
	* 表示作为事件一部分发送的那些列。
		* 前映像，用于删除和更新
		* 后映像，用于插入和更新

行事件及其映像：

| Before image                | After image                | Event       |
| --------------------------- | -------------------------- | ----------- |
| None                        | Row to insert              | Write rows  |
| Row to delete               | None                       | Delete rows |
| Column values before update | Column values after update | Update rows |

###### 行事件的执行

因为多个事件可能表示master上执行的单个语句，所以slave需要保存状态信息，当有并发线程更新同一张表时，保证行时间的正确执行。

处理步骤：

1. 从中继日志中读取各个事件
2. 如果是表映射事件，SQL线程将提取表信息，并保存master对这个表的定义
3. 出现第一个行事件时，锁定列表中的所有表
4. 线程检查每张表是否一致
5. 如果不一致，就报错，停止复制
6. 继续行处理，直至最后一个行事件

拥有前映像的事件需要经过查找后正确定位到需要操作的行。按照查找优先级递减的顺序，查找操作包括：

* 主键查询
	* 最快
* 索引扫描
	* 没有主键，但有索引，找到则delete或update，否则报错
* 表扫描
	* 没有主键也没有索引，全表扫描

使用slave而不是master的主键或索引定位正确的行执行删除或更新操作，所以要注意：

* 有主键，很快，没有则很慢
* master和slave的索引可能不同

###### 事件和触发器

由于触发器引起变化的行也会被复制到slave上执行，所以slave上不能在执行一次触发器。  
事件复制后直接执行，不考虑触发器。

###### 基于行的复制中的过滤

基于行的复制的过滤是基于真正发生变化的表，而不是语句的当前数据库。

###### 部分行复制

5.6.2开始，可以通过binlog-row-image参数控制哪些列写入日志。参数有full、noblob和minimal。

* full
	* 默认值，复制全部列
* noblob
	* 忽略blob，除非他们需要被更新
* minimal
	* 只有主键和更改值的列

#### 什么是MySQL集群

MySQL集群是一个无共享的、分布式节点架构的存储方案，其目的是提高容错性和性能。  
数据被存储和复制在单个数据节点上，其中每个数据节点运行在单独的服务器上，并维护数据的副本。每个集群还包含管理节点。
更新使用读已提交隔离级别，以确保所有节点具有一致的数据，并使用两段提交以确保节点具有相同的数据(如果任何一个写入失败，则更新失败)。

MySQL集群的高性能是它通过存储引擎层使用MySQL服务器作为查询引擎。
因此，您可以透明地将设计为与MySQL交互的应用程序迁移到MySQL集群。

无共享节点概念允许在一台服务器上执行的更新立即在其他服务器上可见。
更新的传输使用了一种复杂的通信机制，用于在网络间实现非常高的吞吐量。
目标是通过使用多个MySQL服务器来分配负载，并通过在不同位置存储数据实现高可用性和冗余性。

##### 术语和组件

MySQL集群的典型部署是在某个网络的不同机器上安装部署集群，因此又称为网络数据库（network database，NDB）。
MySQL集群指的是MySQL集群和NDB组件，而“NDB”指集群组件。

##### MySQL集群和MySQL有何不同

通常认为集群包括成员、消息、冗余和自动化故障转移功能，而复制仅仅是一个服务器向另一个服务器发送消息的形式。

##### 典型配置

MySQL集群有如下三层：

* 应用程序层：负责与MySQL服务器通信的各种应用程序
* MySQL服务器层：处理SQL命令，并与NDB存储引擎通信的MySQL服务器
* NDB集群组件：NDB集群组件，即数据节点，负责处理查询，然后将结果返回给MySQL服务器

每一层都可以独立的纵向扩展，即通过更多的服务器进程来提高性能。

![MySQL-Cluster](/static/img/数据库/MySQL-Cluster.png)

应用程序连接到MySQL服务器，通过存储引擎（如NDB存储引擎）访问NDB集群组件。

##### MySQL集群的特点

数据在集群内部的对等数据节点之间相互复制。数据复制采用同步机制，数据存储在多个数据节点上，每个数据节点连接到所有的其他数据节点上。

集群之间复制采用MySQL复制，是异步的。

MySQL集群有一些创建高可用性系统的专用功能，主要包括：

* 节点恢复
	* 数据节点故障可以通过通信丢失或心跳失败来检测，您可以配置节点以使用来自其余节点的数据副本自动重新启动。故障和恢复可以包括单个或多个存储节点。节点恢复又称为本地恢复。
* 日志
	* 在正常的数据更新期间，数据更改事件的副本被写入存储在每个数据节点上的日志。您可以使用日志将数据还原到某个时间点。
* 检查点
	* 集群支持两种形式的检查点，即本地检查点和全局检查点。
		* 本地检查点移除日志的尾部。
		* 当将所有数据节点的日志刷新到磁盘时，将创建全局检查点，从而创建与事务一致的所有节点数据到磁盘的快照。这样，检查点允许从已知的良好同步点对所有节点进行完整的系统恢复。
* 系统恢复
	* 如果整个系统意外关闭，您可以使用检查点和更改日志来恢复系统。通常，数据从磁盘复制到内存中，从已知的良好同步点。
* 热备份及恢复
	* 可以在不干扰执行事务的情况下，同时创建每个数据节点的备份。备份包括关于数据库中的对象、数据本身和当前事务日志的元数据。
* 无节点故障
	* 任何节点失败都不导致数据库系统崩溃。
* 故障转移
	* 为了确保节点恢复是可能的，所有事务都使用读已提交隔离级别和两阶段提交。事务是双重安全的(即，在客户端接受事务之前，它们被存储在两个不同的位置)。
* 分区
	* 数据在数据节点之间自动分区。从MySQLVersion5.1开始，MySQL集群支持用户定义的分区.
* 联机操作
	* 您可以在没有正常中断的情况下在线执行许多维护操作。这些操作通常需要停止服务器或在数据加锁。
	* 例如，可以在线添加新的数据节点，更改表结构，甚至可以重新组织集群中的数据。

##### 本地和全局冗余

* NDB集群还有一个优化的两阶段提交版本，它减少了使用同步复制发送的消息数量。两阶段协议确保数据被冗余地存储在多个数据节点上，这种状态称为本地冗余。
* 全局冗余使用集群之间的MySQL复制。这将在复制拓扑中建立两个节点。MySQL复制是异步的，因为它不包括复制事件的到达或执行的确认或接收。

![Local-and-global-redundancy](/static/img/数据库/Local-and-global-redundancy.png)

##### 日志处理

* 本地检查点，用于清除部分重做日志
* 全局检查点，主要用于不同数据节点之间同步，全局检查点形成了事务组之间的边界，称为epoch，每个epoch是集群之间复制的单位。MySQL复制把两个连续的全局检查点之间的事务组看成单个事务。

##### 冗余和分布式数据

数据冗余用副本（replica）实现，每个副本包含数据的一份拷贝。这样集群可以容错，一个节点失效，仍然可以访问数据，副本越多，容错越好。

可以指定集群中的副本数目（NoOfReplicas）。

还可以利用分区将数据分布到各个数据节点，这样查询更快。为此，每个数据都要多个节点来存储。

脑裂综合征：

需要一个网络分区算法解决各组数据节点之间的竞争每组独立进行选举。节点数据较少的组将重启，然后分别将该组中的每个节点添加到节点数据较多的组。  
如果数目相当，可以顶一个一个仲裁器，规定第一个成功连接到仲裁其的组获胜。仲裁器可以是MySQL服务器或管理节点，为了高可用，最后将仲裁器放在非数据节点的系统上。  
带有仲裁器的网络分区算法在MySQL集群中是完全自动化的。

#### MySQL集群的架构

MySQL集群由一个或多个MySQL服务器组成，通过NDB存储引擎与NDB集群通信。
NDB集群本身由几个组件组成：存储和检索数据的数据或存储节点以及协调数据节点启动、关闭和恢复的一个或多个管理节点。
大多数NDB组件都是作为守护进程实现的，而MySQL集群还提供了客户端实用程序来操作守护进程的功能。

下面是守护进程和实用程序的列表：

![The-MySQL-Cluster-components](/static/img/数据库/The-MySQL-Cluster-components.png)

* mysqld
	* MySQL服务器
* ndbd
	* 数据节点
* ndbmtd
	* 多线程数据节点
* ndb_mgmd
	* 集群的管理服务器
* ndb_mgm
	* 集群的管理客户端

MySQL服务器通常都支持一个或多个SQL查询应用，然后接收来自数据节点的返回结果。  
数据节点是一系列NDB守护进程，负责存储和检索内存或硬盘上的数据。数据节点安装在集群中的各个服务器上。
还有一个名为ndbmtd的多线程数据节点守护进程，运行在支持多核CPU的平台上。
多核CPU专用服务器上使用多线程数据节点，可以提高数据节点的性能。  
管理守护进程ndb_mgmd运行在服务器上，负责读入配置文件，然后将信息分发到集群中的所有节点上。  
管理客户端ndb_mgm可以检查集群的状态，开始备份，然后执行其他管理功能。

实用程序：

* ndb_config
	* 抽取已有节点配置信息
* ndb_delete_all
	* 删除NDB表的所有行
* ndb_desc
	* 描述NDB表
* ndb_drop_index
	* 删除NDB表的索引
* ndb_drop_table
	* 删除NDB表
* ndb_error_reporter
	* 诊断集群中的错误和问题
* ndb_redo_log_reader
	* 检查并输出集群的重做日志
* ndb_restore
	* 执行集群的恢复

##### 如何存储数据

MySQL群集将所有索引列保存在主内存中。可以将其余的非索引列存储在内存中，也可以存储在具有内存页缓存的磁盘上。

当数据被更改时(通过INSERT、UPDATE、DELETE等)，MySQL集群会将更改的记录写入重做日志，定期将数据指向磁盘。

日志和检查点允许在发生故障后从磁盘恢复。但是，由于重做日志是与提交异步写入的，因此在失败期间可能会丢失有限数量的事务。
为了避免这种风险，MySQL集群实现了写延迟选项(默认为2秒，但这是可配置的)。
这允许检查点写入完成，这样如果发生故障，最后一个检查点就不会因为失败而丢失。
单个数据节点的正常故障不会由于集群内的同步数据复制而导致任何数据丢失。

在内存中维护MySQL群集表时，集群访问磁盘存储的目的只是将更改的记录写入重做日志并执行所需的检查点。
由于日志和检查点的写入是连续的，涉及的随机访问模式也很少，与传统的关系数据库系统中使用的磁盘缓存相比，
MySQL集群可以在有限的磁盘硬件下获得更高的写入吞吐量。

计算一个数据节点需要多大内存：

> (数据库的大小*副本的数量*1.1)/数据节点的数量

```shell
./ndb_size.pl --database=cluster_test --user=root
```

##### 分区

MySQL集群水平地划分数据(即，行自动地在数据节点之间分配，使用一个函数来分配行)。
这是基于使用表主键的散列算法。在MySQL的早期版本中，该软件使用内部机制进行分区，但是MySQLVersion5.1及更高版本允许您为数据分区提供自己的分区算法。

分区允许MySQL集群实现更高的查询性能，因为它支持在数据节点之间分发查询。
因此，在跨几个节点收集数据时，查询返回结果的速度将比从单个节点返回的速度快得多。

如果有多个数据副本(副本)，则会保护分布在数据节点上的数据不发生故障。
如果要使用分区将数据分布到多个数据节点以实现并行查询，则还应确保至少有两个对每一行的副本，以便群集具有容错性。

##### 事务管理

MySQL群集协调跨数据节点的事务更改。这使用了两个子进程，即事务协调器和本地查询处理程序。

* 事务协调器在全局级别上处理分布式事务和其他数据操作。
* 本地查询处理程序管理集群数据节点本地的数据和事务，并充当数据节点上两阶段提交的协调器。

每个数据节点都可以是事务协调器(您可以调优此行为)。当应用程序执行事务时，群集连接到一个数据节点上的事务协调器。
默认行为是选择群集的网络层定义的最近的数据节点。如果在同一距离内有多个可用的连接，则循环算法将选择事务协调器。

然后，选定的事务协调器将查询发送到每个数据节点，本地查询处理程序执行查询，并与事务协调器协调两阶段提交。
一旦所有数据节点验证了查询，就会与事务协调器协调两阶段提交。一旦所有数据节点验证了事务，事务协调器就会验证(提交)事务。

##### 联机操作

在MySQL版本5.1及更高版本中，您可以在集群联机时执行某些操作，这意味着您不必关闭服务器或锁定系统或数据库的部分。

* 备份
	* 可以使用NDB管理控制台执行快照备份(非阻塞操作)，以创建群集中数据的备份。
	* 此操作包括元数据(所有表的名称和定义)、表数据和事务日志(更改的历史记录)的副本。
	* 它不同于mysqldump备份，因为它不使用表扫描来读取记录。可以使用特殊的ndb_restore实用程序还原数据。
* 添加和删除索引
	* 您可以使用ONLINE关键字执行CREATE INDEX或DROP INDEX命令。
	* 当请求联机操作时，该操作是不复制的-它不复制数据以对其进行索引-因此索引不必在之后重新创建。
	* 这样做的一个优点是，事务可以在ALTER TABLE操作期间继续进行，而被更改的表不会因其他SQL节点的访问而被锁定。
	* 但是，该表针对执行ALTER操作的SQL节点上的其他查询而锁定。
* 修改表
	* 您可以使用ONLINE关键字在线执行ALTER TABLE语句。
	* 它也是不复制的，并具有与在线添加索引相同的优点。
	* 此外，在MySQL Cluster Version7.0及更高版本中，只要不使用INTO(paration_deverions)选项，就可以使用REORGORGATION分区命令在线重组跨分区的数据。
* 添加数据节点和节点组
	* 可以在线管理数据节点的扩展，以进行扩展或在失败后进行节点替换。
	* 简单地说，它涉及更改配置文件，执行NDB管理守护进程的滚动重新启动，对现有数据节点执行滚动重新启动，启动新的数据节点，然后重新组织分区。

#### 配置实例

集群配置的简单实例：

![Sample-cluster-configuration](/static/img/数据库/Sample-cluster-configuration.png)

如果将副本数量设置为2，则这个最小配置可以容错，如果将副本数量配置为1，为了获得更好的性能，这个配置可以分区，但是不能容错。

同一节点即运行NDB管理守护进程又作为MySQL服务器是允许的，但是如果节点的数目很多，或者想保证最大荣作，可能需要将这个守护进程迁移到另一个系统中。

##### 入门

最小配置项：

```conf
# /var/lib/mysql-cluster/config.ini
[ndbd default]
NoOfReplicas= 2
DataDir= /var/lib/mysql-cluster

[ndb_mgmd]
hostname=192.168.0.183
datadir= /var/lib/mysql-cluster

[ndbd]
hostname=192.168.0.12

[ndbd]
hostname=192.168.0.188

[mysqld]
hostname=192.168.0.183
```

##### 启动MySQL集群

1. 启动管理节点
1. 启动数据节点
1. 启动MySQL服务器（SQL节点）

###### 启动管理节点

```shell
# --initial需要清除以前的配置信息
sudo ../libexec/ndb_mgmd --initial --config-file /var/lib/mysql-cluster/config.ini
```

###### 启动管理控制台

```shell
# mysql安装目录的bin目录下
./ndb_mgm
ndb_mgm> SHOW
ndb_mgm> STATUS
ndb_mgm> ALL STATUS
```

###### 启动数据节点

拷贝ndbd可执行文件至/var/lib/mysql-cluster

```shell
sudo ./ndbd --initial-start --ndb-connectstring=192.168.0.183
```

###### 启动SQL节点

* ndbcluster
	* 使用哪个NDB集群存储引擎
* ndb_connectstring
	* NDB管理守护进程的位置
* ndb_nodeid and server_id
	* 节点ID，在管理控制台中SHOW命令输出节点ID信息

```shell
sudo ../libexec/mysqld --ndbcluster --console -umysql
```

##### 关闭集群

1. 如果有复制，先使slave跟上进度，然后停止复制
2. 关闭SQL节点
3. 在NDB控制台上发送SHUTDOWN命令
4. 推出NDB控制台

#### 获得高可用性

MySQL集群通过以下方式保证高可用：

* 数据节点之间的数据分布（减少单个节点的数据丢失风险）
* 集群中副本之间的复制
* 丢失的数据节点的自动恢复（故障转移）
* 通过心跳进行数据故障检测
* 本地和全局检查点来保证数据一致性等

配置高可用MySQL集群最佳实践：

* 在不同硬件的数据节点上使用多个副本
* 使用冗余的网络连接防止网络出现故障
* 使用多个SQL节点
* 使用多个数据节点来提高性能，将数据分布化

高可用MySQL集群

![A-highly-available-MySQL-cluster](/static/img/数据库/A-highly-available-MySQL-cluster.png)

##### 系统恢复

如果是正常关闭，会从日志检查点开始恢复。这很大程度上是自动的，是启动过程的正常阶段。
系统从每个数据节点的本地检查点加载最近的数据，从而在重新启动时将数据恢复到最新的快照。
数据节点从其本地检查点加载数据后，系统将重做日志执行到最近的全局检查点，从而将数据同步到关闭前的最后一次更改。
无论是在有意关闭之后重新启动，还是在失败后重新启动整个系统，过程都是相同的。

MySQL集群是内存中的数据库，因此，在启动时必须从磁盘重新加载数据。将数据加载到最近的检查点即可完成此任务。

灾难中从备份恢复使用ndb_restore实用程序。

首先在管理控制台进入单用户模式：

```sql
-- node-id是ndb_restore所在的数据节点的id
ENTER SINGLE USER MODE node-id
-- 然后进行数据恢复
-- 退出单用户模式
EXIT SINGLE USER MODE
```

##### 节点恢复

网络、硬件、内存或操作系统问题或故障都可能导致节点故障。

* 硬件
	* 更换硬件，重启节点
* 网络
	* 修复网络，重启节点
* 内存
	* 增加内存或者重新调整分配，执行数据节点的滚动启动
* 操作系统
	* 重启数据节点

##### 复制

MySQL集群复制又称为内部集群复制或内部复制，MySQL复制又称为外部复制

###### 集群内部复制和MySQL复制

* 内部复制使用同步复制，支持两段提交协议，保证数据的完整性
* MySQL复制是异步复制，依赖于稳定交付的单向数据传输，不需要确认

###### 集群内部复制

内部MySQL集群复制通过存储多个数据副本(称为副本)提供冗余。
该过程确保在查询被确认为完整(提交)之前将数据写入多个节点。这是使用两阶段提交完成的。
这种复制形式是同步的，因为在确认查询或提交完成时，数据保证是一致的。

数据以片段形式复制，其中片段被定义为表中行的子集。由于分区片段分布在数据节点上，每个副本的其他数据节点之上都有该片段的一个副本。
其中一个片段被指定为主片段，用于执行查询。同一数据的所有其他副本都被视为次要片段。在更新期间，首先更新主片段。

###### 集群之间的MySQL复制

如同MySQL复制一样，只不过数据存储在NDB集群中。

* 外部复制必须是基于行的
	* 主SQL节点必须使用--binlog-format=ROW或--binlog-format=MIXED启动
* 外部复制不能是环形的
* 外部复制不支持auto_increment_*选项
* 二进制日志的大小可能比常规的MySQL复制更大

###### MySQL集群（外部）复制的架构

同MySQL复制，但是每个epoach（检查点之间的时间跨度）被视为一个事务。

binlog注入线程维护下面表：

* ndb_binlog_index，存储二进制日志的索引数据(对于SQL节点是本地的)
* ndb_apply_status，存储已复制到从服务器的操作的记录，可用于对失效的复制slave进行即时恢复。

###### 单通道复制和多通道复制

MySQL复制连接称为一个通道，一般只有单通道，但是为了保证最大可用性，可以建立一个备用通道来容错，称为多通道复制。

多通道外部复制：

![Multichannel-external-replication](/static/img/数据库/Multichannel-external-replication.png)

master和slave都有主备，使用不同的通道通信。

启动多通道复制：

1. 启动主master
2. 启动备用master
3. 将主slave连接到主master
4. 将备用slave连接到备用master
5. 启动主slave

故障转移为了避免同样的数据被复制两次，需要确定上一次复制的epoch：

1. 找到slave接收到的最近全局检查点的时间
	```sql
	SELECT @latest := MAX(epoch) FROM mysql.ndb_apply_status;
	```
2. 获取主master上的ndb_binlog_index表中的行
	```sql
	SELECT @file := SUBSTRING_INDEX(File, '/', −1), @pos := Position
	FROM mysql.ndb_binlog_index
	WHERE epoch > @latest ORDER BY ASC LIMIT 1;
	```
3. 同步备用通道
	```sql
	CHANGE MASTER TO MASTER_LOG_FILE = 'file', MASTER_LOG_POS = pos;
	```
4. 在备用通道上启动复制
	```sql
	-- 备用slave
	START SLAVE;
	```

#### 获得高性能

特性对高性能的支持：

* 集群间复制（全局冗余）
* 集群内部复制（本地冗余）
* 主存储器存储
	* 无需等待磁盘写，保证了数据更新的快速处理

##### 高性能的注意事项

* 保证应用程序尽可能高效
	* 修改服务器配置
	* 重构程序成为更高性能的程序
* 最大化数据库的访问
	* 横向扩展
	* 分发数据
* 提高集群性能
	* 增加节点

_Tips：JOIN比较耗费性能_

需要在可用性和性能之间做出权衡，因为副本会消耗性能，而读取操作不需要副本。  
由于分布式特性，服务器性能和网络性能都很重要。

##### 高性能的最佳实践

* 调整访问模式
	* 使用索引
* 确保应用程序是分布式敏感的
	* 查询最好集中在单个节点上
		* 修改哈希函数是数据分布在同个节点
		* 分区剪裁
* 使用批操作
	* transaction_allow_batching参数，在单个事务中包含多个操作。
* 优化数据库模式
	* 使用高效的数据模型
* 优化查询
	* 从检索的角度优化
	* 对JOIN操作敏感
* 优化服务器参数
	* 优化配置
* 使用连接池
	* ndb-cluster-connection-pool修改SQL节点和NDB集群的连接线程数
* 使用多线程数据节点
	* ndbmtd提升额外性能，支持8核CPU
* 使用NDB API个性化应用程序
	* 程序直连NDB集群
* 使用正确的硬件
	* CPU、内存、网络
* 不要使用交换空间
	* 使用真正的内存而不是交换空间，会影响性能和稳定性
* 为数据节点使用处理器亲和度
	* 数据节点进程锁定在与网络通信无关的CPU上

### 监控和管理

#### 监控入门

##### 监控方法

不影响操作或运行唤醒的前提下，用仪器观察、记录或检测操作或环境。

系统监控主要有三种类型：系统性能、应用程序性能和安全性。

* 通过监控确保一切不变称为主动监控
* 通过监控确定哪里出错称为被动监控

##### 监控系统组件

###### 处理器

监视系统的CPU，以确保没有失控的进程，并且CPU周期在运行的程序之间被平等地共享。

* 一种方法是调用正在运行的程序列表，并确定每个程序使用的CPU百分比。
* 另一种方法是检查系统进程的平均负载。大多数操作系统提供CPU性能的几个视图。

CPU超载一些常见的解决办法：

* 添加新服务器运行某些进程
* 删除不必要的进程
* 杀死失控的进程
	* 失控进程可能是有缺陷的应用程序导致的，间歇或偶尔出现问题是，往往也是它们的问题。
* 优化应用程序
* 较低的进程优先级
	* 有些线程可以后台作业
* 重新安排进程
	* 调整执行线程执行时机

消耗太多CPU时间的进程被称为CPU受限的。

###### 内存

为了确保应用程序不要请求过多的内存，因为内存过多会浪费很多系统时间用于内存管理。

使用磁盘存储器来存储贮存中未使用的部分或页，这种技术称为分页或交换。

在交换操作很频繁的时候，可用内存很少可能因为失控进程占用了太多内存，或者太多进程请求了内存。

消耗过多内存的进程被称为内存受限的。

* 增加内存
* 为不同的系统组件或支持内存优化的程序分配不同数量的内存
* 更改分页子系统的优先级，让操作系统早点开始分页

###### 硬盘

为了确保系统拥有足够的可用磁盘空间和I/O带宽，以使进程执行时不会出现明显的延时。

使用单进程传输率和整体传输率衡量读写磁盘的传输速率。

消耗太多磁盘传输率的进程被称为是磁盘受限的。

* 处理磁盘争用的一个方法是添加磁盘控制器和磁盘阵列，将一个受磁盘限制的进程的数据移动到新的磁盘控制器上。
* 将磁盘受限的进程移动到另一个使用率低的服务器上
* 升级磁盘系统

优化选择：

* 如果需要运行大量的进程，需要最大化磁盘传输速率，或者将不同的进程分布在不同的磁盘阵列和系统上
* 如果少数几个进程但是访问量达，需要优化单进程的传输率，通过增加文件系统的块大小来实现

###### 网络子系统

以确保拥有足够的带宽，而且正在发送或接收的数据具有足够高的质量。

如果消耗了过多的带宽或访问网络子系统的时间太长，这样的进程就称为网络受限的。

* 网络带宽问题通常由网络接口最大带宽的百分比利用率决定
	* 通过给不同进程分配特定的端口，能够解决这个问题。
* 网络质量问题通常表现为网络接口遇到了大量错误。操作系统和数据传输应用通常采用校验和或其他算法来检测这类错误，但是重发会给网络和操作系统带来沉重负担。
	* 将某些应用转移到同一网络上的其他系统
	* 安装额外的网卡
	* 重新配置网络协议
	* 将系统转移到网络上的另一个子网

##### 监控方案

* [up.time](https://www.idera.com/)
	* 监控和报告服务器性能的集成系统
* [Cacti](https://www.cacti.net/)
	* RRDtool图形数据的图形报表解决方案
* [KDE System Guard](https://www.kde.org/applications/system/ksysguard/)
	* 允许用户跟踪和控制进程，配置简单
* [Gnome System Monitor](https://help.gnome.org/users/gnome-system-monitor/stable/)
	* 监控CPU、网络、内存和进程的图形化工具
* [Nagios](https://www.nagios.org/)
	* 监控所有服务器、网络开关、应用程序和服务器的一整套解决方案
* [MySQL Enterprise Monitor](https://www.mysql.com/products/enterprise/monitor.html)
	* MySQL数据的性能和可用性提供实时可见能力

##### Linux和Unix的监控

Linux和Unix的系统监控工具：

| Utility  | Description                                                                    |
| -------- | ------------------------------------------------------------------------------ |
| ps       | 显示系统上运行的进程列表                                                       |
| top      | 显示CPU使用率排序的进程活动                                                    |
| vmstat   | 显示内存、分页、块存储和CPU活动的相关信息                                      |
| uptime   | 显示系统运行了多长时间，显示用户数量及在1分钟、5分钟、15分钟内系统的平均负荷量 |
| free     | 显示内存使用率                                                                 |
| iostat   | 显示平均磁盘活动和处理器负载情况                                               |
| sar      | 显示系统活动报告                                                               |
| pmap     | 显示各个进程分别占用内存的情况                                                 |
| mpstat   | 显示多处理器系统的CPU使用率                                                    |
| netstat  | 显示网络活动情况                                                               |
| cron     | 计划执行                                                                       |

###### 进程活动

**top命令**

```shell
# 三秒刷新一次
top -d 3
```

* 用户占用的CPU百分比（%us）
* 系统占用的CPU百分比（%sy）
* nice值（%ni），优先级发生变化的用户进程占用的CPU百分比
	* nice
	* ionice
	* renice
* I/O等待的CPU百分比（%wa）
* 处理软件和硬件中断所占用的CPU百分比
* 内存大小
* 交换空间大小
* 缓冲区大小
* 按照CPU时间的多少降序排序进程列表

**iostat命令**

显示CPU时间的统计信息，设备I/O的统计信息，分区和网络子系统的统计信息。

```shell
avg-cpu:  %user   %nice %system %iowait  %steal   %idle
          22.30    0.00    3.20    0.27    0.01   74.23

Device:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtn
vda               2.56         3.74       279.90    7743570  579741324
scd0              0.00         0.00         0.00         36          0
```

CPU利用率的百分比：

* 用户级别执行
* nice优先级在用户级别执行
* 在系统级别执行
* 等待I/O
* 等待虚拟进程
* 空闲时间

**mpstat命令**

mpstat与iostat信息相似，但是将各处理器的信息分开显示。

```shell
mpstat
mpstat -A
mpstat -P ALL
```

**ps命令**

```shell
ps -A | grep mysqld
```

也可用于确定是否存在一些未知进程，或者是否有单个用户运行了大量进程。这可能是由于脚本配置不合理导致的。

###### 内存利用率

**free命令**

free命令显示可用的物理内存量，包括宗内存量，已用内存量、可用内存量以及交换空间，还可显示内核使用的内存缓冲区和缓存的大小。

```shell
# 轮询
free -t -s 5
```

**pmap命令**

输出包括所有内存地址的详细信息，以及报告缠上时进程使用的内存的大小，还显示了内存块模式。

```shell
pmap -d 112756
```

最后一行显示多少内存被映射到文件，私有内存空间的大小，以及与其他进程共享的内存大小。

###### 硬盘利用率

**iostat命令**

列举了每个设备、设备的传输速率、每秒读写块的数量和读写块的总数量。

**df命令**

```shell
df -h
```

**sar命令**

```shell
sar -bBdS 1 1
```

```shell
04:10:40 PM  pgpgin/s pgpgout/s   fault/s  majflt/s  pgfree/s pgscank/s pgscand/s pgsteal/s    %vmeff
04:10:41 PM      0.00      0.00    172.73      0.00   8310.10      0.00      0.00      0.00      0.00

04:10:40 PM       tps      rtps      wtps   bread/s   bwrtn/s
04:10:41 PM      0.00      0.00      0.00      0.00      0.00

04:10:40 PM kbswpfree kbswpused  %swpused  kbswpcad   %swpcad
04:10:41 PM         0         0      0.00         0      0.00

04:10:40 PM       DEV       tps  rd_sec/s  wr_sec/s  avgrq-sz  avgqu-sz     await     svctm     %util
04:10:41 PM  dev252-0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00
04:10:41 PM dev252-16      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00
04:10:41 PM dev252-32      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00

Average:     pgpgin/s pgpgout/s   fault/s  majflt/s  pgfree/s pgscank/s pgscand/s pgsteal/s    %vmeff
Average:         0.00      0.00    172.73      0.00   8310.10      0.00      0.00      0.00      0.00

Average:          tps      rtps      wtps   bread/s   bwrtn/s
Average:         0.00      0.00      0.00      0.00      0.00

Average:    kbswpfree kbswpused  %swpused  kbswpcad   %swpcad
Average:            0         0      0.00         0      0.00

Average:          DEV       tps  rd_sec/s  wr_sec/s  avgrq-sz  avgqu-sz     await     svctm     %util
Average:     dev252-0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00
Average:    dev252-16      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00
Average:    dev252-32      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00

```

* 分页子系统性能的分页信息
	* 分页置换率
	* 每秒内不需要磁盘访问的分页错误数
	* 需要磁盘访问的重大错误数
		* 过多进程，如果错误书很高且磁盘使用率很高，则可能不是磁盘子系统的问题
	* 其他信息
* I/O传输率的报告
	* 美妙的事务数量
	* 读写请求和读写块的总数量
* 交换空间的报告
	* 可使用交换空间大小
	* 被使用交换空间大小和使用百分比
	* 缓存的使用量
* 设备及其统计信息的列表
	* 传输速率
	* 每秒的读写速率和平均等待时间
	* 如果这些值都很高，说明可能达到了设备的最大带宽
* 最后是所有样本参数的平均值

如果分页报告显示错误率异常高，表明系统给可能运行了太多的应用程序或者没有足够的内存。
如果这些纸较低或者一般，则需要检查交换空间。如果交换空间也正常，就检查设备使用报告。

**vmstat命令**

```shell
vmstat -d
```

###### 网络活动

**netstat命令**

```shell
netstat -i
```

**ifconfig命令**

```shell
ifconig
```

###### 常见系统统计信息

**uptime命令**

系统运行时间即时间间隔内的平均负载。

```shell
uptime
```

平均状态是针对活动状态的进程而言的，而不是阻塞或等待状态。

**vmstat**

提供有关进程、内存、分页系统、I/O块和CPU活动的信息。

```shell
vmstat
```


```shell
procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 6  0      0 825928 1694996 7619648    0    0    12    10    0    0 24 12 64  0  0	
```

* r表示等待运行的进程
* b表示处于不可中断状态的进程
* si换入
* so换出
* bi接收块
* bo发送块
* in每秒的中断数
* cs每秒的上下文切换数
* us用户空间上进程运行的时间
* sy内核空间上进程运行的时间
* id限制空间
* wa等待I/O的时间

###### 使用cron自动监控

每天运行性能监控工具，然后将检测结果与基准进行比较。这是主动检控官的基本前提

#### 监控MySQL

##### 什么是性能

按照用户希望的那样得当的运行，响应时间和而低性能被定义成系统运行不佳。

除非有深思熟虑的计划，并且相当了解变更后的期望和后果，否则永远不要更改服务器、数据库或存储引擎的参数。

##### MySQL服务器监控

###### 如何显示MySQL性能

读取和更改服务器变量：

```sql
SHOW [GLOBAL | SESSION] VARIABLES;
SET [GLOBAL | SESSION] variable_name = value;
SET [@@global. | @@session. | @@]variable_name = value;
-- like
SHOW STATUS LIKE '%thread%';
```

###### SQL命令

很多命令可以查询：

```sql
USE INFORMATION_SCHEMA;
SHOW TABLES;
select * from INFORMATION_SCHEMA.TABLES
```

* SHOW INDEX FROM table;
	* 显示索引
* SHOW PLUGINS;
	* 列出所有已知插件名称和状态
* SHOW [FULL] PROCESSLIST;
	* 显示系统上运行的所有线程数据，包括处理客户端连接的线程
	* 诊断响应差的、僵尸进程或者诊断连接问题
	* 使用KILL命令终止进程
	* 需要SUPER权限
* SHOW [GLOBAL | SESSION] STATUS;
	* 显示所有系统变量的值
* SHOW TABLE STATUS [FROM db];
	* 给定数据库表的详情，包括存储引擎、排序规则、创建数据、索引和行统计信息。
* SHOW [GLOBAL | SESSION] VARIABLES;
	* 显示系统变量
* SHOW ENGINE engine_name LOGS;
	* 显示指定引擎的日志信息
* SHOW ENGINE engine_name STATUS;
	* 显示指定引擎的状态信息
* SHOW ENGINES;
	* 显示已知的存储引擎
* SHOW BINLOG EVENTS [IN log_file] [FROM pos] [LIMIT offset row_count];
	* 显示二进制日志中的事件
* SHOW BINARY LOGS;
	* 显示服务器上的二进制日志列表
* SHOW RELAYLOG EVENTS [IN log_file] [FROM pos] [LIMIT offset row_count];
	* 显示中继日志文件内容
* SHOW MASTER STATUS;
	* 显示master当前配置
* SHOW SLAVE HOSTS;
	* 显示连接到master的slave列表
* SHOW SLAVE STATUS;
	* 限制复制中的slave状态

查询缓存是MySQL最重要的性能特征之一。

使缓存失效的事件：

* 数据或索引的变更
* 同一个查询的微小区别会产生不同的结果集，从而导致缓存未命中。因此使用标准的查询访问公共数据是非常重要的。
* 从临时表获取数据
* 是内存中的查询无效的事务事件，如commit

```sql
SHOW VARIABLES LIKE '%query_cache%';
```

```shell
+------------------------------+----------+
| Variable_name                | Value    |
+------------------------------+----------+
| have_query_cache             | YES      |
| query_cache_limit            | 1048576  |
| query_cache_min_res_unit     | 4096     |
| query_cache_size             | 33554432 |
| query_cache_type             | ON       |
| query_cache_wlock_invalidate | OFF      |
+------------------------------+----------+
```

have_query_cache仅表明查询缓存是否可用，设置query_cache_type还不够，因为这并不会释放查询缓存的缓冲区。
必须同时将query_cache_size设置为0才能完全关闭查询缓存。

通过query_cache开头的变量控制查询缓存，而状态变量以Qcache开头。

```sql
-- 查询缓存的状态变量
SHOW STATUS LIKE '%Qcache%';
```

```shell
+-------------------------+-----------+
| Variable_name           | Value     |
+-------------------------+-----------+
| Qcache_free_blocks      | 1         |
| Qcache_free_memory      | 3128392   |
| Qcache_hits             | 0         |
| Qcache_inserts          | 0         |
| Qcache_lowmem_prunes    | 0         |
| Qcache_not_cached       | 305395518 |
| Qcache_queries_in_cache | 0         |
| Qcache_total_blocks     | 1         |
+-------------------------+-----------+
```

```sql
-- 整理查询缓存，而不是清空
FLUSH QUERY CACHE;
```

###### mysqladmin实用工具

常用命令：

* status
	* 服务器状态信息
* extended-status
	* 完整统计信息
* processlist
	* 进程列表
* kill thread id
	* 杀死指定进程
* variables
	* 显示系统服务器变量和值

```shell
# 每3秒执行一次
mysqladmin -uroot --password processlist --sleep 3
# 显式密码
mysqladmin -uroot -ppassword processlist --sleep 3
# 查询系统变量先前值和当前值
mysqladmin -uroot --password extended-status --relative --sleep 3
# 同时查看
mysqladmin -uroot --password processlist status --sleep 3
```

###### MySQL工作台

* 服务器管理器
* SQL开发
* 数据建模
* 数据库迁移向导

###### 第三方工具

**MySAR**

集成了SHOW STATUS、SHOW VARIABLES和SHOW PROCESSLIST的输出结果。

**mytop**

列出了常规统计信息，如主机名称、服务器版本、运行的查询数量、查询的平均执行时间、线程的总数量和其他的重要统计信息。

**InnoTop**

监控事务、死锁、外键、查询活动、复制活动、系统变量的主要统计信息及主机的其他详情。

如果使用InnoDB作为存储引擎，并且需要一个以文本模式运行良好的监控工具，那就选择InnoTop

**MONyog**

可以为安全和性能的主要组件设置参数，还包含有助于服务器性能调优的工具。
另外还可以设置事件以监听特定参数，并在系统达到指定临界点时发出警告。

* 监控服务器资源
* 识别运行不佳的SQL语句
* 监控服务器日志，如错误日志
* 实施监控查询性能，并识别长时间运行的查询
* 预警重大事件

MONyog还提供了GUI组件

###### MySQL基准测试套件

基准测试：

* 过程：确定系统在某种负载下是如何运行的。
* 目的：分别在服务器处于轻负载、中等负载和高负载的情况下，运行定义良好的测试实例，并衡量和记录系统的统计信息。

基准测试为系统性能设置了期望。

运行Perl的基准测试套件：

```shell
./run-all-tests --server=mysql --cmp=mysql --user=root
```

**benchmark函数**

```sql
SELECT BENCHMARK(10000000, "SELECT CONCAT('te','s',' t')");
```

**explain语句**

```sql
EXPLAIN SELECT * FROM table LIMIT 1;
```

##### 服务器日志

MySQL日志类型：

* 常规查询日志
* 慢查询日志
* 错误日志
* 二进制日志

一般启动了错误日志和常规查询日志。常规日志与他们从客户端返回的顺序一致。

通过`--general-log`启动常规查询日志，`--log-output`指定日志位置。

等价动态变量：

```sql
SET GLOBAL log_output = FILE;
```

通过`--log-slow-quer⁠ies`控制慢查询日志。服务器变量`log_query_time`用来控制什么查询被记录到慢查询日志。

slave不记录慢查询，使用`--log-slow-slave-statements`开启记录。

`--log-error`开启或关闭错误日志，`general_log_file`重写文件相关信息。

`--console`启动，会将错误输出到标准输出。

`--log-bin`启动，开启二进制日志并指定文件名。`--logbin-index`更改二进制日志的索引名。

```sql
# 轮换日志
FLUSH LOGS;
```

##### 性能模式

表现为名为performance_schema的数据库。其中包含很多动态表。

用于诊断死锁、互斥和线程问题。还可以获取查询优化的阶段指标、文件I/O、连接等。

###### 概念

```sql
USE performance_schema;
SHOW TABLES;
```

```shell
+----------------------------------------------------+
| Tables_in_performance_schema                       |
+----------------------------------------------------+
| accounts                                           |
| cond_instances                                     |
| events_stages_current                              |
| events_stages_history                              |
| events_stages_history_long                         |
| events_stages_summary_by_account_by_event_name     |
| events_stages_summary_by_host_by_event_name        |
| events_stages_summary_by_thread_by_event_name      |
| events_stages_summary_by_user_by_event_name        |
| events_stages_summary_global_by_event_name         |
| events_statements_current                          |
| events_statements_history                          |
| events_statements_history_long                     |
| events_statements_summary_by_account_by_event_name |
| events_statements_summary_by_digest                |
| events_statements_summary_by_host_by_event_name    |
| events_statements_summary_by_thread_by_event_name  |
| events_statements_summary_by_user_by_event_name    |
| events_statements_summary_global_by_event_name     |
| events_waits_current                               |
| events_waits_history                               |
| events_waits_history_long                          |
| events_waits_summary_by_account_by_event_name      |
| events_waits_summary_by_host_by_event_name         |
| events_waits_summary_by_instance                   |
| events_waits_summary_by_thread_by_event_name       |
| events_waits_summary_by_user_by_event_name         |
| events_waits_summary_global_by_event_name          |
| file_instances                                     |
| file_summary_by_event_name                         |
| file_summary_by_instance                           |
| host_cache                                         |
| hosts                                              |
| mutex_instances                                    |
| objects_summary_global_by_type                     |
| performance_timers                                 |
| rwlock_instances                                   |
| session_account_connect_attrs                      |
| session_connect_attrs                              |
| setup_actors                                       |
| setup_consumers                                    |
| setup_instruments                                  |
| setup_objects                                      |
| setup_timers                                       |
| socket_instances                                   |
| socket_summary_by_event_name                       |
| socket_summary_by_instance                         |
| table_io_waits_summary_by_index_usage              |
| table_io_waits_summary_by_table                    |
| table_lock_waits_summary_by_table                  |
| threads                                            |
| users                                              |
+----------------------------------------------------+
```

性能模式监控事件。事件是已经生效（在代码中启用，称为监控点）的任意不相关的执行，而且持续时间可测量。事件存储为当前事件（最近值）、历史值和概要（聚集值）。

监控器是由服务器（源）中的监控点构成的，这些监控点在执行时产生了事件。监控器必须启用才能产生事件。

使用setup_actors表监控特定用户（线程）。
使用setup_objects表监控特定表或某个数据库中的所有表。

定时器（timer）是以持续事件测量的一种执行。定时器分为空闲（idle）、等待（wait）、阶段（stage）和语句（statement）。  
更改定时器的持续事件可以改变测量的频率。值为：CYCLE, NANOSECOND, MICROSECOND, MILLISECOND, TICK。  
检查performance_timers表中的行可以查看可用的定时器。

配置表用来启动或禁用行为体（actor）、监控器、对象（表）和定时器

###### 入门

`--performance-schema`启动参数也可以控制。

```conf
[mysqld]
performance_schema=ON
```

开启步骤：

1. 设置定时器（适用于有定时元素的监控点）
2. 开启监控点
3. 开启consumer

```sql
-- 检查当前设置
select * from setup_timers;
-- 开启监控点
UPDATE setup_instruments SET enabled='YES', timed='YES' WHERE name = 'statement/sql/show_grants';
-- 开启consumer
UPDATE setup_consumers SET enabled='YES' WHERE name = 'events_statements_current';
UPDATE setup_consumers SET enabled='YES' WHERE name = 'events_statements_history';
-- 执行命令
show grants \G
-- 检查结果
select * from events_statements_current \G
select * from events_statements_history \G
```

events_statements_table的输出结果是最后一次记录的执行语句。  
events_statements_history的输出结果是所有开启的事件上的最近查询。

还可以启用事前过滤和事后过滤。

###### 使用性能模式诊断性能问题

一次改变一个值，如果无效就恢复这个值再尝试下一次更改。

1. 查询setup_instruments表以识别所有相关的监控点并启用它们。
2. 设置您需要记录的频率的定时器。大多数情况下，默认值是正确的定时器值。如果更改定时器，请记录它们的原始值。
3. 找到与监控点相关的消费者(事件表)并启用它们。确保启用了current、history和history_long。
4. 截断*history和*history_long表，以确保以“干净”状态开始。
5. 重现问题。
6. 查询性能模式表。如果您的服务器有多个客户端正在运行，则可以通过线程ID隔离行。
7. 观察这些值并将其记录下来。
8. 调优一个选项/参数/变量集。
9. 回到第5步。重复，直到性能得到改善。
10. 截断*history和History_long表，以确保以“干净”状态结束。
11. 禁用之前启用的事件。
12. 禁用之前启用的监控点。
13. 将定时器恢复到原来的状态。
14. 再次截断*history和History_long表，以确保以“干净”状态结束。

##### MySQL的监控分类

表查询需要切换schema，如USER mysql;

| 关注点 | 设备                    | 指标                      | 示例                                                              |
| ------ | ----------------------- | ------------------------- | ----------------------------------------------------------------- |
| 性能   | System Variables        | Query Cache               | SHOW VARIABLES LIKE '%query_cache%'                               |
| 性能   | Status Variables        | Number of Inserts         | SHOW STATUS LIKE 'com_insert'                                     |
| 性能   | Status Variables        | Number of Deletes         | SHOW STATUS LIKE 'com_delete'                                     |
| 性能   | Status Variables        | Table Lock Collisions     | SHOW STATUS LIKE 'table_locks_waited'                             |
| 性能   | Logging                 | Slow Queries              | SELECT * FROM slow_log ORDER BY query_time DESC                   |
| 性能   | Logging                 | General                   | SELECT * FROM general_log                                         |
| 性能   | Logging                 | Errors                    | --log-error=file name (startup variable)                          |
| 性能   | Performance Schema      | Thread Information        | SELECT * FROM threads                                             |
| 性能   | Performance Schema      | Mutex Information         | SELECT * FROM events_wait_current                                 |
| 性能   | Performance Schema      | Mutex Information         | SELECT * FROM mutex_instances                                     |
| 性能   | Performance Schema      | File Use Summary          | SELECT * FROM file_summary_by_instance                            |
| 性能   | Storage Engine Features | InnoDB Status             | SHOW ENGINE innodb STATUS                                         |
| 性能   | Storage Engine Features | InnoDB Statistics         | SHOW STATUS LIKE '%Innodb%'                                       |
| 性能   | External Tools          | Processlist               | mysqladmin -uroot --password processlist --sleep 3                |
| 性能   | External Tools          | Connection Health (graph) | MySQL Workbench                                                   |
| 性能   | External Tools          | Memory Health (graph)     | MySQL Workbench                                                   |
| 性能   | External Tools          | InnoDB Rows Read          | MySQL Workbench                                                   |
| 性能   | External Tools          | Logs                      | MySQL Workbench                                                   |
| 性能   | External Tools          | All Variables             | MySQL Workbench                                                   |
| 性能   | External Tools          | Query Plan/Execution[a]   | MySQL Workbench                                                   |
| 性能   | External Tools          | Benchmarking              | MySQL Benchmark Suite                                             |
| 可用性 | Status Variables        | Connected Threads         | SHOW STATUS LIKE 'threads_connected'                              |
| 可用性 | Operating System Tools  | Accessibility             | ping                                                              |
| 可用性 | External Tools          | Accessibility             | mysqladmin -uroot --password extended-status --relative --sleep 3 |
| 资源   | Status Variables        | Storage Engines Supported | SHOW ENGINES                                                      |
| 资源   | Operating System Tools  | CPU Usage                 | top -n 1 -pid mysqld_pid                                          |
| 资源   | Operating System Tools  | RAM Usage                 | top -n 1 -pid mysqld_pid                                          |
| 资源   | MySQL Utilities         | Disk Usage                | mysqldiskusage                                                    |
| 资源   | MySQL Utilities         | Server Information        | mysqlserverinfo                                                   |
| 资源   | MySQL Utilities         | Replication Health        | mysqlepladmin                                                     |

_还可以使用EXPLAIN SQL命令_

##### 数据库性能

###### 衡量数据库的性能

一般的数据库提供了分析工具和索引工具，这些工具生产一些统计信息以优化索引。

MySQL提供了一些简单的工具，有助于确定表和查询是否是最优的。它们都是SQL命令，包括EXPLAIN、ANALYZE TABLE和OPTIMIZE TABLE。

**使用EXPLAIN**

EXPLAIN命令给出如何执行SELECT语句的信息（仅对SELECT有效）。与其他数据库的DESCRIBE相似。

```sql
[EXPLAIN | DESCRIBE] [EXTENDED] SELECT select options
-- 查看表的列或分区信息
[EXPLAIN | DESCRIBE] [PARTITIONS SELECT * FROM] table_name
```

> EXPLAIN table_name 同义命令 SHOW COLUMNS FROM table_name、DESC table_name

用法1：查看MySQL优化器如何执行SELECT语句。

其结果是优化器预计执行该语句需要的JOIN操作列表。

这个命令的最佳用处是确定表是否有索引，从而更精确的定位候选行。

* id
	* 执行序列号
* select_type
	* 查询语句类型
* table
	* 在这一步操作的表
* type
	* 使用的JOIN类型
* possible_keys
	* 如果有包含主键的索引，可用字段的列表
* key
	* 被优化器选中的主键
* key_len
	* 主键或部分主键的长度
* ref
	* 约束或需要对比的字段
* rows
	* 估计要处理的行数
* extra
	* 优化器的额外信息

```shell
*************************** 1. row ***************************
           id: 1
  select_type: SIMPLE
        table: film
         type: ALL
possible_keys: NULL
          key: NULL
      key_len: NULL
          ref: NULL
         rows: 892
        Extra: Using where
```

如果type为ALL，是做全表扫描，应该尽量避免，方法是添加索引或重写查询。  
如果type为INDEX，则执行全索引扫描，这是非常低效的。

如果不使用枚举值定义一个查找表的话，就必须执行JOIN来选择指定值的结果。枚举值能代替小型查找表，可以提升性能。  
因为枚举值的温暖本仅保存一次，在表头结构中，行中保存的是数字，形成一个枚举值的索引（数组索引）。枚举值表能节省空间。

```sql
-- EXPLAIN后使用这个语句查看优化器的重写语句
SHOW WARNINGS \G
```

会话变量`last_query_cost`存储最近一次查询的成本。

**使用ANALYZE TABLE**

重新计算一个或多个表的主键分布。这个信息确定JOIN操作中表的顺序。

```sql
ANALYZE [LOCAL | NO_WRITE_TO_BINLOG] TABLE table_list
```

每当表上有重大变更（如批量增加数据）时，都应该执行此命令，这个命令会在表上加锁。

只能为MyISAM和InnoDB表更新主键分布。

```sql
-- 查看索引
SHOW INDEX FROM table_name;
```

**使用OPTIMIZE TABLE**

重建一个或多个表的数据结构。对于长度可变的字段（行）尤其有用。

```sql
OPTIMIZE [LOCAL | NO_WRITE_TO_BINLOG] TABLE table_list
```

LOCAL或NO_WRITE_TO_BINLOG防止被写进二进制日志。

每当表上有重大变更（如批量增加数据）时，都应该执行此命令，这个命令会在表上加锁，且可能运行很长时间。

###### 数据库优化的最佳实践

**谨慎而有效的使用索引**

索引可以提高性能。

索引会为表的删除和插入增加开销。还会降低复制和恢复操作的性能。

没有被使用、使用有效或分布很广的索引应该删除。

**使用规范化，但不要过度使用**

适时违背范式。

冗余计算结果防止重复计算而提高性能。

使用枚举而不是创建表从而避免使用JOIN。

**使用正确的存储引擎完成任务**

```sql
SHOW ENGINES;
```

```sql
CREATE TABLE t1 (a int) ENGINE=InnoDB;
ALTER TABLE t1 ENGINE=MEMORY;
```

* InnoDB
	* 默认引擎
	* 与NDB同是MySQL是仅有的事务引擎
	* 适用于高性能和事务环境
* MyISAM
	* 适用只读为主的环境
	* 高级缓存和索引机制提高数据检索和索引速度
* Blackhole
	* 通常用于中继代理，不处理数据而需要二进制日志
* CSV
	* 存储引擎读写csv
	* 不支持索引，日期和时间也存在一些问题
* Memory
	* 也称作HEAP，是内存中的存储器
	* 使用哈希机制检索频繁使用的数据，使检索更快
	* 用于频繁访问而很少更改的静态数据情况
* Federated
	* 创建参照多个数据库系统的单个表，将多个数据库服务器的表连接起来
	* 适合分布式或数据集环境
	* 不移动数据，也不要求使用相同的存储引擎
* Archive
	* 以压缩格式存储大量数据
	* 适合存储和检索很少访问的文档或历史数据
	* 不支持索引，只能通过表扫描，因此常规数据库要避免使用
* Merge
	* MRG_MYISAM，将一组MyISAM表分装成单个表
	* 这些表按单个表的位置分区，但是没有使用额外的划分机制，必须放在同一个服务器上
	* 搜素和执行的速度更快，因为单个表管理的数据更少了，修复速度也更快
	* 缺点
		* 必须都使用MyISAM表
		* 替换操作不可用
		* 索引比单表的索引效率低
	* 适合在非常大的数据库（VLDB）如数据仓库使用；还用于解决数据划分问题

**通过查询缓存使用视图来更快获得记过**

封装复杂查询，简化数据处理工作的一个很方便的方法就是视图。

使用视图可以水平的（更少的列）或垂直的（WHERE子句）限制数据。这也减少了带宽，避免了滥用`SELECT *`查询。

消除低性能的JOIN操作。

查询缓存存储频繁访问的查询结果。

**使用约束**

* 唯一索引
* 主键
* 外键
* 枚举值
* 集合（sets）
	* 与枚举相似，限定值
* 默认值
	* 避免数据结构差或判断并返回默认值。减少服务器发送量
* NOT NULL选项
	* 保证数据完整性
	* NULL值会导致查询慢

**使用EXPLAIN、ANALYZE、OPTIMIZE**

合理使用，而不是有规律的定期使用。

##### 提高性能的最佳实践

###### 一切都很慢

* 检查硬件问题
* 改善硬件环境
* 考虑将数据迁移到独立的磁盘上
* 检查操作系统配置
* 考虑将有些应用程序建议到其他服务器上
* 考虑横向扩展的复制
* 优化服务器性能

###### 查询慢

* 规范化数据库模式
* 使用EXPLAIN识别丢失或不正确的索引
* 使用benchmark()函数测试部分查询
* 考虑重写查询
* 对标准查询使用视图
* 使用查询缓存进行测试

###### 应用慢

* 开启查询缓存
* 关闭查询缓存。使用DEMAND模式和SELECT SQL_CACHE，按需使用查询缓存
* 考虑并优化存储引擎
* 确定是否使服务器或操作系统的维妮塔
* 定义应用程序基准测试，并测试比较
* 检查内部查询语句，优化它们的性能
* 使用分区来分散数据
* 检查分区的索引

###### 复制慢

* 确保网络峰值性能最佳
* 确保服务器配置正确
* 优化数据库
* 限制master的更新
* 将读操作分散到多个slave中
* 检查slave的复制延迟
* 定期维护日志（二进制日志和中继日志）
* 如果带宽有限，使用压缩
* 使用包容性和排他性的日志选项，最小化复制内容

#### 监控存储引擎

##### InnoDB

提供了，高可用和高性能的事务型操作，完全支持ACID事务。

索引、缓冲池、日志文件和表空间可以被监控和改进性能。

InnoDB表使用的索引是聚集索引，即使未指定索引，也会为每行分配一个内部值，从而使用聚集索引。  
聚集索引是一种数据结构，它不仅存储索引，还存储数据本身。一旦确定到索引中的某个值，就可以直接检索数据而无需额外的磁盘寻道。  
主键也唯一索引都采用聚集索引创建。

如果创建了二级索引，聚集索引的关键字（主键、唯一键或者行ID）也会存在二级索引中。
这样可以快速按关键字查找和快速获取聚集索引的原始数据。
着这意味着使用主键列扫描二级索引，则只需要二级索引就可以获取数据。

缓冲池是用于管理事务和读写磁盘数据的缓存机制，如果配置得当，可以减少磁盘访问。
缓冲池同时还是崩溃恢复的一个重要组成部分，因为缓冲池内的信息将会被定期写入磁盘。默认保存在ib_buffer_poll文件中
InnoDB使用缓冲池来存储数据变更和事务。将数据变更保存到缓冲池中的数据页中。每次引用的时候，该页都会放到缓冲池中。
如果发生改变，就标记为“脏页”。然后这个变更被写入磁盘以更新数据，并想重做日志写入一个副本，这些日志文件为ib_logfile0或ib_logfile1。

InnoDB存储引擎使用两种基于磁盘的机制存储数据，即日志文件和表空间，在关机或死机之前，InnoDB还会使用这些日志来重建或重做数据修复。
在程序启动时，InnoDB引擎读取日志并自动将脏页写入磁盘，从而在系统崩溃前恢复缓冲中的更新。

表空间时InnoDB用来组织与机器无关的文件的工具，包括数据、索引及混滚机制。
默认情况下所有表共享一个表空间（称为共享表空间）。共享表空间不会自动生成多个文件。
默认情况下，一个表空间只占据单个文件，该文件随数据增加而增长。指定autoextend可以允许表空间自动创建新文件。  
还可以将表存储在自己的表空间中（独立表空间）。独立表空间包含数据和表的索引。
虽然仍有一个InnoDB文件，但独立表空间能够将数据隔离在不同的文件中，这些表空间可以自动扩展成多个文件，使得表可以存储更多数据，超出了操作系统可以处理的数据量。
还可以将表空间划分为多个文件，然后存储在不同的磁盘上。

###### 使用SHOW ENGINE命令

SHOW ENGINE INNODB STATUS命令（又称InnoDB监视器）显示有关InnoDB存储引擎的状态的统计和配置信息。

```sql
SHOW ENGINE INNODB STATUS \G
```

SHOW ENGINE INNODB MUTEX显示了InnoDB的互斥体信息，对存储引擎中的线程调优很有帮助。

```sql
SHOW ENGINE INNODB MUTEX;
```

Status列显示了互斥体在操作系统上的等待次数。

###### 使用InnoDB监视器

InnoDB时唯一支持直接监控的本地存储引擎。背后有一个称为监视器的特殊机制，它为父亲和客户端工具手机和报告统计信息。

监控内容：

* 表和记录锁
* 锁等待
* 信号量等待
* 文件I/O请求
* 缓冲池
* 清除和插入缓冲合并活动

使用上面的SHOW ENGINE INNODB STATUS命令可以直接连接监视器，还可以通过创建特殊的表，直接从监视器获取信息。  
一旦创建，每个表中的数据都会转储到标准错误。通过MySQL错误日志可以查看这些信息。

创建下面表来启动监视器，停止只需删除表，监视器每隔15s自动生成新数据。重启会删除表，需要重建。

```shqll
innodb_lock_monitor
innodb_monitor
innodb_table_monitor
innodb_tablespace_monitor
```

每个监视器提供以下数据：

* innodb_monitor
	* 标准监视器显示的信息与SQL命令相同。
* innodb_lock_monitor
	* 与监视器与SQL命令相同，但是不包括锁信息，可以用来检测死锁
* innodb_table_monitor
	* 表监视器生成内部数据字典的详细报告，用于诊断表问题或者了解索引细节。
* innodb_tablespace_monitor
	* 显示共享表空间的扩展信息，包括文件段的列表，还验证表空格键分配的数据结构

###### 监控日志文件

InnoDB日志文件在数据和操作系统之间缓冲数据，所以保证日志正常运行可以获得良好的性能。

```sql
SHOW STATUS LIKE 'InnoDB%log%';
```

* Innodb_log_waits
	* 当日志文件太小时（没有足够空间存储所有数据），操作必须等待日志刷新的等待时间计数器。
	* 如果该值开始增加并长时间大于0，可能需要增加日志文件的大小
* Innodb_log_write_requests
	* 写日志请求的数量
* Innodb_log_writes
	* 数据被写入日志的次数
* Innodb_os_log_fsyncs
	* 操作系统文件同步次数，即fsync()方法调用
* Innodb_os_log_pending_fsyncs
	* 挂起文件同步请求的数量。
	* 如果该值开始增加并长时间大于0，可能需要检查磁盘访问问题
* Innodb_os_log_pending_writes
	* 挂起日志写请求的次数
	* 如果该值开始增加并长时间大于0，可能需要检查磁盘访问问题
* Innodb_os_log_written
	* 吸入日志的总字节数
* Innodb_available_undo_logs

###### 监控缓冲池

缓冲池时InnoDB缓存频繁访问数据的地方。缓冲池任何数据变更也会被缓存。缓冲池还存储当前事务的信息。因此它时关乎性能问题的关键机制。

SHOW INNODB STATUS可以查看缓冲池的行为信息。

报告中的注意事项：

* 空缓冲区
	* 空的、可用于缓冲数据的缓冲段个数
* 已修改的页
	* 已经发生表换的页（脏页）数
* 待处理读请求
	* 等待中的读请求的个数，该值应该保持在低水平
* 待处理的写请求
	* 等待中的写请求的个数，该值应该保持在低水平
* 命中率
	* 缓冲区成功命中的请求个数与总请求之间的比例，最好接近1:1

缓冲池的状态变量：

```sql
SHOW STATUS LIKE 'InnoDB%buf%';
```

* InnoDB_buffer_pool_pages_data
	* 含有数据的页数，包括不变的页和更改过的页
* InnoDB_buffer_pool_pages_dirty
	* 更改过的页的数目
* InnoDB_buffer_pool_pages_flushed
	* 缓冲池页面被刷新的次数
* InnoDB_buffer_pool_pages_free
	* 空闲页的数目
* InnoDB_buffer_pool_pages_misc
	* InnoDB引擎执行管理性工作用到的页数
		> X = InnoDB_buffer_pool_pages_total – InnoDB_buffer_pool_pages_free – InnoDB_buffer_pool_pages_data
* InnoDB_buffer_pool_pages_total
	* 缓冲池中的总页数
* InnoDB_buffer_pool_read_ahead_rnd
	* InnoDB扫描大数据块时发生随机预读的数量
* InnoDB_buffer_pool_read_ahead_seq
	* 顺序扫描全表时发生顺序预读的数量
* InnoDB_buffer_pool_read_requests
	* 逻辑读请求的次数
* InnoDB_buffer_pool_reads
	* 直接从磁盘中逻辑读取（而不是从缓冲池）的次数
* InnoDB_buffer_pool_wait_free
	* 如果缓冲池忙或者没有空闲页，等待页面刷新的次数
* InnoDB_buffer_pool_write_requests
	* 写入InnoDB缓冲池的次数

###### 监控表空间

InnoDB可以在运行缓慢时扩展表空间，那么基本自给自足。autoextend选项配置innodb_data_file_path变量，可以自动扩展。

```shell
--innodb_data_file_path=ibdata1:10M:autoextend
```

###### 使INFORMATION_SCHEMA中的表

INFORMATION_SCHEMA数据库中包含大量的InnoDB表。从技术上说，这些表是视图，因为他们的数据是查询时生成的。

这些表用于监控压缩、事务、锁等

* INNODB_CMP
	* 显示压缩表的详细信息和统计信息
* INNODB_CMP_RESET
	* 与INNODB_CMP相同，但是从查询时会重置统计信息，从而可以定期跟踪统计信息
* INNODB_CMPMEM
	* 显示在缓冲池中压缩使用情况的详细信息和统计信息
* INNODB_CMPMEM_RESET
	* 与INNODB_CMPMEM相同，但是从查询时会重置统计信息，从而可以定期跟踪统计信息
* INNODB_TRX
	* 显示所有事务的详细信息和统计信息
* INNODB_LOCKS
	* 显示事务请求的所有锁的详细信息和统计信息，描述每个锁的状态、模式、类型信息
* INNODB_LOCK_WAITS
	* 显示事务请求的所有被阻塞的锁的详细信息和统计信息，描述每个锁的状态、模式、类型和阻塞事务。

使用压缩表可以监控表的压缩信息，包括页大小、使用哪些页、压缩时间和解压时间等详细信息。  
如果使用了压缩并希望压缩带来的开销不会影响数据库服务器的性能，那么这些信息是重要的监控对象。

使用事务和锁顶表来监控事务。可以保证事务型数据顺利运行。它可以精确的确定各个事务所在的状态，以及哪些事务被阻塞，哪些被锁定。

###### 使PERFORMANCE_SCHEMA表

```sql
-- 查看活动线程列表
SELECT thread_id, name, type FROM threads WHERE NAME LIKE '%innodb%';
```

一些InnoDB特有的项存在于wlock_instances、mutex_instances、file_instances、file_summary_by_event_name、和file_summary_by_instances表中。

###### 其他要考虑的参数

* 某些情况下调节innodb_thread_concurrency选项可以提高性能
	* 默认0或者8（早期）
	* 比值设置为处理器个数加上独立磁盘的和
* innodb_fast_shutdown选项能快速关闭InnoDB
	* 跳过了一些步骤
* innodb_lock_wait_timeout可以控制InnoDB如何处理死锁
	* 默认50s
* AUTOCOMMIT设置为0，保证整个装载只提交一次
* 还可以关闭外键和唯一约束来改善批量装载

###### InnoDB故障排除的技巧

**错误**

去错误日志中寻找错误信息使用`--log-error`选项开启

**死锁**

`--innodb_print_all_deadlocks`选项将所有死锁信息写入日志。这样SHOW INNODB STATUS看到的就不止一个死锁。

**数据字典问题**

存储崩溃或文件损坏：

* 孤立临时表
	* ALTER TABLE失败，可能由于没有正确清理临时表。
	* 使用表监视器确定表名，然后用DROP TABLE命令删除这个孤表
* 无法打开表
	* Can't open file: 'somename.innodb'
	* Cannot find table somedb/somename...
	* 数据库文件夹有个一somename.frm的孤立文件，删除它
* 表空间不存在
	* 使用了--innodb_file_per_table选项，InnoDB data dictionary has tablespace id N, but tablespace with the id or name does not exist...
	* 删除表然后重建
		* 在另一个库中重建这个表
		* 找到frm文件并复制到原始库
		* 删除表
		* 这样报找不到ibd文件，这样重建表或从备份中恢复
* 无法创建表
	* 可能由于没有frm文件，根据错误日志信息进行处理

**观察控制台信息**

有些错误信息只在标准输出中才有。

**I/O问题**

通常在启动或创建/删除新对象的时候出现。

检查错误日志或控制台的错误信息，检查操作系统相关的错误，它们会提示引发错误的原因。
还要检查数据目录下丢失或崩溃的文件夹和InnoDB文件。

操作系统对磁盘进行诊断防止硬件问题被认为是性能问题。

检查innodb_data_*配置

**数据库崩溃**

配置文件中innodb_force_recovery恢复选项启动服务器，其值设置为1到6的整型，可是InnoDB在启动时跳过某些操作。

只应该在某些极端情况使用。

1. 发出SELECT语句时，跳过损坏的页。仅允许部分数据恢复
2. 不要启动master或清除线程
3. 不要在崩溃之后执行回滚
4. 不要执行插入缓冲区操作。不要计算表的统计信息
5. 启动时忽略掉撤销（undo）日志
6. 运行恢复时不要执行重做（redo）日志

##### MyISAM

只需要调整key cache。

提高性能的方法分为三大类：优化粗盘存储；通过监控和优化key cache来有效地使用内存；优化数据库表。

* 优化磁盘存储
* 优化数据库表的性能
* 使用MyISAM实用工具
* 按照索引顺序存储表
* 压缩表
* 对数据表进行碎片整理
* 监控key cache
* 预加载key cache
* 使用多个key cache
* 其他需要考虑的参数

###### 优化磁盘存储

将数据保存为myd文件和一个或多个myi文件，这些文件与frm文件一起存储在与数据库同名的目录下，由--datadir启动选项决定。

因此，MyISAM的磁盘空间优化与服务器上的磁盘空间优化方法相同。
可以将数据目录移动到自己的磁盘上可以提高性能，还可以使用RAID或其他高可用性存储选项来进一步提升性能。

###### 修复表

优化表：ANALYZE TABLE、OPTIMIZE TABLE、REPAIR TABLE。

* ANALYZE TABLE：检测表的关键字分布。参考InnoDB部分的介绍
* REPAIR TABLE：为MyISAM、Archive和CVS存储引擎修复崩溃的表，用于恢复哪些崩溃的或运行很慢的表
* OPTIMIZE TABLE：用于恢复被删除的块和重组表，从而提高性能。参考InnoDB部分的介绍

###### 使用MyISAM实用工具

* myisam_ftdump
	* 显示全文索引信息
* myisamchk
	* 在MyISAM表上执行分析
* myisamlog
	* 查看MyISAM表的更改日志
* myisampack
	* 压缩表以减少存储量

_注意事项：使用优化工具之前做好备份。_

myisamchk时检控官的主力工具。

性能提升、恢复和状态报告的选项：

* analyze
	* 分析索引的关键字分布以提升性能
* backup
	* 更改表之前备份
* check
	* 检查表的错误信息
* extended-check
	* 彻底检查表包括索引的错误信息
* force
	* 如果发现错误，执行修复
* information
	* 显示表的统计信息
* medium-check
	* 更加深入的检查和修复表，少于extended-check
* recover
	* 全面修复表，执行除了唯一索引重复的所有修复操作
* safe-recover
	* 传统形式的修复，有序的读取所有行，并更新所有索引
* sort index
	* 从高到低排列索引树，这样能够减少索引结构的查找时间，加快索引的访问速度
* sort records
	* 按指定的索引顺序对记录进行排序，这样可以提高某些基于索引的查询性能

###### 按索引顺序存储表

可以提高大量的数据范围查询的检索效率。

有序的访问数据，而无需查找磁盘页。

```shell
# 按照第二个索引顺序排序
myisamchk -R 2 /usr/local/mysql/data/test/table1
```

使用ALTER TABLE和ORDER BY达到同样的结果。

由于新增操作使表不再有序，导致数据库性能下降，在经常变更的表上采用这个技术，可以确保表的存储顺序最佳。

###### 压缩表

MyISAM只能压缩只读表。因为MyISAM不能压缩、重新排序，也不能对压缩数据执行添加或删除操作。

```shell
# 备份
myisampack -b /usr/local/mysql/data/test/table1
```

###### 对数据表进行碎片整理

OPTIMIZE TABLE命令或者myisampack工具

###### 监控key cache

key cache是一个高效的存储结构，用于存储频繁使用的索引数据。只有MyISAM才能使用key cache。
通过快速查找机制（通常使B-tree）存储关键字。索引内部的存储形式使连接列表，可以被快速检索到。

MyISAM数据表数据读取时自动创建key cache。每次查询前，都检查key cache。

```sql
-- 查询相关的变量
SHOW STATUS LIKE 'Key%';
SHOW VARIABLES LIKE 'key%';
```

调整key cache需要通过监控调优。

提高缓存命中率：

* 预加载缓存
* 使用多个key cache
* 为默认key cache分配更多的内存

###### 预加载key cache

预加载是提高查询速度的有效办法。

```sql
-- IGNORE LEAVES只加载非叶子节点
LOAD INDEX INTO CACHE table_name IGNORE LEAVES;
```

###### 使用多个key cache

MyISAM允许创建多个key cache或自定义key cache，以减少对默认key cache的争用。  
该特性允许将一个或多个表的索引加载到某个特殊的缓存中。这意味着按任务分配内存。
如果一段时间内对一组表执行大量的查询操作，而且频繁引用这些表上的索引，那么这个方法则能够大大提高性能。

首先使用SET命令分配内存，然后执行一个或多个CACHE INDEX命令加载一个或多个表的索引。
与默认的不同，可以将缓存大小设置为0将其刷新或删除。

```sql
SET GLOBAL emp_cache.key_buffer_size=128*1024;
CACHE INDEX salaries IN emp_cache;
SET GLOBAL emp_cache.key_buffer_size=0;
-- 其实是创建了一个新的全局用户变量
select @@global.emp_cache.key_buffer_size;
```

可以在配置文件中保存配置，init-file=path_to_file命令引入到主配置中。

###### 其他要考虑的参数

* myisam_data_pointer_size
	* 如果没有为MAX_ROWS指定值，CREATE TABLE使用默认指针大小一般取2-7。默认为6.
* myisam_max_sort_file_size
	* 数据排序时使用的临时文件大小的最大值。增大值可以加速索引的修复和重组。
* myisam_recover_options
	* MyISAM的恢复模式。也可用于OPTIMIZE TABLE。
	* 模式包括：默认（default）、备份（backup）、强制（force）、快速（quick），选项可以任意组合
	* 默认模式指不检查备份、强制或快速的情况下执行恢复
	* 备份模式是指在恢复前后弦创建备份
	* 强制模式指即使数据丢失，仍然进行数据恢复
	* 快速模式是指如果没有标记为删除的模块，就不检查表中的数据行
* myisam_repair_threads
	* 如果大于1，则并行执行修复和排序操作，从而加快操作速度否者顺序执行
* myisam_sort_buffer_size
	* 排序操作的缓存区大小。增加该值有助于排序索引，但是如果该值操作4GB，只是用64位机器
* myisam_stats_method
	* 在统计操作中用于控制服务器如何统计所引致分布的NULL值，这会影响到优化器。
* myisam_use_mmap
	* 为读写MyISAM表开启存储器映选项。如果同时存在很多小写入和返回大数据集的读查询，这个功能非常有用。

其他注意事项：

* MyISAM数据损坏的概率比InnoDB高，因此需要较长的恢复时间。
* 由于不支持事务会导致语句部分执行。
* slave会由于查询导致滞后，索引包含事务的高可用方案中使用MyISAM可能会出现问题。

#### 监控复制

##### 入门

有两个方面影响复制拓扑性能。必须同时优化他们。

* 确保有足够的带宽去处理复制数据
* 确保被复制的数据库是被优化过的
	* master的任何低效率的操作都会导致salve的低效
	* 特别是索引和规范化
	* 查询语句页需要优化，防止拖垮slave性能

##### 服务器设置

确保服务器性能是最优的。

确保服务器操作系统又有足够的内存，而且存储设备和存储引擎对数据库来说都是最优的。

master执行的操作，slave也要复制。
master使用多线程运行，slav使用单线程复制，所以负载基本相同时，slave处理和执行事件也可能花更多的时间。

故障转移时提升的slave应该与master拥有相同的性能。

##### 包容性和排他性复制

* 可以将复制配置成复制所有数据；
* 也可hi只记录master上的某些数据或者忽略某些数据，从而限定哪些写入二进制日志，哪些被复制；
* 或者还可以配置slave，使其对某些数据进行操作。

参考复制过滤部分

##### 复制线程

* master上有个Binlog Dump线程
* slave上有个Slave IO线程和Slave SQL线程

```sql
SHOW PROCESSLIST;
```

* Id
	* 连接Id
* User
	* 运行语句的用户
* Host
	* 语句来源主机
* db
	* 指定的库，NULL则没有指定默认库
* Command
	* 运行的命令类型
* Time
	* 处于报告状态的时间，秒为单位
* State
	* 描述当前动作或状态（如等待）
* Info
	* 正在执行的语句信息。NULL表明没有语句正在执行，等待状态的线程也为NULL

##### 监控master

```sql
SHOW MASTER STATUS \G
SHOW BINARY LOGS \G
SHOW BINLOG EVENTS \G
```

###### master的监控命令

SHOW MASTER STATUS \G：

* File
	* binlog文件名称
* Position
	* 二进制当前位置
* Binlog_Do_DB
	* --binlog-do-db指定的所有库
* Binlog_Ignore_DB
	* --binlog-ignore-db指定的所有库
* Executed_Gtid_Set
	* master上的所有GTID，与gtid_executed的值一样

SHOW BINLOG EVENTS \G：

```sql
SHOW BINLOG EVENTS [IN <log>] [FROM <pos>] [LIMIT [<offset>,] <rows>]
```

这个命令会产生大量数据，用于将master上都是事件与slave中继日志中的事件进行对比。

###### master的状态变量

* Com_change_master
	* CHANGE MASTER命令执行的次数
	* 如果该值变化的频繁或者高于服务器数乘以slave的计划启动次数的乘积高的多，说明连接不稳定
* Com_show_master_status
	* 显示SHOW MASTER STATUS命令执行的次数
	* 如果该值很高，表明重连请求次数不正常

##### 监控slave

```sql
SHOW SLAVE STATUS \G
SHOW BINARY LOGS \G
SHOW BINLOG EVENTS \G
SHOW RELAYLOG EVENTS \G
```

###### slave的监控命令

SHOW SLAVE STATUS \G：

包括slave的二进制日志、slave到master的连接和复制活动，当前binlog文件的文件名和偏移位置。

结果信息分组：master连接信息、slave性能、日志信息、过滤、日志性能和错误条件。

* 第一行信息最重要，显示了当前I/O线程的状态
	* 正在连接到master
	* 等待master事件
	* 重新连接master等
* master连接的信息包括当前master的主机名、连接的用户账号以及用于连接master的slave端口，最后时SSL信息
* master二进制日志和中继日志信息，包括文件名和位置信息
	* Relay_Master_Log_File表明了中继日志最近事件所在的master日志文件名
* 复制过滤器配置猎取了所有slave端的复制过滤器
* slave和I/O、SQL线程的最近的错误号和文本。
* slave配置信息，跳过计数器的设置和until条件
* 底部时当前的错误信息，如果slave正常运行，这些值应该总是0

重要的性能字段：

* Connect_Retry
	* 重连事件间隔，秒为单位
* Exec_Master_Log_Pos
	* 显示master二进制日志中最后执行的事件位置
* Relay_Log_Space
	* 所有中继日志文件的总大小，确定是否需要清除中继日志
* Seconds_Behind_Master
	* 事件执行和事件写入master二进制日志之间的间隔事件
	* 过高表示复制滞后
* Retrieved_Gtid_Set
	* slave收到的GTID事务列表
	* 如果列表不一致，slave读取事件可能比master滞后
* Executed_Gtid_Set
	* slave执行的GTID列表
	* 如果与Retrieved_Gtid_Set不同步，说明slave没有执行全部事务，或者有些事务时由slave发出的

###### slave的状态变量

前四个变量应该与slave的维护频率相对应，如果不一致：拓扑结构上slave数量是否比预期的多或者某个slave重启次数过于频繁

* Com_show_slave_hosts
	* SHOW SLAVE HOSTS命令执行次数
* Com_show_slave_status
	* 命令执行次数
* Com_slave_start
	* 命令执行次数
* Com_slave_stop
	* 命令执行次数
* Slave_heartbeat_period
	* master的心跳检测的间隔时间的当前配置信息
* Slave_last_heartbeat
	* 最近收到的心跳事件。显示为一个时间戳。
* Slave_open_temp_tables
	* slave的SQL线程使用的临时表数量
* Slave_received_heartbeats
	* 从master得到恢复的心跳书
* Slave_retried_transactions
	* slave启动后SQL线程重试事务次数
* Slave_running
	* 已经连接到master上正常运行为ON，否则为OFF

##### 其他要考虑的因素

###### 网络

使用slave_compressed_protocol变量可以设置压缩信息。

SSL信息参考《通过Internet进行复制》部分

设置心跳间隔：

CHANGE MASTER命令中的`master_heartbeat_period=<value>`配置master的心跳

```sql
SHOW STATUS like 'slave_heartbeat period';
SHOW STATUS like 'slave_received_heartbeats';
```

###### 监控和管理slave滞后

大规模数据更新、slave负担过重或其他严重的网络性能事件都会导致slave滞后于master。

* SHOW SLAVE STATUS查看Seconds_Behind_Master表明slave滞后于master的秒数。
* SHOW PROCESSLIST也可以表明slave的延迟时间。

这种情况一帮增加slave平衡负载

###### slave滞后的原因和预防错是

使用多线程slave可以缓解滞后问题。

滞后原因：

* I/O线程读取日志中的事件被延迟，通常由于slave单线程而master多线程执行导致
* 低效率的JOIN的长查询
* 磁盘读取I/Odds限制
* 锁竞争
* InnoDB线程并发问题

缓解滞后：

* 组织数据
	* 规范化和使用数据分片实现分布式，提高性能
* 分而治之
	* 横向扩展
	* 过滤
* 识别并重构长时间运行的查询
	* 重构查询、操作或应用发出较短的或更紧凑的事务
	* 注意与过滤共同使用引发的事务完整性问题
* 负载均衡
	* 平衡各个slave之间的负载
* 使用最新的硬件
	* 至少和master一样强大
* 减少锁竞争
	* 重构查询避免使用锁

###### 使用GTID

* enforce_gtid_consistency
	* 服务器禁止执行任何不安全的事务
	* 包括事务内部使用CREATE TALBE ... SELECT和CREATE TEMPORARY TABLE。
	* 默认是禁用的、只读的全局变量
* gtid_executed
	* 绘画范围则表示会话中写入缓存的一组事务
	* 全局范围则显示二进制日志中记录的全部事务
* gtid_mode
	* 是否正在使用GTID
* gtid_next
	* 确定GTID的创建方式
	* AUTOMATIC表示通过标准全局唯一机制创建GTID。
	* ANONYMOUS表示使用文件和位置生成GTID，因此不是唯一的
* gtid_owned
	* 会话范围表示当前服务器拥有的所有GTID列表
	* 全局范围表示所有GTID列表及每个GTID的拥有者
* gtid_purged
	* 显示已经从二进制日志中清除的事务

因为无法排除GTID，所以需要在master上做全备份，设置gtid_purged中的GTID列表，然后在slave上恢复。

### 备份和恢复

备份应对一下情况：

* 数据保护
	* 当错误语句slave已经生效后的错误处理
* 创建新服务器

```bat
# 备份数据库内容（结构加数据，没有数据库本身）
mysqldump -uusername -ppassword databasename>/bak.sql
# 恢复
mysql -uusername -ppassword databasename</bak.sql
# 登陆后恢复
mysql -uusername -ppassword
source /bak.sql
```

### 监控

有许多不同的东西可以监视、测量和计划来处理这些类型的更改。下面是一些例子:

* 可以将索引添加到经常读取的表中。
* 可以重写查询或更改数据库结构，以加快执行时间。
* 如果锁被保存了很长时间，这表明几个连接在使用同一个表。更换存储引擎可能会有好处。
* 如果一些过热的slave正在处理不成比例的查询，系统可能需要进行一些重新均衡，以确保所有的过热的slave都被均匀地击中。
* 要处理资源使用的突然变化，必须确定每个服务器的正常负载，并理解系统何时因为负载突然增加开始缓慢响应。

如果没有监视，就无法发现问题查询、过热的slave或使用不当的表。

## Oracle

### 用户

默认用户

| 用户名 | 密码       | 备注      |
| ------ | ---------- | --------- |
| sys    | 安装时设置 | as sysdba |
| system | manager    |           |
| scott  | tigger     |           |

创建用户

```sql
sqlplus / as sysdba
set linesize 300

select * from dba_users;
select * from all_users;
select * from user_users;

create user username identified by password default tablespace users;
drop user username cascade;
-- 解锁用户
alter user scott account unlock;
```

### 表空间

```sql
select username,default_tablespace from   dba_users;
select table_name from user_tables;

sqlplus sys/sys as sysdba
--创建默认表空间
create tablespace mytbs datafile '/home/oracle/oradata/data.dbf' size 300M;
--创建用户
create user mytbs identified by mytbs default tablespace mytbs;
--赋权 需访问到dba_directories
grant dba to mytbs; 


desc user_tables;
SELECT * FROM DICTIONARY;-- 数据字典表
SELECT TABLE_NAME, TABLESPACE_NAME FROM USER_TABLES;
SELECT VIEW_NAME FROM USER_VIEWS;
SELECT TABLE_NAME,CONSTRAINT_NAME FROM USER_CONSTRAINTS;
SELECT INDEX_NAME,TABLE_NAME FROM USER_INDEXES;
SELECT SEQUENCE_NAME FROM USER_SEQUENCES;
```

### 权限

#### 系统权限

* 登陆权限

```sql
grant create session to username;
```

* 创建表

```sql
grant create table to username;
```

* 表空间

```sql
grant unlimited tablespace to username;
```

* 撤销权限

```sql
revoke create table from username;
```

* 赋予所有用户权限

```sql
grant create any table to public;
```

* 查询当前用户系统权限

```sql
select * from user_sys_privs;
```

#### 对象权限

* 赋予用户对象权限

```sql
grant select on tablename to username;
grant insert on tablename to username;
grant all on tablename to username;
revoke all on tablename to username;
```

* 列权限

查询和删除不能控制到列

```sql
grant insert(columnname) on tablename to username;
grant update(columnname) on tablename to username;
```

* 查询当前用户对象权限

```sql
select * from user_tab_privs;-- 表
select * from user_clo_privs;-- 列
```

#### 权限传递

* 赋予用户权限，被赋权限用户可以继续赋予其他用户

```sql
grant select on tablename to username with admin option;
grant alter any table to username with admin option;
grant select on tablename to username with grant option;
```

### 角色

```sql
create role rolename;
grant create session to rolename;
grant rolename to username;
-- 有些权限无法赋给角色，如unlimited tablespace
drop role rolename;
```

### 登陆验证机制

* 操作系统验证(首先采用)
* 密码文件验证
* 数据库验证

* 启动过程

linux

```shell
# new version
lsnrctl start
sqlplus sys/oracle as sysdba
startup
# old version
lsnrctl start
sqlplus /nolog
conn sys/oracle as sysdba
startup
```

windows

```bat
lsnrctl start
oradmin -startup -sid orcl
```

* 修改密码

```sql
alter user username identified by password;
```

### 表操作

```sql
CREATE TABLE tablename AS SELECT * FROM tablename1; -- 创建表并复制数据
INSERT INTO tablename (SELECT * FROM tablename1);
DROP TABLE tablename

ALTER TABLE tablename ADD (id NUMBER);
ALTER TABLE tablename MODIFY (id VARCHAR(10));
ALTER TABLE tablename DROP COLUMN ID;
ALTER TABLE tablename ADD CONSTRAINT pk_tablename PRIMARY KEY (id);
ALTER TABLE TABLENAME ADD CONSTRAINT fk_tablename FOREIGN KEY (EMPNO) REFERENCES EMP(EMPNO);
ALTER TABLE tablename DROP CONSTRAINT pk_tablename;

SELECT * FROM tablename;
DELETE FROM tablename;
```

### 索引

增加了查询效率，降低了插入效率

```sql
CREATE INDEX idx_tablename_columnname ON TABLENAME (columnname);
show index from tablename;
show keys from tablename;
```

### 序列

```sql
CREATE SEQUENCE SEQUENCE_NAME;

SELECT SEQUENCE_NAME.nextval FROM dual;
SELECT SEQUENCE_NAME.currval FROM dual;

SELECT SEQUENCE_NAME FROM USER_SEQUENCES;
```

### 字符串

```sql
select to_char(sal,'999,999,999.99') FROM EMP;-- 2,975.00
select to_char(sal,'L999,999,999.99') FROM EMP;-- ￥2,975.00
select to_char(sal,'000000.00') FROM EMP;-- 002975.00
select to_number('002975.00','000000.00') FROM dual;-- 2975
```

```sql
select col1 || col2 from tablename;
-- 两个引号转义成一个引号
select 'a' || 'b''c' from dual;-- abc
```

```sql
-- 指定转义字符
SELECT * FROM BONUS WHERE BONUS.ENAME LIKE '%$%%' ESCAPE '$';
-- 使用'转义'
SELECT * FROM BONUS WHERE BONUS.ENAME LIKE '%''%';
```

### 组函数

```sql
SELECT max(SAL) FROM EMP;
SELECT min(SAL) FROM EMP;
SELECT avg(SAL) FROM EMP;
SELECT round(avg(SAL),2) FROM EMP;-- 四舍五入两位
SELECT sum(SAL) FROM EMP;
SELECT count(*) FROM EMP;-- 非空字段
SELECT count(DISTINCT JOB) FROM EMP;

-- 不使用组函数获取最大值
SELECT
  SAL
FROM (
  SELECT
    ROWNUM ,
    EMP.*
  FROM EMP ORDER BY SAL DESC
) t WHERE ROWNUM <2
```

### 分组

```sql
SELECT JOB,count(*) FROM EMP GROUP BY JOB;
SELECT JOB,DEPTNO,count(*) FROM EMP GROUP BY JOB,DEPTNO;
SELECT ENAME FROM EMP WHERE COMM = (SELECT max(COMM) FROM EMP);

SELECT DEPTNO,avg(COMM) AVG_COMM FROM EMP 
WHERE JOB!='KING' GROUP BY DEPTNO 
HAVING avg(COMM)>350 ORDER BY AVG_COMM DESC
```

### 子查询

```sql
-- 查询每个部分薪水最高的员工和薪水
SELECT
  EMP.ENAME,
  SAL,
  t.DEPTNO
FROM EMP, (SELECT
             DEPTNO,
             MAX(SAL) MAXSAL
           FROM EMP
           GROUP BY DEPTNO) t
WHERE EMP.DEPTNO = t.DEPTNO AND EMP.SAL = t.MAXSAL

-- 查询部门平均薪资等级
SELECT
  SALGRADE.GRADE,
  t.DEPTNO,
  t.AVGSAL
FROM SALGRADE
  JOIN
  (SELECT
     DEPTNO,
     avg(SAL) AVGSAL
   FROM EMP
   GROUP BY DEPTNO) t ON
                        t.AVGSAL > SALGRADE.LOSAL AND t.AVGSAL < SALGRADE.HISAL;

-- 查询领导姓名
SELECT
  t1.EMPNO,
  t1.ENAME,
  t2.ENAME MGRNAME
FROM EMP t1, EMP t2
WHERE t1.MGR = t2.EMPNO;

-- 部门员工薪水等级的平均值
SELECT
  avg(GRADE),
  DEPTNO
FROM (
       SELECT
         DEPTNO,
         SALGRADE.GRADE
       FROM EMP
         LEFT JOIN SALGRADE ON EMP.SAL BETWEEN SALGRADE.LOSAL AND SALGRADE.HISAL) t
GROUP BY DEPTNO

-  不使用组函数获取最大值
SELECT SAL
FROM EMP
WHERE EMP.SAL NOT IN (
  SELECT DISTINCT e1.SAL
  FROM EMP e1, EMP e2
  WHERE e1.SAL < e2.SAL)

-- 平均薪水最高的部门
SELECT
  DEPTNO
FROM EMP
GROUP BY DEPTNO
HAVING avg(SAL) = (
  SELECT max(AVGSAL)
  FROM (
    SELECT
      DEPTNO,
      avg(SAL) AVGSAL
    FROM EMP
    GROUP BY DEPTNO
  )
)

SELECT DEPTNO
FROM (SELECT
        DEPTNO,
        avg(SAL) AVGSAL
      FROM EMP
      GROUP BY DEPTNO)
WHERE AVGSAL = (
  SELECT max(AVGSAL)
  FROM (
    SELECT
      DEPTNO,
      avg(SAL) AVGSAL
    FROM EMP
    GROUP BY DEPTNO
  )
)
```

### 空值

```sql
SELECT nvl(COMM, 0) FROM EMP;
```

### 时间

```sql
select sysdate from dual
SELECT to_date('1992-2-2','yyyy-MM-dd') FROM dual;
SELECT to_char(sysdate,'yyyy-MM-dd') FROM dual;
```

### 分页

```sql
-- 第一层：获取数据物理地址
-- 第二层：取得最大页数
-- 第三层：取得最小页数
-- 第四层：因为取得的页数都是物理地址，再根据物理地址，插叙出具体数据

--rowid分页，第一步
SELECT
  rowid rid
FROM emp
ORDER BY sal DESC;
--rowid分页，第二步
SELECT
  rownum rn,
  rid
FROM (SELECT
        rowid rid
      FROM emp
      ORDER BY sal DESC)
WHERE rownum < 10;
--rowid分页，第三步
SELECT rid
FROM (SELECT
        rownum rn,
        rid
      FROM (SELECT
              rowid rid
            FROM emp
            ORDER BY sal DESC)
      WHERE rownum < 10)
WHERE rn > 5;
--rowid分页，第四步
SELECT *
FROM emp
WHERE rowid IN (SELECT rid
                FROM (SELECT
                        rownum rn,
                        rid
                      FROM (SELECT
                              rowid rid
                            FROM emp
                            ORDER BY sal DESC)
                      WHERE rownum < 10)
                WHERE rn > 5);
```

### 修改编码

```shell
shutdown immediate;
startup mount;
ALTER SYSTEM ENABLE RESTRICTED SESSION;
ALTER SYSTEM SET JOB_QUEUE_PROCESSES=0;
ALTER SYSTEM SET AQ_TM_PROCESSES=0;
alter database open;
alter database character set INTERNAL_USE UTF8;
shutdown immediate;
startup;
exit;
```

### 备份还原

```shell
export ORACLE_SID=orcl
export ORACLE_HOME=/oracle/product/11gR1/db
export PATH=$PATH:.:/oracle/product/11gR1/db/bin

# 整个库备份还原
expdp system/manager DIRECTORY=dpdata1 DUMPFILE=full.dmp FULL=y;
impdb system/manager DIRECTORY=dump_dir DUMPFILE=full.dmp FULL=y;
```

### ORA错误

#### ORA-00845

```shell
mount -o size=2G -o nr_inodes=1000000 -o noatime,nodiratime -o remount /dev/shm
```

## 三范式

* 列不可分
* 要有主键，不能存在部分依赖，确保表中的每列都和主键相关（多对多关系拆分成三张表，防止非主键列部分依赖主键）
* 非主键列必须直接依赖于主键，不能存在传递依赖，（避免查询路径过长而导致询问时间过长或者更新异常）

## 行转列

### 静态拼接行转列

```sql
SELECT DISTINCT
  PRODID             AS ID,
  sum(CASE WHEN color = 'r'
    THEN COUNTS END) AS red,
  sum(CASE WHEN color = 'b'
    THEN COUNTS END) AS blue,
  sum(CASE WHEN color = 'y'
    THEN COUNTS END) AS yellow
FROM
  PROD
GROUP BY PRODID;
```

## 优化

* 表建立索引
* 查询时最左索引原则（索引列条件靠近where）

------

*以上概念总结于传智播客JavaWeb课程*